<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>FILE</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-11-17T05:34:18.603Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Les</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/11/17/fdisk%20-l/"/>
    <id>http://yoursite.com/2020/11/17/fdisk -l/</id>
    <published>2020-11-17T02:40:48.354Z</published>
    <updated>2020-11-17T05:34:18.603Z</updated>
    
    <content type="html"><![CDATA[<p>fdisk -l</p><p>mkfs.ext4 /dev/nvme0n1p4</p><p>原本的是  /dev/nvme0n1p7</p><p>多个分区 挂在到同目录</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;fdisk -l&lt;/p&gt;
&lt;p&gt;mkfs.ext4 /dev/nvme0n1p4&lt;/p&gt;
&lt;p&gt;原本的是  /dev/nvme0n1p7&lt;/p&gt;
&lt;p&gt;多个分区 挂在到同目录&lt;/p&gt;

      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/11/13/%E4%B8%93%E4%B8%9A%E7%9F%A5%E8%AF%86%E6%98%AF%E4%B8%80%E7%A7%8D%E9%87%8D%E8%A6%81%E7%9A%84%E7%9F%A5%E8%AF%86%E8%B5%84%E4%BA%A7%EF%BC%8C%E4%BD%86%E6%98%AF%E4%BB%96%E4%BB%AC%E5%BE%88%E9%9A%BE%E4%BB%A5%E8%AF%A6%E7%BB%86%EF%BC%8C%E5%BD%A2%E5%BC%8F%E5%8C%96%E5%92%8C%E5%AE%8C%E6%95%B4%E7%9A%84%E6%96%B9%E5%BC%8F%E6%9D%A5%E8%A1%A8%E8%BE%BE%E5%AE%83%E3%80%82/"/>
    <id>http://yoursite.com/2020/11/13/专业知识是一种重要的知识资产，但是他们很难以详细，形式化和完整的方式来表达它。/</id>
    <published>2020-11-13T07:03:50.019Z</published>
    <updated>2020-11-17T00:44:12.700Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>专业知识是一种重要的知识资产，但是他们很难以详细，形式化和完整的方式来表达它。用户需要咨询专家，以确定如何解决特定领域的问题，如企业的科技问题。虽然有大量的数据可用于解决问题，但用户仍然寻求专家的服务和指导.</p><p>之前的专家检索任务致力于发现领域性的专家.自[2]提出专家检索任务以来,以文本为中心的专家检索方式快速发展.[5]通过应用概率排名原理推导了两个生成模型系列。 还提出了概率主题来同时模拟专业知识和专家的主题分布。xx在由人员和检索到的最高文献组成的特定主题的专家图中，对多步相关概率分布进行建模模型</p><p>There has been much research on generative probabilistic mod-<br>els for expert retrieval [21, 49]. Such models have been categorized in candidate generation models [13], topic generation models [4, 5] and proximity-based variants [5, 54]. Of special relevance to us are the unsupervised profile-centric (Model 1) and document-centric (Model 2) models of Balog et al. [4], which focus on raw textual evidence without incorporating collection-specific information (e.g., query modeling, document importance or document structure). Supervised discriminative models [23, 47, 60] are preferred when query-candidate relevance pairs are available for training. Unlike their generative counterparts these models have no issue combining complex and heterogeneous features (e.g., link-based features, document importance features, etc.); they resemble Learning to Rank (L2R) methods for document retrieval [6, 35]. However, a lack of training data may greatly hinder their applicability [6, p. 179]. Beyond unsupervised generative and supervised discriminative approaches, there are graph-based approaches based on random walks [55] and voting-based approaches based on data fusion [36]. De- martini et al. [19] propose a vector space-based method for the entity ranking task; their framework extends vector spaces operating on documents to entities. See [6] for a survey on the topic.</p><p>早期的专家检索系统通常被称为专家定位器和专业知识管理系统[38]。 这些数据库系统通常依靠人们根据一组预定义的主题对自己的专业知识进行自我评估[39]，众所周知这会产生不可靠的结果[7]。随着P @ NOPTIC系统[15]的引入，以及后来的TREC Enterprise跟踪[61]的引入，对自动化专业技术配置文件方法的研究兴趣日益浓厚。 区分基于个人资料的方法（可创建候选人知识的文本表示）和基于文档的方法（将候选人表示为文档的加权组合）之间的区别非常有用。 后者通常在排名方面表现更好，而前者则效率更高，因为它避免了检索与查询有关的所有文档[6，p。 221]。</p><p>关于生成概率模型的专家检索已有很多研究[21，49]。 此类模型已分类为候选生成模型[13]，主题生成模型[4、5]和基于接近度的变体[5、54]。 与我们特别相关的是Balog等人的无监督的以档案为中心的模型（模型1）和以文件为中心的模型（模型2）。 [4]，其重点是原始文本证据，而不包含特定于集合的信息（例如查询建模，文档重要性或文档结构）。 </p><p> 除了无监督的生成方法和有监督的区分方法之外，还有基于图的方法基于随机游走[55]和基于投票的方法基于数据融合[36]。 De-martini等。 文献[19]提出了一种基于向量空间的实体排名方法。 它们的框架将对文档进行操作的向量空间扩展到实体。 有关该主题的调查，请参见[6]。</p><p>在 TREC 2005企业跟踪项目启动专家检索任务后[14] ，提出了一系列有监督和无监督的任务算法，可分为有监督算法和无监督算法。监督算法包括基于相关性的专家检索学习算法[18] ，寻找专家学习[52] 。与我们特别相关的是无监督算法。最著名的非监督模型是以概要为中心(Model 1)和以文档为中心(Model 2)的专家查找模型[4,8] ，这些模型专注于原始文本证据，而没有包含特定于集合的信息，例如查询建模、文档重要性或文档结构。模型1和模型2的专家发现算法都是语言再评估模型，它们通过计算候选人在某一特定主题上拥有专业知识的概率来区分彼此。其他无监督的模型包括: 基于线程的模型，在社交媒体环境中进行专家发现; 在博客文档环境中发现博客作者为专家的语言模型; 在无监督的情况下学习分布式单词表示的浅对数线性回归模型，专家发现任务的候选人发现框架和话题生成框架; 以及发现专家组的语言模型，旨在检索给定话题的专家组排名列表。</p><p>向知识经济和信息经济的过渡[1]极大地依赖了认知能力[50]。 对于雇主来说，促进信息交流和促进合作至关重要[17]。 过去，组织会为其成员建立专用数据库系统以维护个人资料[7]。 但是，这些系统要求员工积极主动。 此外，众所周知，自我评估有悖于实际情况[10，32]，文档收集在实践中很快变得不可行，无法进行手动管理。 因此，人们对构建专家档案[7，61]和从组织的异构文档存储库中检索专家的自动化方法[15]产生了浓厚的兴趣。 专家发现（也称为专业知识检索或专家搜索）解决了具有适当技能和知识的寻找合适人员的任务[6]。 它试图提供问题的答案</p><p>语言模型利用词语之间的语义相似性[53]。(2)随着可用数据量的增加，显然需要比平滑的最大似然语言模型具有更强的学习能力的更强大的方法[63]。(3)近十年来，引进了专家检索的监督方法[23,47]。然而，数据提供的加速有一个主要缺点，就监督方法而言，人工注释工作需要保持类似的增长顺序。这就需要进一步开发无监督的方法。(4)在一些专家知识检索方法中，为集合中的每个文档建立了语言模型。这些方法缺乏针对大型文档集合的高效查询能力，因为每个查询项都需要与每个文档[6]匹配。我们提出的解决方案强调无监督模型构造、高效的查询能力以及查询词和候选专家之间的语义匹配</p><p>专家发现(和剖析)。专家搜索系统不同于传统的搜索引擎[18,19] ，因为它们解决的问题是找到合适的人(与正确的文件相反)具有适当的技能和知识，通过用户查询指定。初步尝试在改造传统的搜索引擎，以这项任务与贫穷的结果[7]。要解决的关键问题是如何表示个别专家的知识[20,21,22,9]。在这些尝试中，最受关注和成功的是侧面模型[21,9]和侧面文档模型[23,20,7]。第一种方法是根据每个候选人关联的文档为他们创建一个配置文件，然后通过输入查询和他们的配置文件之间的匹配对专家进行排名。第二种方法是首先检索与输入查询相关的文档，然后根据匹配文档的相关性得分对专家进行排序。这两种方法的结合最近显示出可以进一步提高可实现的性能[24,9] ，我们将在下面进一步讨论</p><p>文献中提到的大多数解决方案都是无监督的[23,20,21,22,9] ，因为它们在部署模型时不需要任何培训数据。还提出了有监督的 方法 [25,26] ，但它们的应用通常被限制在可用于训练查询专家对的数据集合[27,28]。这显然是一个限制，实际上导致研究人员主要集中在无监督的方法</p><p>Van Gysel等人最近提出了一种最新的学术界专家发现系统。 [9]。 它采用最初用于产品搜索[10]的无监督基于神经的检索算法[30]的集合，以适应专家通过对数线性模型从上下文中寻找上下文的对数模型，该模型从以 手头的数据集。 在查询时，首先通过将用户查询映射到专家档案的相同潜在空间中，然后通过检索其档案与查询之间具有最高点积的专家来计算专家的检索。 在讨论这种方法与我们的方法之间的区别之前，我们需要回顾一下有关我们将在解决方案中使用的主要模块的技术知识</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h3&gt;&lt;p&gt;专业知识是一种重要的知识资产，但是他们很难以详细，形式化和完
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/11/09/ExF/"/>
    <id>http://yoursite.com/2020/11/09/ExF/</id>
    <published>2020-11-09T02:13:54.327Z</published>
    <updated>2020-11-10T06:56:56.530Z</updated>
    
    <content type="html"><![CDATA[<p>问题1.</p><p>​    基于具体问题的(长文本的专家检索)目前没有很好的解决办法.</p><p>问题2.</p><p>​    专家学术文本语义表示</p><p>问题3.</p><p>​    存粹的基于语义表示的文本检索丢失了文本与作者之间的关系信息.</p><p>Expert  search  aims  to  find  and  rank  experts based  on  a  user’s  query. Precise expert search is a detailed description of the query to obtain relevant experts. Most of the previous expert search systems are based on keyword searches and cannot accurately locate relevant experts. We use different depth semantic models and combine the relationship between experts and texts to conduct expert search through voting models.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;问题1.&lt;/p&gt;
&lt;p&gt;​    基于具体问题的(长文本的专家检索)目前没有很好的解决办法.&lt;/p&gt;
&lt;p&gt;问题2.&lt;/p&gt;
&lt;p&gt;​    专家学术文本语义表示&lt;/p&gt;
&lt;p&gt;问题3.&lt;/p&gt;
&lt;p&gt;​    存粹的基于语义表示的文本检索丢失了文本与作者之间的关系信息.&lt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/11/02/%E5%85%AC%E5%BC%8F/"/>
    <id>http://yoursite.com/2020/11/02/公式/</id>
    <published>2020-11-02T06:37:04.214Z</published>
    <updated>2020-11-08T12:11:29.555Z</updated>
    
    <content type="html"><![CDATA[<p>公式</p><script type="math/tex; mode=display">p(c a \mid q)=\frac{p(q \mid c a) p(c a)}{p(q)}</script><script type="math/tex; mode=display">\operatorname{Score}_{R R}(a, q)=\sum_{d: a \in d, d \in R(q)} \frac{1}{\operatorname{rank}(d, q)}</script><script type="math/tex; mode=display">s\left(c a_{i}\right)^{n+1}=s\left(c a_{i}\right)^{n}+\sum_{c a_{j} \in U} \sum_{e \in R_{j i}} w\left(\left(v_{j}, v_{i}\right), e\right) s\left(c a_{j}\right)^{n}</script><script type="math/tex; mode=display">v = Transformer(d)</script><p>$W(e) = rank(indexOfAuthor)$</p><script type="math/tex; mode=display">Dis(d_A, d_B) =   \prod w(e) \ e \in E</script><script type="math/tex; mode=display">Socre = \theta ^{Dis(d_A, d_B) - 1}</script><p>在图中有 $\forall d\in D$ 我们有d的邻居 $adj(d)$, 再有$ \forall a \in adj(d) \subset A$ 可以得到 $d^+ \in  adj(a) \subset D$. </p><script type="math/tex; mode=display">\mathcal{L}(A, B)=y^{*}\|f(A)-f(B)\|^{2}+\left(1-y^{*}\right) \max \left(0, m^{2}-\|f(A)-f(B)\|^{2}\right)</script><script type="math/tex; mode=display">\mathcal{L}(Q, P, N)=\max \left(0,\|f(Q)-f(P)\|^{2}-\|f(Q)-f(N)\|^{2}+m\right)</script><p>$ G(D,A,E) $</p><script type="math/tex; mode=display">m\left(q, d^{+}, d^{-}\right)=c-\lambda \cdot\left(\mathrm{BM} 25\left(q, d^{+}\right)-\mathrm{BM} 25\left(q, d^{-}\right)\right)</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;公式&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;
p(c a \mid q)=\frac{p(q \mid c a) p(c a)}{p(q)}&lt;/script&gt;&lt;script type=&quot;math/tex; mode=displa
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/10/30/Java%20%20%E5%9F%BA%E7%A1%80/"/>
    <id>http://yoursite.com/2020/10/30/Java  基础/</id>
    <published>2020-10-30T14:33:51.197Z</published>
    <updated>2020-10-31T00:35:19.266Z</updated>
    
    <content type="html"><![CDATA[<p>Java  基础</p><ol><li>hashmap是怎么实现的</li><li>ES内部原理 ES地理位置<a href="https://www.nowcoder.com/jump/super-jump/word?word=排序" target="_blank" rel="noopener">排序</a>底层数据结构</li><li>了解哪些设计模式</li><li>优先级队列原理</li><li>一致性哈希了解吗</li><li>java 字节流 字符流</li><li>java 线程创建方式</li><li>ACID</li><li>java 中数组和<a href>链表</a>的区别，各自优势 </li><li>如何设计拥有高效的随机读取能力的的<a href>链表</a>（跳表） </li><li>设计跳表，跳表插入开销，跳表随机读取过程 </li><li>java 泛型理解 concurrentHashMap put流程</li><li>hashmap ，concurrentHashMap（put过程，怎么解决冲突的，sizeCtl 等关键成员变量的作用） </li><li>volatile </li><li>spring IOC 过程 </li><li>如何自己设计IOC框架</li><li>设计一个高并发系统</li><li>Java 泛型的理解，hashmap</li><li>lambda都用来干什么了</li><li>对java中锁的理解</li><li>悲观锁 乐观锁</li><li>对CAS的理解，java中的CAS，如何不用unsafe实现CAS</li><li>spring ioc过程，循环依赖怎么解决的</li><li>spring aop, jdk 动态<em>*</em>和 cglib稍微说说了下</li><li>对volatile的理解</li><li>详细的说一下concurrentHashMap</li><li>知道LSM吗</li><li>LSM 在cassandra 存储模型中的体现</li><li>jvm内存模型jvm 内存模型</li><li>volatile，</li><li>java的arraylist linklist有什么区别，什么数据结构，hashmap是啥结构，线程安全不？如果要线程安全怎么办？答con-hashmap，怎么实现的，还有没有优化！</li><li>java的io，nio，bio等啥区别</li><li>还有一个cas了解吗</li><li>问java和c++区别</li><li>java的垃圾回收</li><li>面向对象的特性</li><li>java的线程池说一下</li><li>java的GC，说一下，</li><li>标记清除和标记整理的区别。</li><li>说一下，JVM那些东西</li><li>linux用过吧，常用命令，解压缩那些参数代表啥</li><li>java的hashmap,数据结构，怎么扩容</li><li>arraylist和linkedlist区别</li><li>11.java有内存泄漏吗？<br>12.说一下内存泄漏的原因并举一个例子吧</li><li>什么时候不用分代收集的方式 </li><li>软引用、弱引用、强引用</li><li>软引用和弱引用具体区别 </li><li>类加载机制是什么 </li><li>结合tomcat说一下双亲委派 </li><li>并发里面的atomic底层 </li><li>cas会遇到什么问题（aba），除了aba问题呢？ </li><li>了解rpc吗？（学过，只知道本地存根、远程存根什么的） </li><li><a href>项目</a>里用到了rpc吧（用到了，具体我不负责，并不了解） </li><li>进程和线程区别 </li><li>进程和进程，线程和线程怎么通信 </li><li>用过juc包吧（提到了线程池和sychronized），线程池常用哪些参数 </li><li>core满了以后会怎么样 </li><li>如果没有设置core这些，不断的有请求，会发生什么 </li><li>说一下stackoverflow和oom的区别（提到了栈帧） </li><li>怎么快速出现一个stackoverflow错误 </li><li>写个java代码，最后到执行的过程是啥（提到了编译） </li><li>4.java有没有内存溢出 5.写一个程序实现内存溢出</li><li>20.Jvm内存区域划分<br> 21.一个对象从进入堆区到死亡的全流程</li><li>29.同步和异步的区别<br>30.非阻塞io和阻塞式io的区别<br>31.http如何保持连接<br>32.如果不用http，如何保持连接<br>33.Volatile 关键字的作用<br>34.Volatile 关键字的实现<br>35.用户态和内核态的区别<br>36.lru了解吗？<br>37.怎么实现lru？<br>38.布隆过滤器了解吗？</li><li>object类clone和hash关系</li><li>用过什么容器<br>  hashmap1.7 和1.8区别</li><li><p>了解过jdk什么<br>  用过什么容器</p><pre><code>hashmap[源码]()</code></pre><p>  为啥用<a href>红黑树</a>不用其它树<br>hashcode怎么对应数组的序号<br>  流和nio区别 优缺点<br>jvm内存结构 新老代什么的 为啥不用计数法用可达性分析啥的</p><p>4.如何把exception提取出来</p><p>3.git操作，指令<br>4.jvm相关</p><p>3.error和ecxeption说一下<br>4.如何把exception提取出来</p></li></ol><p>8.arraylist linkedlist区别<br>  9.arraylist如何扩容<br>10.hashmap怎么解决冲突<br>  11.integer a=1和new integer和integer.valueof是否==<br>12.值改为200还一样吗 （不一样）<br>  13.jvm内存结构<br>    14.静态变量在哪个部分存<br>  15.mysql索引结构<br>    16.聚集索引和二级索引怎么存 区别是什么<br>  17.二级索引里存的key是什么</p><p>\11. java单例模式一套</p><p>\12. java多线程原子锁，cas机制，aba问题</p><p>\13. 缓存置换lru实现</p><ol><li>对线程安全的理解</li><li>乐观锁和悲观锁的区别？</li><li>这两种锁在Java和MySQL分别是怎么实现的？</li><li>事务有哪些特性？</li><li>怎么理解原子性？</li><li>HashMap为什么不是线程安全的？</li><li>怎么让HashMap变得线程安全？</li><li>jdk1.8对ConcurrentHashMap做了哪些优化？</li><li>线程池了解吗？讲讲那个函数有几个形参，分别是什么，最重要的是什么，corepoolSize和maxpoolsize区别，如果来了一个线程，过程是什么。</li></ol><p>java线程池了解吗，看过<a href="https://www.nowcoder.com/jump/super-jump/word?word=源码" target="_blank" rel="noopener">源码</a>吗？说一说</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Java  基础&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;hashmap是怎么实现的&lt;/li&gt;
&lt;li&gt;ES内部原理 ES地理位置&lt;a href=&quot;https://www.nowcoder.com/jump/super-jump/word?word=排序&quot; target=&quot;_blank&quot;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/10/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    <id>http://yoursite.com/2020/10/30/操作系统/</id>
    <published>2020-10-30T14:33:13.598Z</published>
    <updated>2020-10-31T00:34:09.632Z</updated>
    
    <content type="html"><![CDATA[<p>操作系统</p><ol><li><p>IO高并发如何实现？</p></li><li><p>线程与进程的区别？线程和进程的区别</p></li><li><p>为什么进程的切换开销比线程大？</p><p>进程切换开销为什么比线程大.</p></li><li><p>信号量机制；(整型、记录型、AND型、信号量集)</p></li><li><p>锁机制；(互斥锁、自旋锁</p></li><li><p>cache一致性；</p></li><li><p>虚拟内存与物理内存的区别；</p></li><li><p>什么是死锁？</p></li><li><p>线程与进程的区别？</p></li><li><p>进程什么时候由用户态转化为内核态？(系统调用、中断、异常)</p></li><li><p>内核态与用户态的区别？(安全性)</p></li><li><p>epoll有啥好处</p><p>共享fd, 避免了从用户态-&gt;内核太中的复制.</p><p>本来就是异步</p></li><li><p>进程之间可以通过指针共享内存吗</p></li><li><p>同步异步，阻塞非阻塞IO区别。</p><p>同步, 异步的区别就是我请求之后是等到</p></li><li><p>epoll/select</p></li><li><p>进程间通信方式</p><p>共享内存, 管道, Socket, 信号.</p></li><li><p>socket，epoll/select</p></li><li><p>进程和线程，同步方式</p></li><li><p>文件系统，node节点</p></li><li><p>软硬链接</p></li><li><p>网络编程epoll/select详细讲</p></li><li><p>乐观锁和悲观锁</p><p>乐观锁就是就总是认为没有其他线程来和我进行资源争夺.每次都是再修改数据的时候看看是否已经被修改.</p><p>悲观锁总是认为会由其他线程进行资源的争夺,悲观锁一开始就要对静态区上锁.</p></li><li><p>自旋锁和互斥锁区别</p><p>自旋锁, -&gt; 不丢掉当前cpu的使用权,就相当于原地等待.</p><p>互斥锁,</p></li><li><p>hash冲突</p></li><li><p>socket编程哪些函数，都写出来</p><p>accpet, bind recv. send</p></li><li><p>select什么时候比epoll好</p></li><li><p>有没有了解过协程？说下协程和线程的区别？用过哪些linux命令？如查看内存使用、网络情况？ </p></li><li><p>学过操作系统吧，死锁的四个条件是啥</p></li><li><p>\6. linux内存磁盘转化</p><p>\7. linux线程状态</p><p>\8. linux页表结构</p></li></ol><p>\13. pthread</p><p>\9. 内核怎么处理线程（初始化，加锁）</p><ol><li><p>cpu分配时间片<a href>算法</a></p></li><li><p>如何查看内存空间？如何查看磁盘空间？(free; df -h)</p></li><li><p>如何查看进程？(ps aux)</p></li><li><p>一个文件”ip.txt”，有两个字段ip(第一列)和访问时间(第二列)，找出访问次数最多的</p></li><li><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk '&#123;ips[$1]++;&#125; END &#123;for(ip in ips) printf("%s\t%d\n", ip, ips[ip]);&#125;' ip.txt | sort -n -k 2 -r | head -n 1</span><br></pre></td></tr></table></figure></li><li><p>Linux的基本命令，netstat，top等</p></li><li><p>linux IPC</p></li><li><p>写脚本杀死指定名称的进程；</p></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps aux | grep $&#123;processName&#125; | grep -v grep | awk '&#123;print $2&#125;' | xargs kill -s 9</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;操作系统&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;IO高并发如何实现？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;线程与进程的区别？线程和进程的区别&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;为什么进程的切换开销比线程大？&lt;/p&gt;
&lt;p&gt;进程切换开销为什么比线程大.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/10/30/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    <id>http://yoursite.com/2020/10/30/数据库/</id>
    <published>2020-10-30T14:26:24.844Z</published>
    <updated>2020-10-31T00:31:01.106Z</updated>
    
    <content type="html"><![CDATA[<p>数据库</p><ol><li>索引：是什么？如何实现？</li><li>sql引擎：有哪些？MyISAM和InnoDB的区别？B+树与B树的区别？</li><li>23.介绍B 树<br>24.数据库两种存储引擎的区别<br>25.为什么myisam不支持行锁</li><li>11.Mysql索引的实现<br>12.使用b 树的理由<br>13.B 树做索引比<a href>红黑树</a>好在哪里？</li><li></li><li>主键索引和二级索引（自建索引）的区别和联系 </li><li>MySQL的引擎有哪些？区别？底层实现？索引？</li><li>B树和B+树的特点和优势B树和B+树区别</li><li>数据库的隔离级别</li><li>MySQL索引结构，问了好几个数据库问题</li><li>数据库了解吗，事务的特性，带来的隔离级别和问题，非关系型数据库用</li><li>数据库的最左匹配原则是啥？怎么用？</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;数据库&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;索引：是什么？如何实现？&lt;/li&gt;
&lt;li&gt;sql引擎：有哪些？MyISAM和InnoDB的区别？B+树与B树的区别？&lt;/li&gt;
&lt;li&gt;23.介绍B 树&lt;br&gt;24.数据库两种存储引擎的区别&lt;br&gt;25.为什么myisam不支持行锁&lt;/l
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/10/30/%E7%BD%91%E7%BB%9C/"/>
    <id>http://yoursite.com/2020/10/30/网络/</id>
    <published>2020-10-30T14:25:08.820Z</published>
    <updated>2020-10-31T00:32:50.253Z</updated>
    
    <content type="html"><![CDATA[<ol><li>web页面请求过程：在浏览器中输入一个网址到获得一个页面，这个过程中有用到哪些协议？(DNS + HTTP + TCP + IP + ARP；这个问题基本上可以将所有的网络协议串起来，是一个很好的问题，值得注意)</li><li>HTTP报文格式；</li><li>访问一个网址和提交一段代码到网上有何区别？(GET和POST的区别)</li><li>TCP四次握手；(需要详细说明)</li><li>拥塞避免机制；</li><li>web页面请求过程 web页面请求过程；</li><li>OSI网络分层模型，TCP/IP网络分层模型？(7层；5层)</li><li>为什么TCP/IP去除了表示层和会话层？(没必要搞那么复杂)</li><li>TCP与UDP的区别；(TCP实现了可靠传输；UDP不保证可靠传输；)</li><li>TCP如何实现可靠传输；(超时重传)</li><li>TCP的发送窗口大小如何确定？(拥塞避免)</li><li>DNS的查询方式；(递归和迭代)</li><li>HTTP与HTTPS的区别；(加密与否)</li><li>HTTPS如何实现加密传输；(非对称加密机制)</li><li>HTTPS的认证过程；</li><li>TTL指的是什么？(Time To Live，生存时间，也是跳数限制)</li><li>ARP协议；</li><li>TCP、UDP的区别；</li><li>TCP如何实现可靠连接；</li><li>socket编程；</li><li>TCP连接断开时为什么需要一个timewait状态？</li><li>A向B发送一个消息，如何保证B正确收到？(可靠传输，超时重传)</li><li>TCP和UDP</li><li>TCP拥塞控制，流量控制。</li><li>TCP三次握手四次挥手，状态转移。</li><li>TIME_WAIT状态知道吗，作用是什么</li><li>浏览器输入url发生了什么（经典问题）<br>由此深入问了相关的问题, TCP 握手, 挥手, DNS解析过程, hosts, ARP协议</li><li>HTTPS怎么工作的, HTTPS建立连接的流程<br>HTTPS中间人攻击问题</li><li>TCP抓包会吗</li><li>TCP粘包</li><li>UDP怎么实现可靠传输</li><li>http中的get和post有什么区别？post是怎么样放在body中的？http1和2的区别，http和https的</li><li>TCP四次挥手的CLOSE_WAIT状态在哪端</li><li>简单说一下，tcp，udp异同点；</li><li>区别在哪，如果我要做一款聊天软件，用到什么协议，为什么？</li><li>如果tcp还不够安全怎么办？</li><li>了解计算机网络协议嘛？说说运输层的协议，答出tcp和udp,接着问异同点，tcp为什么可靠，问到三次握手和四次挥手，为什么需要四次挥手，Tcp的拥塞控制四个核心<a href="https://www.nowcoder.com/jump/super-jump/word?word=算法" target="_blank" rel="noopener">算法</a>是什么。</li><li>http与https有啥区别？https是怎么做到安全的？ </li><li>说一下tcp三次握手和四次挥手 </li><li>http和https区别 </li><li><p>http头部都有哪些信息 </p></li><li><p>网络可靠传输</p></li></ol><p>\2. tcp报文结构</p><p>\3. 网络传输模型</p><p>\4. 拥塞机制</p><p>\5. 流量控制</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;web页面请求过程：在浏览器中输入一个网址到获得一个页面，这个过程中有用到哪些协议？(DNS + HTTP + TCP + IP + ARP；这个问题基本上可以将所有的网络协议串起来，是一个很好的问题，值得注意)&lt;/li&gt;
&lt;li&gt;HTTP报文格式；&lt;/li&gt;

      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/10/28/PDD_algorithms/"/>
    <id>http://yoursite.com/2020/10/28/PDD_algorithms/</id>
    <published>2020-10-28T11:49:17.116Z</published>
    <updated>2020-10-29T14:24:59.466Z</updated>
    
    <content type="html"><![CDATA[<ol><li>如何实现topK；(堆)</li><li>实现跳表</li><li><a href>手撕</a>两个栈实现一个队列；</li><li><a href>手撕</a>数据流的中位数；(两个堆)</li><li><strong><a href>手撕</a><a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>的直径；(递归)</strong></li><li>双向<a href="https://www.nowcoder.com/jump/super-jump/word?word=链表" target="_blank" rel="noopener">链表</a>的插入；</li><li>手撕快速<a href="https://www.nowcoder.com/jump/super-jump/word?word=排序" target="_blank" rel="noopener">排序</a>；</li><li><a href>手撕</a>字符串中回文子串的数目；(dp)</li><li><a href>手撕</a>给你一个字符串，返回所有它能表示的IP地址；(回溯)</li><li>说说堆<a href="https://www.nowcoder.com/jump/super-jump/word?word=排序" target="_blank" rel="noopener">排序</a>的过程，建堆的时间复杂度是多少；(建堆+调整；O(n))</li><li>重拍数组中的元素，使之组合起来能得到一个最大的数字；(重新定义比较器)</li><li>剪绳子；(dp或者贪心)</li><li>找出两个序列中的最长公共子序列；(dp)</li><li>两个并发线程T1和T2，分别只能打印A和B，要求写一段代码，可以一直打印序列”AABBAABB…”(不会)</li><li><a href>手撕：</a><a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>的后序遍历，递归和非递归</li><li><a href="https://www.nowcoder.com/jump/super-jump/word?word=算法" target="_blank" rel="noopener">算法</a>：手撕冒泡<a href="https://www.nowcoder.com/jump/super-jump/word?word=排序" target="_blank" rel="noopener">排序</a>，并分析时间复杂度；</li><li>最长回文子串；</li><li>快排</li><li>编程题，<a href="https://www.nowcoder.com/jump/super-jump/word?word=链表" target="_blank" rel="noopener">链表</a>反转，我用了迭代写法</li><li>合并两个有序数组，</li><li>trie树（一个字典，一个文本，找出字典中所有出现在文本中的词）</li><li>给一个数组，求连续子数组和为k的倍数的所有子数组</li><li>一个有序数组[0,0,0,1,1,1,1,1,1,3,3,3,3,,3]，给一个k，找出k的左边界</li><li>编程题，<a href="https://www.nowcoder.com/jump/super-jump/word?word=链表" target="_blank" rel="noopener">链表</a>反转</li><li>代码题，快排（最坏情况复杂度多少，怎么优化）</li><li>代码题，从数组中构建平衡查找<a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a></li><li>代码题，上面题目的数组每个数都有一个频率表示会被访问多少次，如何构建<a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>使得时间复杂度最低</li><li>代码题，矩阵中最长递增子序列（<a href="https://www.nowcoder.com/jump/super-jump/word?word=leetcode" target="_blank" rel="noopener">leetcode</a> 329）</li><li>数组中第k大的数</li><li>编程题，LRU如何实现</li><li>编程题，找第k大的数</li><li>编程题，N的阶乘后面有几个零</li><li>编程题，求0 - N-1的全排列输出</li><li>编程题，LEETCODE 518</li><li>编程题，数轴上某些位置有点，每个点都有一个速度和方向（左或右），在零时刻他们开始运动，求第一次有两点相碰的时间？如果只有相反方向的相碰才算，如何求解？</li><li>编程题，有一个记录一段程序中每个函数开始调用和结束调用时刻的log，可能存在嵌套函数。根据输出log找耗时最长的几个函数（嵌套函数的耗时不算</li><li>贪心和<a href="https://www.nowcoder.com/jump/super-jump/word?word=动态规划" target="_blank" rel="noopener">动态规划</a>的区别</li><li>编程题，<a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>层序遍历</li><li>编程题，<a href="https://www.nowcoder.com/jump/super-jump/word?word=排序" target="_blank" rel="noopener">排序</a>数组做个旋转</li><li>编程题，旋转的<a href="https://www.nowcoder.com/jump/super-jump/word?word=排序" target="_blank" rel="noopener">排序</a>数组中找最小值</li><li>场景题，给一堆log，每条记录都是由（用户id，访问时间，访问ip）组成的条目。现在要你判断访问的ip中哪些是办公ip，哪些是商家店铺ip，哪些是家庭ip等。</li><li><a href="https://www.nowcoder.com/jump/super-jump/word?word=算法题" target="_blank" rel="noopener">算法题</a>1:给定x，求他能不能和另一个数相乘得到m个1</li><li><a href="https://www.nowcoder.com/jump/super-jump/word?word=算法题" target="_blank" rel="noopener">算法题</a>2:给五张扑克牌，问他们能不能组成一个新顺子</li><li>蛇形数组，解法1，解法2</li><li>一段字符串的句子，由多个单词组成，返回颠倒后的句子（单词不颠倒）</li><li>找到最长回文子串</li><li>搜索问题：有一些物品和其出现的次数。写一个随机函数，随机返回一个物品，使得返回概率与其出现的次数成正比。</li><li>旋转数组找目标值</li><li>给定日期，channel，曝光量，求channel=baidu 的累积曝光量超过100w的日期（注意是累积）</li><li><strong><a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>路径最大和</strong></li><li>矩阵从左到右从上到下递增（见过？换一题</li><li>判断完全n叉树（自己设计数据结构）两个<a href="https://www.nowcoder.com/jump/super-jump/word?word=排序" target="_blank" rel="noopener">排序</a>数组找到第k个（思路对？换一题</li><li>给定一串点，表示一个多边形，给定一个点，判断点是否在多边形内（跪了</li><li><a href="https://www.nowcoder.com/jump/super-jump/word?word=算法题" target="_blank" rel="noopener">算法题</a>：<a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>最大路径和，</li><li>数字的下一个排列，</li><li>一个<a href="https://www.nowcoder.com/jump/super-jump/word?word=链表" target="_blank" rel="noopener">链表</a>只保存当前<a href="https://www.nowcoder.com/jump/super-jump/word?word=链表" target="_blank" rel="noopener">链表</a>绝对值相等的第一个元素</li><li><a href="https://www.nowcoder.com/jump/super-jump/word?word=算法题" target="_blank" rel="noopener">算法题</a>，找出最大覆盖字符串的字符串集合</li><li>一根绳子，随意取2个点剪断，问这三条边能构成三角形概率</li><li>01矩阵，找出最大的由1构成的正方形</li><li>求给定<a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>，求其中距离最远的两个节点的距离值</li><li>给定一个<a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>以及<a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>中的部分节点，如何找出这些节点的最低公共祖先</li><li>写一个<a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>的中序遍历的迭代器（刚开始写的类，后面让用类模板）</li><li>将中序遍历改成非迭代</li><li>大数相减（两个字符串相减）</li><li>让你实现一个O(1)获取中位数的，怎么实现。</li><li>给定一个数组，找出最长子序列的长度，子序列满足：递增-递减-递增波动变化</li><li>算法题：消消乐，给定一个数字序列，将连续的数字全部消除，比如1,2,3,3,3,2,3，返回1,2,2,3（用栈做）</li><li>消消乐升级，只要有相同连续数字，全部消除，如1,2,3,3,3,2,3，返回1,3（用栈做，上一题代码上再加判断）</li><li>判断完全n叉树（自己设计数据结构）</li><li>两个栈实现队列</li><li>交错字符串 变种</li><li>二数之和变种</li><li>三数之和变种</li><li>判断整数是否为二的幂次方</li><li>手写堆<a href="https://www.nowcoder.com/jump/super-jump/word?word=排序" target="_blank" rel="noopener">排序</a></li><li>给我一张纸，画了一个九方格，都填了数字，给一个MN矩阵，从1开始逆时针打印这MN个数，</li><li>做题：数组A，2*n个元素，n个奇数、n个偶数，设计一个<a href="https://www.nowcoder.com/jump/super-jump/word?word=算法" target="_blank" rel="noopener">算法</a>，使得数组奇数下标位置放置的都是奇数</li><li>已知一个正整数组，一k，任取两个数，问两个数之和大于k的概率，手写。</li><li><a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>从左到右遍历叶子结点，输出从根节点到叶子节点的路径</li><li><a href>手撕：</a>三数之和(leetcode 15)</li><li>两个队列实现一个栈；</li><li>最长回文子串；(dp)</li><li>查找有重复元素的非降序列中第一次出现的数字；(变形的二分查找)</li><li>堆排序，并分析时间复杂度；</li><li>链表中环的入口节点，并解释原因；</li><li>数组中连续子数组的最大和；</li><li>字符串转化为数字；(注意细节处理)</li><li>根据身高重建队列</li></ol><p>这道题属于颜色填充问题：把二维空间按照颜色/属性的不同划分成不同的区域，统计/标记这些区域。<br>这种题型用dfs解决即可，方法都很类似。</p><p>类似题还有：</p><ol><li>图像渲染</li><li>岛屿的周长</li><li>被围绕的区域 1020.飞地的数量 （这两题基本一样的）</li><li>岛屿数量</li><li>统计封闭岛屿的数目 130题与200题的组合</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;如何实现topK；(堆)&lt;/li&gt;
&lt;li&gt;实现跳表&lt;/li&gt;
&lt;li&gt;&lt;a href&gt;手撕&lt;/a&gt;两个栈实现一个队列；&lt;/li&gt;
&lt;li&gt;&lt;a href&gt;手撕&lt;/a&gt;数据流的中位数；(两个堆)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href&gt;手撕&lt;/a&gt;&lt;a
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>windows protobuf  .proto文件编译器</title>
    <link href="http://yoursite.com/2020/10/28/windows%20protobuf/"/>
    <id>http://yoursite.com/2020/10/28/windows protobuf/</id>
    <published>2020-10-28T09:57:15.000Z</published>
    <updated>2020-11-27T13:33:17.471Z</updated>
    
    <content type="html"><![CDATA[<h3 id="windows-protobuf-proto文件编译器"><a href="#windows-protobuf-proto文件编译器" class="headerlink" title="windows protobuf  .proto文件编译器"></a>windows protobuf  .proto文件编译器</h3><p><a href="https://repo1.maven.org/maven2/com/google/protobuf/protoc/" target="_blank" rel="noopener">com/google/protobuf/protoc)</a></p><p>选择你对应的编译器版本,这里我选择的是3.6.0版本的</p><p><img src="1.png" alt="png"></p><p>下载protoc-3.6.0-windows-x86_64.exe </p><p>cmd 进入到你的protoc-3.6.0-windows-x86_64.exe文件的目录</p><p>执行 protoc.exe path/to/your/proto/file —java_out=OUTPUT_DIR</p><p><img src="2.png" alt="png"></p><p><img src="3.png" alt="png"></p><p>生成成功.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;windows-protobuf-proto文件编译器&quot;&gt;&lt;a href=&quot;#windows-protobuf-proto文件编译器&quot; class=&quot;headerlink&quot; title=&quot;windows protobuf  .proto文件编译器&quot;&gt;&lt;/a&gt;win
      
    
    </summary>
    
    
      <category term="tool" scheme="http://yoursite.com/categories/tool/"/>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/10/18/GC%E7%AE%97%E6%B3%95/"/>
    <id>http://yoursite.com/2020/10/18/GC算法/</id>
    <published>2020-10-18T03:09:25.932Z</published>
    <updated>2020-10-31T00:35:57.167Z</updated>
    
    <content type="html"><![CDATA[<h3 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a>JVM</h3><h4 id="内存模型"><a href="#内存模型" class="headerlink" title="内存模型"></a>内存模型</h4><h4 id="GC"><a href="#GC" class="headerlink" title="GC"></a>GC</h4><p>Gc全流程<br>JVM中的GC机制大体介绍一下，介绍新生代的回收机制，新生代回收的复制和标记清除的优劣；<br>minor gc和full gc<br>怎么判断对象可被回收<br>GC是怎么判断年代的<br>强制young gc会有什么问题？<br>回收过程是怎么样的？<br>有过GC调优的经历么？<br>知道G1么？<br>CMS GC有什么问题？<br>java的内存模型，gc的分代</p><p>gc<a href="https://www.nowcoder.com/jump/super-jump/word?word=算法" target="_blank" rel="noopener">算法</a>，怎么判断对象可被回收</p><p>说一下新生代、老年代用到的<a href>算法</a> </p><p>了解java虚拟机吗？说说垃圾回收，都有哪些<a href="https://www.nowcoder.com/jump/super-jump/word?word=算法" target="_blank" rel="noopener">算法</a>？（如何识别垃圾2种，如何清理垃圾4种），讲讲分代回收的过程双亲委派</p><ol><li><p>Java为什么要设计双亲委派模型？ </p></li><li><p>什么时候需要自定义类加载器？ </p></li><li><p>\10. 操作系统与jvm的不同</p><p>\11. 类加载过程</p><p>\12. 线程怎么去访问jvm里的类信息</p><ol><li>了解java虚拟机吗？说说垃圾回收，都有哪些<a href="https://www.nowcoder.com/jump/super-jump/word?word=算法" target="_blank" rel="noopener">算法</a>？（如何识别垃圾2种，如何清理垃圾4种），讲讲分代回收的过程。</li><li></li></ol></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;JVM&quot;&gt;&lt;a href=&quot;#JVM&quot; class=&quot;headerlink&quot; title=&quot;JVM&quot;&gt;&lt;/a&gt;JVM&lt;/h3&gt;&lt;h4 id=&quot;内存模型&quot;&gt;&lt;a href=&quot;#内存模型&quot; class=&quot;headerlink&quot; title=&quot;内存模型&quot;&gt;&lt;/a&gt;内存模
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/09/30/PDD_redis_QA/"/>
    <id>http://yoursite.com/2020/09/30/PDD_redis_QA/</id>
    <published>2020-09-30T14:09:49.088Z</published>
    <updated>2020-09-30T14:19:33.168Z</updated>
    
    <content type="html"><![CDATA[<p>PDD_redis_QA</p><ol><li><p><a href>redis</a>哪些数据结构</p></li><li><p><a href>redis</a>主从机制了解么？怎么实现的？</p></li><li><p><a href>redis</a>哪些数据结构? zset底层怎么实现的?</p></li><li><p><a href>redis</a>索引结构，有哪些数据结构，怎么持久化</p></li><li><p><a href>redis</a>设计分布式悲观锁</p></li><li><p><a href>redis</a>实现乐观锁</p></li><li><p><a href>redis</a>常用的数据结构有哪几种，在你的<a href>项目</a>中用过哪几种，以及在业务中使用的场景，</p></li><li><p><a href>redis</a>的hash怎么实现的，rehash过程讲一下和Java-HashMap的rehash有什么区别？</p></li><li><p><a href>redis</a>cluster有没有了解过，怎么做到高可用的？</p><p>集群实际上是用来提供分布式数据库的解决方案的.高可用是使用哨兵技术.</p></li><li><p><a href>redis</a>集群和哨兵机制有什么区别？ </p></li><li><p><a href>redis</a>的持久化机制了解吗？</p></li><li><p><a href>redis</a>的hotkey吗？怎么处理的？</p></li><li><p><a href>redis</a>是单线程的吗？单线程为什么还这么快？讲一讲<a href>redis</a>的内存模型？</p></li><li><p><a href>redis</a>用来干什么了 </p></li><li><p><a href>redis</a>用到了什么数据结构 </p></li><li><p><a href>redis</a>预热</p></li><li><p><a href>redis</a>存储数据</p></li><li><p><a href>redis</a>怎么存储数据</p></li><li><p><a href>redis</a>存的key是什么值</p></li><li><p><a href>redis</a>分布式锁</p></li><li><p><a href>redis</a>分布式配置</p></li><li><p><a href>redis</a>持久化</p></li><li><p><a href>redis</a>单线程作用</p></li><li><p><a href>redis</a>存储数据，在工程中的作用</p></li><li><p><a href>redis</a>负载均衡 热键和大键的影响</p></li><li><p><a href>redis</a>主从机制 分片分布式</p></li><li><p><a href>redis</a>如何持久化</p></li><li><p><a href>redis</a>持久化 主进程和子进程</p></li><li><p><a href>redis</a>哨兵中的raft算法</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;PDD_redis_QA&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href&gt;redis&lt;/a&gt;哪些数据结构&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href&gt;redis&lt;/a&gt;主从机制了解么？怎么实现的？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href&gt;redis&lt;/a&gt;哪
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/09/30/PDD/"/>
    <id>http://yoursite.com/2020/09/30/PDD/</id>
    <published>2020-09-30T02:56:07.357Z</published>
    <updated>2020-10-31T00:35:53.058Z</updated>
    
    <content type="html"><![CDATA[<p>PDD</p><p>redis</p><ol><li><p><a href>redis</a>哪些数据结构</p><ol><li>SDS simple synamic string：支持自动动态扩容的字节数组预空间分配</li><li>list ：链表 </li><li><strong>dict ：</strong>使用双哈希表实现的, 支持平滑扩容的字典 </li><li>zskiplist ：附加了后向指针的跳跃表 实现有序集合键. 和集群节点的内部数据结构.</li><li>intset ： 用于存储整数数值集合的自有结构 </li><li>ziplist ：一种实现上类似于TLV, 但比TLV复杂的, 用于存储任意数据的有序序列的数据结构 </li><li>quicklist：一种以ziplist作为结点的双链表结构, 实现的非常不错 </li><li>zipmap ： 一种用于在小规模场合使用的轻量级字典结构 </li></ol></li><li><p><a href>redis</a>主从机制了解么？怎么实现的？</p></li><li><p><a href>redis</a>哪些数据结构? zset底层怎么实现的?</p><p>zset的编码有<strong>ziplist</strong>和<strong>skiplist</strong>两种。<br>底层分别使用<strong>ziplist（压缩链表）</strong>和<strong>skiplist（跳表）</strong>实现。</p><p><img src="C:\Users\leleyi\AppData\Roaming\Typora\typora-user-images\image-20201012194452252.png" alt="image-20201012194452252"></p><blockquote><ol><li>保存的元素少于128个</li><li>保存的所有元素大小都小于64字节</li></ol></blockquote><p>字典的键保存元素的值，字典的值则保存元素的分值；跳跃表节点的 object 属性保存元素的成员，跳跃表节点的 score 属性保存元素的分值。</p></li><li><p><a href>redis</a>索引结构，有哪些数据结构，怎么持久化</p></li><li><p><a href>redis</a>设计分布式悲观锁</p></li><li><p><a href>redis</a>实现乐观锁</p></li><li><p><a href>redis</a>常用的数据结构有哪几种，在你的<a href>项目</a>中用过哪几种，以及在业务中使用的场景，</p></li><li><p><a href>redis</a>的hash怎么实现的，rehash过程讲一下和JavaHashMap的rehash有什么区别？</p></li><li><p><a href>redis</a>cluster有没有了解过，怎么做到高可用的？</p></li><li><p><a href>redis</a>集群和哨兵机制有什么区别？ </p></li><li><p><a href>redis</a>的持久化机制了解吗？</p></li><li><p><a href>redis</a>的hotkey吗？怎么处理的？</p><p>hotkey 就是再某些活动使得有些数据 的访问量特别高, 然后巨大的访问量对让服务器的压力特别大.</p><p>处理方式 1. 使用缓存直接从JVM 中取. 避免到redis服务器上同时出现很大量的请求.</p><p>处理方式 2. 备份hotkey, 使得请求随机到各个redis节点上取获取value.</p></li><li><p><a href>redis</a>是单线程的吗？单线程为什么还这么快？讲一讲<a href>redis</a>的内存模型？</p></li><li><p><a href>redis</a>用来干什么了 </p></li><li><p><a href>redis</a>用到了什么数据结构 </p></li><li><p><a href>redis</a>预热</p></li><li><p><a href>redis</a>存储数据</p></li><li><p><a href>redis</a>怎么存储数据</p></li><li><p><a href>redis</a>存的key是什么值</p></li><li><p><a href>redis</a>分布式锁</p></li><li><p><a href>redis</a>分布式配置</p></li><li><p><a href>redis</a>持久化</p></li><li><p><a href>redis</a>单线程作用</p></li><li><p><a href>redis</a>存储数据，在工程中的作用</p></li><li><p><a href>redis</a>负载均衡 热键和大键的影响</p></li><li><p><a href>redis</a>主从机制 分片分布式</p></li><li><p><a href>redis</a>如何持久化</p><p>RDB AOF 优先考虑AOF持久化.</p><p><strong>RDB</strong> 将数据库状态保存为RDB文件. (SAVE 命令会阻塞服务进程, 不能接受其他请求)   根据用户的设置, 不同的时间, 不同的修改次数.达到条件之后执行BGSAVE</p><p><strong>AOF</strong> 通过保存数据库执行过的命令来记录数据库状态. 首先将命令 追加到aof_buf缓冲区. 然后通过不同的用户配置在不同的情况进行 将aof_buf中的内容写入AOF, 并且不同情况的同步时间也不同.(这里的同步时指, 将说数据写入缓存, 然后同步到磁盘.(这由可以由操作系统来完成, fsync, fdatasync))— 安全性上 aways肯定时最安全的,出现问题丢失一个事件的数据, everysec丢失一秒的数据. no 取决于操作系统何时同步. 随着时间的,命令越来越多, 所以AOF 需要重写, 更具数据库的内容来重新创建一个AOF文件.</p><p>AOF 子进程运行,增加一个重写缓冲区就ok了.</p></li><li><p><a href>redis</a>持久化 主进程和子进程</p></li><li><p><a href>redis</a>哨兵中的raft算法</p></li><li><p><a href>redis</a>Redis和LevelDB的区别</p></li><li><p><a href>redis</a>说一下Raft和Paxos协议的区别</p></li><li><p><a href>redis</a>描述一下Redis中的哨兵机制，主从切换具体是如何实现的</p></li><li><p><a href>redis</a>当哈希环出现“数据倾斜” 该如何解决</p></li><li><p><a href>redis</a>说一下Redis Cloud的设计与实现 </p></li><li><p><a href>redis</a>Redis和LevelDB的区别</p></li><li><p><a href>redis</a>是单线程了吗？有什么好处</p></li><li><p><a href>redis</a>持久化了解不,你们线上怎么用的</p></li><li><p><a href>redis</a>分布式锁如何玩？超时时间如何设置 </p></li><li><p><a href>redis</a>zk的监听原理，你来实现你怎么做 </p></li><li><p><a href>redis</a>Redis 集群，生产环境Redis 如何做数据迁移</p></li><li><p><a href>redis</a>Redis 怎么保证不丢数据，能不能保证严格意义的一定不会丢</p></li><li><p><a href>redis</a>怎么处理事务的，如果是Redis集群数据怎么存。</p></li></ol><p>手撕代码：</p><ol><li>实现跳表</li><li>如何实现topK；(堆)</li><li><a href>手撕</a>两个栈实现一个队列；</li><li><a href>手撕</a>数据流的中位数；(两个堆)</li><li><strong><a href>手撕</a><a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>的直径；(递归)</strong></li><li>双向<a href="https://www.nowcoder.com/jump/super-jump/word?word=链表" target="_blank" rel="noopener">链表</a>的插入；</li><li>手撕快速<a href="https://www.nowcoder.com/jump/super-jump/word?word=排序" target="_blank" rel="noopener">排序</a>；</li><li><a href>手撕</a>字符串中回文子串的数目；(dp)</li><li><a href>手撕</a>给你一个字符串，返回所有它能表示的IP地址；(回溯)</li><li>说说堆<a href="https://www.nowcoder.com/jump/super-jump/word?word=排序" target="_blank" rel="noopener">排序</a>的过程，建堆的时间复杂度是多少；(建堆+调整；O(n))</li><li>重拍数组中的元素，使之组合起来能得到一个最大的数字；(重新定义比较器)</li><li>剪绳子；(dp或者贪心)</li><li>找出两个序列中的最长公共子序列；(dp)</li><li>两个并发线程T1和T2，分别只能打印A和B，要求写一段代码，可以一直打印序列”AABBAABB…”(不会)</li><li><a href>手撕：</a><a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>的后序遍历，递归和非递归</li><li><a href="https://www.nowcoder.com/jump/super-jump/word?word=算法" target="_blank" rel="noopener">算法</a>：手撕冒泡<a href="https://www.nowcoder.com/jump/super-jump/word?word=排序" target="_blank" rel="noopener">排序</a>，并分析时间复杂度；</li><li>最长回文子串；</li><li>快排</li><li>编程题，<a href="https://www.nowcoder.com/jump/super-jump/word?word=链表" target="_blank" rel="noopener">链表</a>反转，我用了迭代写法</li><li>合并两个有序数组，</li><li>trie树（一个字典，一个文本，找出字典中所有出现在文本中的词）</li><li>给一个数组，求连续子数组和为k的倍数的所有子数组</li><li>一个有序数组[0,0,0,1,1,1,1,1,1,3,3,3,3,,3]，给一个k，找出k的左边界</li><li>编程题，<a href="https://www.nowcoder.com/jump/super-jump/word?word=链表" target="_blank" rel="noopener">链表</a>反转</li><li>代码题，快排（最坏情况复杂度多少，怎么优化）</li><li>代码题，从数组中构建平衡查找<a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a></li><li>代码题，上面题目的数组每个数都有一个频率表示会被访问多少次，如何构建<a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>使得时间复杂度最低</li><li>代码题，矩阵中最长递增子序列（<a href="https://www.nowcoder.com/jump/super-jump/word?word=leetcode" target="_blank" rel="noopener">leetcode</a> 329）</li><li>数组中第k大的数</li><li>编程题，LRU如何实现</li><li>编程题，找第k大的数</li><li>编程题，N的阶乘后面有几个零</li><li>编程题，求0 - N-1的全排列输出</li><li>编程题，LEETCODE 518</li><li>编程题，数轴上某些位置有点，每个点都有一个速度和方向（左或右），在零时刻他们开始运动，求第一次有两点相碰的时间？如果只有相反方向的相碰才算，如何求解？</li><li>编程题，有一个记录一段程序中每个函数开始调用和结束调用时刻的log，可能存在嵌套函数。根据输出log找耗时最长的几个函数（嵌套函数的耗时不算</li><li>贪心和<a href="https://www.nowcoder.com/jump/super-jump/word?word=动态规划" target="_blank" rel="noopener">动态规划</a>的区别</li><li>编程题，<a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>层序遍历</li><li>编程题，<a href="https://www.nowcoder.com/jump/super-jump/word?word=排序" target="_blank" rel="noopener">排序</a>数组做个旋转</li><li>编程题，旋转的<a href="https://www.nowcoder.com/jump/super-jump/word?word=排序" target="_blank" rel="noopener">排序</a>数组中找最小值</li><li>场景题，给一堆log，每条记录都是由（用户id，访问时间，访问ip）组成的条目。现在要你判断访问的ip中哪些是办公ip，哪些是商家店铺ip，哪些是家庭ip等。</li><li><a href="https://www.nowcoder.com/jump/super-jump/word?word=算法题" target="_blank" rel="noopener">算法题</a>1:给定x，求他能不能和另一个数相乘得到m个1</li><li><a href="https://www.nowcoder.com/jump/super-jump/word?word=算法题" target="_blank" rel="noopener">算法题</a>2:给五张扑克牌，问他们能不能组成一个新顺子</li><li>蛇形数组，解法1，解法2</li><li>一段字符串的句子，由多个单词组成，返回颠倒后的句子（单词不颠倒）</li><li>找到最长回文子串</li><li>搜索问题：有一些物品和其出现的次数。写一个随机函数，随机返回一个物品，使得返回概率与其出现的次数成正比。</li><li>旋转数组找目标值</li><li>给定学生id，成绩，班级，科目，写sql取每个班每个科目得分top3的学生id</li><li>给定日期，channel，曝光量，求channel=baidu 的累积曝光量超过100w的日期（注意是累积）</li><li><strong><a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>路径最大和</strong></li><li>矩阵从左到右从上到下递增（见过？换一题</li><li>判断完全n叉树（自己设计数据结构）两个<a href="https://www.nowcoder.com/jump/super-jump/word?word=排序" target="_blank" rel="noopener">排序</a>数组找到第k个（思路对？换一题</li><li>给定一串点，表示一个多边形，给定一个点，判断点是否在多边形内（跪了</li><li><a href="https://www.nowcoder.com/jump/super-jump/word?word=算法题" target="_blank" rel="noopener">算法题</a>：<a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>最大路径和，</li><li>数字的下一个排列，</li><li>一个<a href="https://www.nowcoder.com/jump/super-jump/word?word=链表" target="_blank" rel="noopener">链表</a>只保存当前<a href="https://www.nowcoder.com/jump/super-jump/word?word=链表" target="_blank" rel="noopener">链表</a>绝对值相等的第一个元素</li><li><a href="https://www.nowcoder.com/jump/super-jump/word?word=算法题" target="_blank" rel="noopener">算法题</a>，找出最大覆盖字符串的字符串集合</li><li>一根绳子，随意取2个点剪断，问这三条边能构成三角形概率</li><li>01矩阵，找出最大的由1构成的正方形</li><li>求给定<a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>，求其中距离最远的两个节点的距离值</li><li>给定一个<a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>以及<a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>中的部分节点，如何找出这些节点的最低公共祖先</li><li>写一个<a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>的中序遍历的迭代器（刚开始写的类，后面让用类模板）</li><li>将中序遍历改成非迭代</li><li>大数相减（两个字符串相减）</li><li>让你实现一个O(1)获取中位数的，怎么实现。</li><li>给定一个数组，找出最长子序列的长度，子序列满足：递增-递减-递增波动变化</li><li>算法题：消消乐，给定一个数字序列，将连续的数字全部消除，比如1,2,3,3,3,2,3，返回1,2,2,3（用栈做）</li><li>消消乐升级，只要有相同连续数字，全部消除，如1,2,3,3,3,2,3，返回1,3（用栈做，上一题代码上再加判断）</li><li>判断完全n叉树（自己设计数据结构）</li><li>两个栈实现队列</li><li>交错字符串 变种</li><li>二数之和变种</li><li>三数之和变种</li><li>判断整数是否为二的幂次方</li><li>手写堆<a href="https://www.nowcoder.com/jump/super-jump/word?word=排序" target="_blank" rel="noopener">排序</a></li><li>给我一张纸，画了一个九方格，都填了数字，给一个MN矩阵，从1开始逆时针打印这MN个数，</li><li>做题：数组A，2*n个元素，n个奇数、n个偶数，设计一个<a href="https://www.nowcoder.com/jump/super-jump/word?word=算法" target="_blank" rel="noopener">算法</a>，使得数组奇数下标位置放置的都是奇数</li><li>已知一个正整数组，一k，任取两个数，问两个数之和大于k的概率，手写。</li><li><a href="https://www.nowcoder.com/jump/super-jump/word?word=二叉树" target="_blank" rel="noopener">二叉树</a>从左到右遍历叶子结点，输出从根节点到叶子节点的路径</li><li><a href>手撕：</a>三数之和(leetcode 15)</li><li>两个队列实现一个栈；</li><li>最长回文子串；(dp)</li><li>查找有重复元素的非降序列中第一次出现的数字；(变形的二分查找)</li><li>堆排序，并分析时间复杂度；</li><li>链表中环的入口节点，并解释原因；</li><li>数组中连续子数组的最大和；</li><li>字符串转化为数字；(注意细节处理)</li><li>根据身高重建队列</li></ol><p>场景题</p><p>场景：在微博上关注了1k个大v，大v们每人有1w条微博，要想快速的访问前100条，应该怎么做？(排序+堆)</p><ol><li><p>有10亿个数，如何找出其中最小的100个数；(堆)</p><p>可以使用位图, 10亿个数不重复的话.</p></li><li><p>1w人抢购100件商品，如何实现？(高并发)</p></li><li><p>web漏洞有哪些？</p></li><li><p>两个很大的矩阵相乘，如何并行实现？(分块)</p></li><li><p><a href="https://www.nowcoder.com/jump/super-jump/word?word=海量数据" target="_blank" rel="noopener">海量数据</a><a href="https://www.nowcoder.com/jump/super-jump/word?word=排序" target="_blank" rel="noopener">排序</a>；(堆，归并)</p></li><li><p>场景题：<a href="https://www.nowcoder.com/jump/super-jump/word?word=拼多多" target="_blank" rel="noopener">拼多多</a>在线海量以物搜物的问题</p></li><li><p><a href="https://www.nowcoder.com/jump/super-jump/word?word=海量数据" target="_blank" rel="noopener">海量数据</a>找中位数</p></li><li><p>hash冲突，写拉链法代码</p></li><li><p>假设你是一个篮球制造厂商的测试总监，你要如何保证篮球的质量</p></li><li><p>消息的推拉模型</p></li><li><p>如何设计推送系统</p></li><li><p>64匹马赛跑，8个跑道，选出最快4匹马</p></li></ol><p>问题</p><p>网络：</p><p>数据库：</p><ol><li><p>索引：是什么？如何实现？</p></li><li><p>sql引擎：有哪些？MyISAM和InnoDB的区别？B+树与B树的区别？</p></li><li><p>MySQL的引擎有哪些？区别？底层实现？索引？</p></li><li><p>B树和B+树的特点和优势B树和B+树区别</p></li><li><p>数据库的隔离级别</p></li><li><p>MySQL索引结构，问了好几个数据库问题</p></li><li><p>数据库了解吗，事务的特性，带来的隔离级别和问题，非关系型数据库用</p></li><li><p>数据库的最左匹配原则是啥？怎么用？</p></li><li><p>你们数据库有没有用到分库分表，怎么做的？分库分表以后全局id怎么生成的？ </p></li><li><p>如何优化查询 </p></li><li><p>建立索引的原则 </p></li></ol><p>数据结构与<a href>算法</a>：</p><ol><li>二叉搜索树的特征，查找和插入的时间复杂度；</li><li>为什么说二叉搜索树有时会不稳定，如何改进？(可能会退化为<a href>链表</a>；改进为平衡二叉查找树)</li><li>AVL树大概的调整过程；(左旋右旋)</li><li><a href>红黑树</a>的特征以及大概的调整过程；</li><li>数组中0，1，2分别代表三种颜色的小球，调整数组元素使得相同颜色的小球在一起，要求在时间复杂度为O(n)，不能用额外空间；(双指针)</li><li>一个<a href>链表</a>，value里面存了公司里所有人的年龄，希望你对这个<a href>链表</a>做切分，切分出来的section越多越好，但是有一个条件：同一个年龄的人只允许分配到用一个section中，返回所有section的长度的数组；输入：29 -&gt; 30 -&gt; 31 -&gt; 32 -&gt; 31 -&gt; NULL，输出：[1, 1, 3]；(滑动窗口)</li><li><a href="https://www.nowcoder.com/jump/super-jump/word?word=红黑树" target="_blank" rel="noopener">红黑树</a>了解么，时间复杂度?</li><li>既然两个数据结构时间复杂度都是O(logN)，zset为什么不用<a href="https://www.nowcoder.com/jump/super-jump/word?word=红黑树" target="_blank" rel="noopener">红黑树</a></li><li>简单说说avl树，有什么特征。哪里用到了！！我答的<a href="https://www.nowcoder.com/jump/super-jump/word?word=红黑树" target="_blank" rel="noopener">红黑树</a>，然后接着问<a href="https://www.nowcoder.com/jump/super-jump/word?word=红黑树" target="_blank" rel="noopener">红黑树</a>和avl树区别在哪？答了构建<a href="https://www.nowcoder.com/jump/super-jump/word?word=红黑树" target="_blank" rel="noopener">红黑树</a>的那些概念，说不对，都是平衡的，为什么要用<a href="https://www.nowcoder.com/jump/super-jump/word?word=红黑树" target="_blank" rel="noopener">红黑树</a>不用avl树！</li></ol><p>Linux常用命令：</p><ol><li></li><li></li></ol><ol><li></li><li></li><li>elastic beanstalk部署怎么搞的</li><li>用到docker了吗</li><li>websocket</li><li>memtable怎么实现的(跳表)，SSTable(index + 二分)</li><li>Dubbo踩过哪些坑，怎么解决的？</li><li></li><li>说说Spring的生命周期吧</li><li>你提到的Remember Set底层是怎么实现的？</li><li>怎么避免产生浮动垃圾？</li><li>Java中的HashMap、TreeMap解释下？</li><li>TreeMap查询写入的时间复杂度多少？</li><li>ConcurrentHashMap怎么实现线程安全的？</li><li>HashMap多线程有什么问题？怎么解决？</li><li>CAS和synchronize有什么区别？都用synchronize不行么？</li><li>SpanId怎么保证唯一性？</li><li>RpcContext是在什么维度传递的？</li><li>Dubbo的远程调用怎么实现的？</li><li>Spring的单例是怎么实现的？</li><li>get需要加锁么，为什么？</li><li>volatile的作用是什么？</li><li>为什么要单独实现一个服务治理框架？</li><li>谁主导的？内部还在使用么？</li><li>逆向有想过怎么做成通用么？</li><li>线程池的线程数怎么确定？</li><li>如果是IO操作为主怎么确定？</li><li>如果计算型操作又怎么确定？</li><li>跳表的查询过程是怎么样的，查询和插入的时间复杂度?</li><li>说下Dubbo的原理?</li><li>分布式追踪的上下文是怎么存储和传递的？ </li><li>SpringMVC不同用户登录的信息怎么保证线程安全的？ </li><li>我们聊聊mysql吧，说下索引结构，为什么使用B+树？ </li><li>Dubbo的RpcContext是怎么传递的？主线程的ThreadLocal怎么传递到线程池？你说的内存泄漏具体是怎么产生的？  </li><li>线程池的线程是不是必须手动remove才可以回收value？那你说的内存泄漏是指主线程还是线程池？  </li><li>什么是索引覆盖？ </li><li></li><li>做题：手写一个对象池</li><li>备忘录模式 命令模式</li><li>同步锁，线程安全的单例，手写。</li><li>mysql的非聚簇索引，说一说</li><li></li><li>。</li><li></li><li>hashmap的东西</li><li></li><li></li><li>git命令</li><li>正则表达式，写一个</li><li>IOC和DI什么意思（刚好学到那里，答上了）</li><li>我看你还用了RabbitMQ，简单说一下RabbitMQ的工作原理？如何保证消息的顺序执行？Kafka了解吗？和RabbitMQ有什么区别？你为啥不用kafka来做，当时怎么考虑的？ </li></ol><ol><li></li><li>你了解哪些设计模式啊。挑一个熟悉的讲讲？（除了单例模式）在<a href>项目</a>中有用过设计模式吗？讲讲你怎么用的？简单说一下<em>*</em>模式和装饰器模式？</li><li></li><li>索引的常见实现方式有哪些，有哪些区别?MySQL的存储引擎有哪些，有哪些区别？InnoDB使用的是什么方式实现索引，怎么实现的？说下聚簇索引和非聚簇索引的区别？ </li><li>看你简历提到了raft<a href>算法</a>，讲下raft<a href>算法</a>的基本流程？raft<a href>算法</a>里面如果出现脑裂怎么处理？有没有了解过paxos和zoo<a href>keep</a>er的zab<a href>算法</a>，他们之前有啥区别？</li><li>聊聊java基础吧，如果我是想一个人的姓名一样就认为他们equal，能现场写下我们怎么重写equals吗？如果两个对象，一个是cat，一个是dog，我们认为他们的name属性一样就一样，怎么重写equals </li><li>还有点时间，写个题吧 假设有打乱顺序的一群人站成一个队列。 每个人由一个整数对(h, k)表示，其中h是这个人的身高，k是排在这个人前面且身高大于或等于h的人数。 编写一个<a href>算法</a>来重建这个队列。</li><li>IO，了解过poll，epoll</li><li></li><li>提到用explain查看，explain的结果都有哪些字段 </li></ol><p>5.微服务框架</p><ul><li>接触过springcloud吗？ </li><li>微服务一般都会有限流，有哪些手段（负载均衡、消息队列） </li><li>提到了负载均衡，有哪些策略 </li><li>限流的<a href>算法</a>有哪些 </li><li>令牌桶<a href>算法</a>说一下具体怎么实现的 </li></ul><p>6.提到令牌桶<a href>算法</a>，那就说<a href>算法</a>吧</p><ul><li></li><li>说一下快排怎么弄的 </li></ul><p>7.我问<a href>腾讯</a>内部是不是用java少，主要是c++和php，他说是</p><ul><li><p>还有用go的，提到了go，你知道协程是什么吗？</p><p>3.linkedlist、arraylist区别，内存分配上呢<br>4.string是否可变，string a + string b是怎么实现的<br>5.接口和抽象类说一下<br>6.内部类了解吗？匿名内部类了解吗？<br>7.阻塞io和非阻塞io说一下，非阻塞io优点是什么？怎么去监听，怎么实现非阻塞的<br>8.spring优点是什么，说一下ioc、aop<br>9.spring bean的生命周期说一下<br>10.spring bean的类型有哪些</p><p>13.了解学校个人情况<br>1.选择<a href>排序</a><br>2.判断二进制里1的个数<br>3.输入string判断是不是ipv4地址</p></li></ul><p>阿里二面 电话 45mins<br>  1.自我介绍<br>  2.深挖<a href>项目</a>（40分钟）</p><ul><li><p>介绍自己工作，遇到难点（提到了gc），怎么去优化问题（25mins） </p><ul><li></li><li>怎么去优化cas </li><li><a href>项目</a>遇到问题，比如cpu很高，怎么去排查 </li><li></li><li>好，那你自己设计一下怎么实现远程过程调用 </li><li>bio，nio区别 </li><li>4核cpu，100个http连接，用bio和nio分别需要多少个线程 </li><li>ip是不是可靠的，tcp怎么保证可靠 </li></ul><p>3.说一下spring aop底层机制</p><p>阿里三面 电话 30mins<br>1.自我介绍<br>2.深挖<a href>项目</a></p><ul><li>具体的架构、实现、策略 </li></ul></li><li>出一个新的实际问题，如何更改架构满足 </li></ul><p>阿里四面 电话 20mins<br>  1.自我介绍<br>  2.问<a href>项目</a>具体做什么了（10mins）<br>  3.如何把一个ip转化为int数字，实现互相转化<br>4.除了实习，在技术上你之前还做了哪些东西<br>  5.问问题</p><ul><li><p>还有技术面没 无，最后一轮技术了 </p><ul><li><p>部门具体干啥 交叉面的，我的部门应该是淘宝 </p></li><li><p>哪里还需要努力或者做哪些准备对工作有好处 多扩展技术栈</p></li></ul></li></ul><pre><code>- 讲解gc调优的过程 </code></pre><ul><li><ul><li>问<a href>滴滴</a>用的java版本（用的1.8）<br>知道g1吗，说一下区别<br><a href>项目</a>为啥不用g1还在用新生代老年代（答：不知道）（面试官说<a href>美团</a>用的还是1.7） </li></ul><p>3.用到了spring和mybatis框架，说一下spring的优点（提到了restful接口）<br>4.restful接口定义，和普通url区别，restful有哪些类型<br>5.由restful面试官引出了http，http、tcp处于哪一层<br>6.输入url发生什么（说的比较细就没问了）<br>7.之前学校本科时候的<a href>项目</a>用到了servlet<br>servlet和spring区别（答：servlet早都忘了，别问了）<br>springmvc怎么处理http请求（答：不知道）（面试官讲了一下，说也是基于servlet）<br>8.接下来就不问你<a href>项目</a>了，问你知识吧</p><ul><li></li><li><p>学过编译原理吧，讲一下编译原理的一些内容，随性发挥，能说多少说多少，没关系 </p></li><li><p>用过mysql吧，索引介绍一下（提到了b+树） </p></li><li><p>为啥用b+树，优点是啥 </p></li><li><p>说到了b+树，知道用机械硬盘和ssd作为存储盘的区别是啥吗 </p></li><li></li><li><ul><li><p>4.编程</p></li><li><p>连续子数组的最大和 </p></li></ul><p><a href>京东</a>二面 现场 30mins<br>1.自我介绍<br>2.挖<a href>项目</a>相关<br>3.<a href>滴滴</a>和<a href>华为</a>的感受上的区别</p></li></ul></li></ul><ul><li><pre><code>4.jvm相关</code></pre><p>  5.数据库相关自己说一下</p><pre><code>6.代码：- [二叉树]()转[链表]() </code></pre><ul><li>反转<a href>二叉树</a> </li></ul><p><a href>美团</a>三面 视频 45mins</p><pre><code>1.自我介绍2.问[项目]()3.编程- 类似于打印全排列，回溯法就行 </code></pre><p>   10.进程和线程的区别<br> 11.Java调度进程和线程<br>   12.Hashmap的结构</p><pre><code> 13.String和Stringbuffer的区别 14.你用过哪些设计模式</code></pre><p>   15.静态<em>*</em>实现</p><pre><code> 16.动态***实现</code></pre><p> 17.观察者模式<br>   18.观察者模式的使用场景</p><pre><code> 19.e-r图</code></pre><p> 20.Jvm内存区域划分</p><pre><code> 21.一个对象从进入堆区到死亡的全流程 22.数据库索引的实现 26.**写代码：** -  记录：id, status </code></pre><ul><li>存储：256库*256表 </li><li>场景：需要扫描所有数据，找出所有status=2的id列表 </li><li><p>要求：同一份代码，部署20台服务器，速度快，且每一张表不会被扫描2次 </p><p>27.大学期间遇到过最大的困难以及解决？<br>28.为什么选择读计算机？<br>29.为什么不考公务员？<br>30.以后想做的方向<br>31.10年以后的设想 </p></li></ul></li></ul><pre><code>  ###  二面    1.自我介绍 2.学校[项目]()都做了什么？（详细） 3.具体用到的技术？   4.深度学习模块怎么实现？   5.问了问nlp流程   6.nlp模型各部分的作用   7.神经网络训练的原理   8.训练集和测试集的比例 9.用了哪些设计模式   10.Spring aop怎么实现？ 14.[项目]()里Redis怎么用   15.分布式缓存可能出现的问题 16.分布式锁   17.Setnx加锁的原理 18.怎么解除分布式锁？   19.Jvm内存区域划分   20.程序计数器的作用   21.本地方法栈和虚拟机栈的区别   22.Gc全流程 23.Gc[算法]()   24.连接过程中什么时候会出现time_wait状态   25.为什么要有time_wait状态 26.一致性hash了解吗？   27.一致性hash的优点？   28.**设计题：**有一个服务器专门接收大量请求，怎么设计？   39.**[算法题]()：**[二叉树]()前序遍历非递归作者：我的天呦真可爱  链接：https://www.nowcoder.com/discuss/219391来源：牛客网  Java中的Map接口及其实现进行一些介绍；   LinkedHashMap与TreeMap中的有序是同样的概念吗？LinkedHashMap的顺序调整是怎么完成的；   HashMap详细介绍一下，存取的时间复杂度是多少（我分为键不冲突、键冲突时在[链表]()中或在[红黑树]()中的时间复杂度来讲的）；     HashMap中的数据是存在哪里，怎么存，通过key怎么求在数组中的位置；     [红黑树]()介绍一下；HashMap的[红黑树]()中放数据的时候怎么对比key的值从而调整树，TreeNode里面怎么比较key的；     介绍一下多线程（然后面试官根据我提到的一些内容开始疯狂发问，多线程这一块是给我问懵了，因为有些问题我和面试官不在一个频道上，没理解他问的啥）     继承Thread和实现Runnable的区别；介绍synchronized、Lock和volatile的区别；volatile在并发时会不会有问题，例如加减乘除；Lock相关的类的使用流程；lock()和unlock()之间抛了异常怎么办，在使用try catch时怎么写（就是怎么处理异常）；线程获取不到锁会阻塞吗；tryLock()方法理解；多个线程同时调用tryLock()方法时如何保证原子性（如何保证肯定只有一个能获得锁）；  Java的接口和抽象类的区别； Java中的线程的生命周期，状态转换； 数据库中的乐观锁和悲观锁概念，乐观锁的实现方式有哪些（版本号机制、CAS[算法]() ）   对于读多写少和写多读少的操作，分别使用乐观锁还是悲观锁；HashMap 和 ConcurrentHashMap；追问具体内容；</code></pre><p>  ArrayList 和 LinkedList；</p><pre><code>  接口与抽象类；  Exception 与 Error；  JVM 的内存结构；</code></pre><p>  垃圾回收（器）；</p><p>线程池原理；</p><p>  悲观锁与乐观锁（Java 中）；</p><p>JVM 调优；</p><p>数据库数据结构，索引；</p><p>数据库隔离级别，锁协议，并发问题等；</p><p>InnoBD 多版本并发控制；</p><p>InnoBD 与 MyISAM；</p><p>Redis；</p><p>数据库读写分离、分库分表；</p><p>TCP 细节；</p><p>Spring IOC、AOP；</p><p>  java <em>*</em>与 CGLib；</p><p>RabbitMQ 的某个问题；</p><p>  都看些什么书，什么博客</p><p>  负载均衡，微服务等；</p><p>  网络方面，怎么影响性能，不同层的问题等；</p><p>  HTTP 和 RPC 等；</p><p>  IO 方面，BIO 和 NIO，内核态，零拷贝，Netty 等；</p><p>  数据库方面，读写分离，分库分表等，涉及到一个场景题；</p><p>  Thread；</p><p>  equals 和 hashCode 等；</p><p>  volatile；</p><pre><code>  JMM；</code></pre><p>  垃圾回收，分代等；</p><p>  synchronized；</p><p>  单例模式；</p><p>  ThreadLocal；</p><p>  jvm 栈空间分配；</p><p>  TCP/IP 五层模型；</p><p>  各层常见协议；</p><pre><code>  HTTP 的报文结构；</code></pre><p>  HTTP 和 HTTPS；</p><p>  常见的 HTTP 头；</p><p>  数据库隔离级别等；</p><p>  快排特点等；</p><p>  堆排怎么找左子节点；</p><p>  Linux 分割文本的问题；</p><p>  cookie 和 session；</p><p>  磁盘文件到JVM的加载过程</p><p>  类存在的意义</p><p>  如何确定session存放值比如用户id</p><p>  手写生产者消费者模式</p><p>  a数组用b数组顺序<a href="https://www.nowcoder.com/jump/super-jump/word?word=排序" target="_blank" rel="noopener">排序</a></p><p>  如何查询IP地址是否在国内网段</p><p>  线程池</p><p>  Reentrantlock</p><p>  synchronized</p><p>  组合索引</p><p>  JVM内存结构，类加载信息存储在哪</p><p>  数据库的隔离级别</p><p>  cookie在http报文的那个位置</p><p>  http和https</p><pre><code>  time-wait和close-wait</code></pre><p>  最左看<a href>二叉树</a>第一个节点</p><p>  mysql左前原则</p><p>  innodb索引 b+树子节点一定存表行信息吗</p><p>  \7. 有序集合数据结构怎么实现</p><p>  \8. jvm判断回收</p><p>  \9. </p><p>  \10. 类加载过程</p><p>  \11. java四种引用</p><p>  \12. 方法区</p><p>  \13. <a href>项目</a></p><p>  \14. 队列集合怎么实现的，有哪些</p><p>  \15. 类加载过程的不足</p><p>  \16. blockingqueue怎么实现阻塞</p><pre><code>  \17. 哪些对象可以作为gcRoot</code></pre><p>  \1. 查找树中连接两个节点最大路径</p><pre><code>  \2. 进程间通信效率最高的方式</code></pre><p>  3.共享内存怎么实现</p><p>  作者：lishinho<br>    链接：<a href="https://www.nowcoder.com/discuss/333012" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/333012</a><br>  来源：牛客网</p><p>  \1. dns过程</p><pre><code>  \2. dns递归调用和叠代调用</code></pre><p>  \3. tcp可靠性含义</p><p>  \4. tcp可靠性应用</p><p>  \5. 拥塞机制</p><p>  \6. 长连接短链接</p><p>  \7. http常用首部字段</p><p>  \8. select函数，epoll函数</p><p>  \9. 静态链接库和动态链接库</p><p>  \10. 进程和线程</p><p>  \11. 编译和链接的区别</p><p>  \12. 最大连续和dp解法</p><p>  \4. Mysql四种隔离级别</p><p>  5.Mysql InnoDB和MyISAM区别</p><p>  \6. Mysql profile是做什么的</p><p>  \9. 缓存怎么实现</p><p>  \10. LRU和FIFO</p><pre><code>  \11. 分页原理</code></pre><p>  12.tcp拥塞控制</p><p>  \13. http报文头结构</p><p>  \14. http报文长度边界字段</p><p>  作者：lishinho<br>    链接：<a href="https://www.nowcoder.com/discuss/333012" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/333012</a><br>  来源：牛客网</p><p>  \2. 大数据优化内容</p><pre><code>  \3. 口述程序整数反转</code></pre><p>  \4. zk的作用</p><p>  5.kafka的partition</p><p>  \6. kafka中一个broker故障，会怎么办</p><p>  \7. flink如何实现exactly-once语义</p><p>  \8. flink的实现原理</p><p>  \9. 其他流处理框架与flink的区别</p><p>  \10. spark如何处理流处理</p><p>  \11. storm如何处理流处理</p><p>  \12. lambda框架原理</p><p>  \13. 如何解决超卖问题</p><p>  \14. 如何用<a href>算法</a>解决高并发</p><p>  \15. 如何大数据快速查询一条数据</p><p>  \17. 怎么做evaluation验证flink效果</p><p>  \1. Java多态的实现</p><p>  \2. TreeMap和HashMap的区别</p><p>  3.MySQL索引底层的实现</p><pre><code>  \4. 什么是NoSQL，NoSQL的常见应用</code></pre><p>  \5. Redis的数据结构</p><p>  \1</p><p>  \2. 浮点数怎么存储</p><p>  \3. 什么是TTL，什么是TraceRoute</p><p>  \3. 网络查找命令</p><p>  \4. Linux磁盘命令</p><p>  5.网络第二层和第三层有什么区别</p><p>  6.linux的常用指令</p><p>  作者：lishinho<br>    链接：<a href="https://www.nowcoder.com/discuss/333012" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/333012</a><br>  来源：牛客网</p><p>  \1. JVM</p><pre><code>  \2. linux内核</code></pre><p>  \3. zoo<a href>keep</a>er</p><p>  \4. kafka消息队列</p><p>  \5. 数据库mysql和<a href>redis</a></p><p>  \6. 分布式事务</p><p>  \7. 微服务框架</p><p>  \8. 网络攻击</p><p>  \9. 代码耦合性</p><p>  \10. <a href>项目</a>完成背景</p><p>  \11. TCP，UDP</p><p>  \1. Zab协议</p><p>  \2. 进程地址存储</p><p>  \3. 网络编程IO多路复用</p><p>  \4. 网络传输模型</p><p>  \5. IO过程</p><p>  \6. 新的微服务框架</p><p>  作者：lishinho<br>    链接：<a href="https://www.nowcoder.com/discuss/333012" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/333012</a><br>  来源：牛客网</p><p>  ​    </p><p>  1.jsp到servlet过程，servlet生命周期</p><pre><code>  2.http与https区别，传输过程，如何交互</code></pre><p>  \3. hashmap结构，concurrenthashmap结构</p><p>  4.线程池声明与使用</p><p>  \5. JVM内存模型，垃圾回收</p><p>  \6. Tomcat运行原理</p><p>  \7. 手撸死锁模型</p><p>  \8. 流处理与批处理区别</p><p>  9.storm和flink的区别</p><p>  10.怎么学习的</p><p>  作者：lishinho<br>    链接：<a href="https://www.nowcoder.com/discuss/333012" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/333012</a><br>  来源：牛客网</p><p>  \1. 手撸适配器模式</p><pre><code>  \2. 手撸代码并查找边界错误</code></pre><p>  \3. Spring MVC框架</p><p>  \4. BASE原则</p><p>  \5. 分布式原理CAP原则</p><p>  \6. Java反射</p><pre><code>  \7. private属性,final类型举例</code></pre><p>  \8. ReadWriteLock</p><p>  \9. 数据库-四种隔离级别-脏读/幻读/-索引</p><p>  微信视频面，最后问了我要不要去大数据研发，我拒绝了，当时比较傻缺</p><p>  \1. 网络：tcp udp区别</p><p>  http协议介绍</p><p>  \2. 面向对象 抽象类和接口区别</p><p>  3.单例模式实现</p><p>  \4. 数据库索引</p><p>  \5. Js怎么面向对象</p><p>  \6. 装饰器模式原理</p><pre><code>  7.静态类和单例模式有什么区别</code></pre><p>  \8. 设计一个股票推送的设计模式</p><p>  \9. 容错分析题：页面加载慢原因</p><p>  3.set的底层实现<br>    4.锁的分类<br>  5.不用锁实现cas （atomic<br>    6.aop实现原理<br>  7.新建bean，如何声明 （用注解<br>    8.devops平台步骤<br>  9.测试是在哪个步骤之前或之后（构建时候<br>    10.ansible以外的部署方式<br>      11.ansible的机制<br>    12.微服务架构是什么<br>      13.如何解决事务问题<br>      14.cap理论</p><pre><code>\2. Java HashMap/TreeMap</code></pre><p>  \3. 多线程方法</p><pre><code>\4. 死锁\5. Flink6.static关键字7.数据库常见支持类型\8. char和varchar的区别，优缺点9.索引的种类\10. 联合索引最左原则  \11. 索引底层：B+树，散列，位图\12. java hashmap put操作  \13. hashmap扩容，承载因子  \14. 设计模式在自己工程中使用举例</code></pre><p>  ​    </p><pre><code>  \2. zoo[keep]()er怎么实现分布式锁  \3. 分布式锁作用  \4. Hashmap，concurrentHashmap</code></pre><p>  ​    </p><pre><code>  \8. 单例模式  \9. [项目]()中遇到的OOM问题</code></pre><p>  \10. 怎么监视JVM数据</p><p>  ​    </p><p>  \3. java Threadlocal类(线程变量本地化）</p><p>  \4. mysql存储引擎</p><p>  \5. sql优化</p><p>  \6. 进程线程区别</p><p>  \7. SSM框架常用注解</p><p>  \7. 自定义注解</p><p>  \1. 子数组和为0 dp<a href="https://www.nowcoder.com/jump/super-jump/word?word=算法" target="_blank" rel="noopener">算法</a></p><p>  \2. flink怎么保证exactly-once语义</p><p>  \3. 高并发环境怎么做测试</p><p>  \4. 常用的检查系统failure的方法</p><p>  \5. java堆怎么排查错误</p><p>  \2. java static</p><p>  \3. 操作系统栈和堆区别</p><p>  \4. 存储代码段</p><p>  \5. 缓存，缓存不一致性</p><pre><code>  \6. tcp与udp应用场景</code></pre><p>  \7. 聚簇索引与非聚簇索引</p><p>  \8. join的种类以及实际操作</p><p>  \9. 编程：<a href>二叉树</a>按层遍历</p><p>  \1. 工程flink的checkpoint的具体过程</p><p>  \2. checkpoint对系统有什么影响</p><p>  \3. int和integer的区别,装箱与拆箱</p><p>  \4. 怎么调用integer的方法，具体过程</p><p>  \5. java内部类和静态内部类</p><p>  \6. <a href>二叉树</a>前序遍历</p><p>  \7. best time to buy and sell stock最多二次买卖</p><p>  \8. 常见设计模式</p><p>  数据库mysql的隔离级别</p><p>  怎么实现多线程安全</p><p>  jvm的类加载机制和垃圾回收原理</p><p>  b+树和<a href>红黑树</a>区别</p><p>  <a href>二叉树</a>的遍历方法 写按层遍历<a href>二叉树</a></p><p>  flink和spark的区别</p><pre><code>  单例模式和适配器模式</code></pre><p>  \1. java基本数据类型</p><pre><code>  \2. java对象生命周期</code></pre><p>  \3. mysql和<a href>redis</a>区别</p><p>  \4. 线程生命周期</p><p>  \5. 多线程好处</p><p>  \6. 线程池作用</p><p>  \2. zk用途，分布式锁</p><p>  \4. 括号匹配编程</p><p>  \5. 树节点z-order打印</p><p>  \1. linux 怎么进shell</p><p>  \2. linux的swap分区</p><p>  \3. 网络tcp四次挥手</p><p>  \4. 应用层协议http post和get请求</p><p>  \5. jmeter集合测试</p><p>  \6. 大数据有哪些failure 怎么应对</p><p>  \7. 分布式架构的性能优化</p><p>  \8. mysql存储引擎</p><p>  \9. xss攻击，sql注入</p><p>  \10. 网络虚拟化技术是什么，常用平台</p><p>  \1. 操作系统进程分配区，内存管理</p><p>  \2. io多路复用</p><p>  \3. 操作系统层面怎么实现互斥锁</p><p>  \4. 数据段组成</p><p>  \5. 网络tcp建立与释放</p><p>  \6. tcp长连接 heartbeat</p><p>  \7. tcp半连接</p><p>  \8. 图的遍历<a href>算法</a> 迪杰斯特拉<a href>算法</a></p><p>  \9. 上楼梯</p><p>  \10. </p><p>  \14. 图形学了解</p><p>  15.快排实现</p><p>  \16. 堆<a href>排序</a>实现，怎么建堆</p><p>  \</p><p>  \</p><p>  \4. MySQL的ORM方式</p><p>  \5. mybatis怎么对应实体</p><p>  \6. applicationcontext逻辑</p><p>  \7. bean的生命周期和种类</p><p>  \8. flink的检查点机制怎么改进？</p><p>  \9. flink窗口</p><p>  \10. flink的任务失败模型</p><p>  \11. 还有很多工程上的细节</p><p>  \3. zoo<a href>keep</a>er原理 ZAB协议</p><p>  \4. zoo<a href>keep</a>er加节点</p><p>  \5. 分布式锁种类</p><p>  \6. zoo<a href>keep</a>er分布式锁，<a href>redis</a>分布式锁</p><p>  \1. hbase读写过程</p><p>  \2. flink工程</p><p>  \3. 设计通过flink查找9点10分各个路口通过车辆的信息</p><p>  \4. 学习flink的方法和途径</p><p>  \5. jvm错误排查 oom排查 jvm问题：垃圾回收时间过长</p><p>  \6. 十个kafka消费者线程消费，如何设计在多线程场景下完成统计</p><p>  6.<a href>redis</a>常用的数据结构<br>    7.了解过mybatis没 （用过没深入了解过</p><pre><code>  3.error和ecxeption说一下5.手写sql</code></pre><p>  6.<a href>手撕：</a>把数组排成最小的数（<a href="https://www.nowcoder.com/jump/super-jump/word?word=剑指offer" target="_blank" rel="noopener">剑指offer</a>）</p><pre><code>  3.一个100g的大文件，如何进行[排序](https://www.nowcoder.com/jump/super-jump/word?word=排序)。内存只有4g</code></pre><p>  ​    </p><pre><code>  作者：白天不懂夜的黑谁又能懂我伤悲链接：https://www.nowcoder.com/discuss/304038</code></pre><p>  来源：牛客网</p><pre><code>  [网易]()二面 视频 30mins自我介绍  [项目]() 15分钟</code></pre><p>  深浅拷贝区别<br>    枚举类能否继承<br>      编译成class文件里有什么内容<br>    编译成字节码以后还能变吗<br>      编程：一组数据，对一些数据加x，一些数据减x，使得所有数据一样，判断是否有这样一个x4.mybatis好处是啥<br>    5.自己写过sql没，要注意哪些地方</p><p>智力题：</p><ol><li>海盗分金；(博弈论)</li><li>三个火枪手；(博弈论)</li></ol><p>项目:</p><p>word2vec和doc2vec区别</p><p>Bert的应用.Siamese Network 为什么能够work</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;PDD&lt;/p&gt;
&lt;p&gt;redis&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href&gt;redis&lt;/a&gt;哪些数据结构&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;SDS simple synamic string：支持自动动态扩容的字节数组预空间分配&lt;/li&gt;
&lt;li&gt;list ：链表 &lt;/li
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/09/29/%E5%B9%B3%E5%A4%9A%E5%A4%9A/"/>
    <id>http://yoursite.com/2020/09/29/平多多/</id>
    <published>2020-09-29T14:03:37.344Z</published>
    <updated>2020-09-30T11:35:46.741Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/09/29/#%20%E5%AD%97%E8%8A%82/"/>
    <id>http://yoursite.com/2020/09/29/# 字节/</id>
    <published>2020-09-29T14:01:24.837Z</published>
    <updated>2020-09-29T14:01:34.569Z</updated>
    
    <content type="html"><![CDATA[<p># 字节</p><p>作者：*?</p><p>链接：<a href="https://www.nowcoder.com/discuss/485900?source_id=profile_create&amp;channel=1009" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/485900?source_id=profile_create&amp;channel=1009</a></p><p>来源：牛客网</p><p>技术</p><p>后端</p><p>【字节跳动】字节跳动后端面经 已拿意向书 <a href="https://www.nowcoder.com/discuss/302265" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/302265</a></p><p>【字节跳动】字节后端三面 凉凉夜色为我思念成河 <a href="https://www.nowcoder.com/discuss/227726" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/227726</a></p><p>【字节跳动】字节跳动 C++深圳后端 四面面经 意向书已get <a href="https://www.nowcoder.com/discuss/21736" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/21736</a></p><p>【字节跳动】头条后端开发提前批技术面小结（已拿意向性offer） <a href="https://www.nowcoder.com/discuss/216828" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/216828</a></p><p>【字节跳动】字节跳动提前批后端第三面凉经 <a href="https://www.nowcoder.com/discuss/214125" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/214125</a></p><p>【字节跳动】字节二面（凉面）C++ 后端 <a href="https://www.nowcoder.com/discuss/209688" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/209688</a></p><p>【字节跳动】字节跳动提前批后端开发（视频架构）一二三面 <a href="https://www.nowcoder.com/discuss/209548" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/209548</a></p><p>【字节跳动】字节跳动 后端提前批一面凉经 <a href="https://www.nowcoder.com/discuss/207096" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207096</a></p><p>【字节跳动】字节 后端 一面凉经 <a href="https://www.nowcoder.com/discuss/207326" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207326</a></p><p>【字节跳动】字节跳动 C++后端 一面 面经 <a href="https://www.nowcoder.com/discuss/207260" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207260</a></p><p>【字节跳动】字节提前批后端开发-视频架构方向面经 <a href="https://www.nowcoder.com/discuss/207891" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207891</a></p><p>【字节跳动】头条互娱 后端 一面二面 <a href="https://www.nowcoder.com/discuss/208374" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/208374</a></p><p>【字节跳动】字节跳动 互娱后端一面 <a href="https://www.nowcoder.com/discuss/208161" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/208161</a></p><p>【字节跳动】字节跳动-视频架构-后端开发（视频一面） <a href="https://www.nowcoder.com/discuss/208773" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/208773</a></p><p>【字节跳动】字节跳动 成都效率工程后端C++提前批三面凉面 <a href="https://www.nowcoder.com/discuss/205353" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/205353</a></p><p>【字节跳动】字节跳动后端提前批 <a href="https://www.nowcoder.com/discuss/204112" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/204112</a></p><p>【字节跳动】字节跳动 成都效率工程后端C++提前批三面凉面 <a href="https://www.nowcoder.com/discuss/205353" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/205353</a></p><p>【有赞、字节跳动、网易、华为、美团、滴滴】6家Java后端社招面经 <a href="https://www.nowcoder.com/discuss/349126" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/349126</a></p><p>【字节跳动】字节跳动Java后端视频面一面凉经 <a href="https://www.nowcoder.com/discuss/302831" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/302831</a></p><p>【字节跳动】字节后端开发面经 <a href="https://www.nowcoder.com/discuss/301301" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/301301</a></p><p>【字节跳动】字节跳动-后端开发-面经 <a href="https://www.nowcoder.com/discuss/262576" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/262576</a></p><p>【字节跳动】【字节跳动】后端开发三轮面经 <a href="https://www.nowcoder.com/discuss/241356" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/241356</a></p><p>【字节跳动】字节跳动后端三轮面经 <a href="https://www.nowcoder.com/discuss/226626" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/226626</a></p><p>【字节跳动】字节跳动提前批后端开发 <a href="https://www.nowcoder.com/discuss/220896" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/220896</a></p><p>【字节跳动】头条后端开发面经（已拿意向书） <a href="https://www.nowcoder.com/discuss/217672" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/217672</a></p><p>【字节跳动】头条提前批后端,刚拿到意向书，分享面经还愿 <a href="https://www.nowcoder.com/discuss/213834" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/213834</a></p><p>【字节跳动】字节跳动后端提前批二面凉 <a href="https://www.nowcoder.com/discuss/207144" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207144</a></p><p>【字节跳动】字节 后端 一面凉经 <a href="https://www.nowcoder.com/discuss/207065" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207065</a></p><p>【字节跳动】头条深圳后端提前批一面凉经 <a href="https://www.nowcoder.com/discuss/207046" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207046</a></p><p>【字节跳动】字节跳动提前批后端两面面经 <a href="https://www.nowcoder.com/discuss/207290" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207290</a></p><p>【字节跳动】头条java后端提前批一面凉经 <a href="https://www.nowcoder.com/discuss/207272" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207272</a></p><p>【字节跳动】头条后端一轮游面经 <a href="https://www.nowcoder.com/discuss/207815" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207815</a></p><p>【字节跳动】头条提前批Java后端工程师面经 <a href="https://www.nowcoder.com/discuss/206411" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/206411</a></p><p>【字节跳动】字节跳动data后端一面面经 <a href="https://www.nowcoder.com/discuss/204325" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/204325</a></p><p>【字节跳动】头条后端一面凉经 <a href="https://www.nowcoder.com/discuss/205034" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/205034</a></p><p>【字节跳动】字节跳动 后端开发 二面凉经 <a href="https://www.nowcoder.com/discuss/343393" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/343393</a></p><p>【字节跳动】字节跳动后端实习面试（全程超越附体） <a href="https://www.nowcoder.com/discuss/338849" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/338849</a></p><p>【字节跳动】今日头条 后端 社招 <a href="https://www.nowcoder.com/discuss/325907" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/325907</a></p><p>【蚂蚁金服、PingCAP、字节跳动】后端两年社招面经 <a href="https://www.nowcoder.com/discuss/322042" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/322042</a></p><p>【字节跳动、腾讯】头条后端校招面经一二三面 腾讯后端实习一二面 面经 <a href="https://www.nowcoder.com/discuss/314995" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/314995</a></p><p>【字节跳动】字节跳动后端开发面试 <a href="https://www.nowcoder.com/discuss/293766" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/293766</a></p><p>【PingCAP、蚂蚁、字节跳动】后端社招面试经历(两年经验) <a href="https://www.nowcoder.com/discuss/284494" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/284494</a></p><p>【字节跳动】【字节】后端一面 <a href="https://www.nowcoder.com/discuss/280129" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/280129</a></p><p>【字节跳动】字节跳动效率工程后端三面凉经 <a href="https://www.nowcoder.com/discuss/277817" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/277817</a></p><p>【字节跳动】字节跳动一二面面经【后端】 <a href="https://www.nowcoder.com/discuss/250449" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/250449</a></p><p>【字节跳动】字节后端一面凉经 <a href="https://www.nowcoder.com/discuss/241250" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/241250</a></p><p>【字节跳动】字节跳动 后端开发 一、二、三面 面经 <a href="https://www.nowcoder.com/discuss/236551" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/236551</a></p><p>【字节跳动】字节跳动后端开发实习生凉经 <a href="https://www.nowcoder.com/discuss/213918" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/213918</a></p><p>【字节跳动】字节跳动后端一面凉经 <a href="https://www.nowcoder.com/discuss/209668" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/209668</a></p><p>【字节跳动】字节跳动后端二面凉经 <a href="https://www.nowcoder.com/discuss/209793" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/209793</a></p><p>【字节跳动】字节跳不动后端面经 <a href="https://www.nowcoder.com/discuss/208742" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/208742</a></p><p>【字节跳动】字节跳动后端开发一面凉 <a href="https://www.nowcoder.com/discuss/208946" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/208946</a></p><p>【字节跳动】头条后端实习二面面经 7/14 <a href="https://www.nowcoder.com/discuss/206633" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/206633</a></p><p>【字节跳动】后端开发二面凉经QAQ <a href="https://www.nowcoder.com/discuss/203652" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/203652</a></p><p>【字节跳动】190705字节跳动效率工程EE后端一面面经 <a href="https://www.nowcoder.com/discuss/203488" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/203488</a></p><p>【字节跳动】头条一面二面Data后端（一首凉凉送给自己） <a href="https://www.nowcoder.com/discuss/205742" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/205742</a></p><p>【字节跳动】头条南京后端上岸 <a href="https://www.nowcoder.com/discuss/218650" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/218650</a></p><p>【字节跳动】字节跳动提前批后端，刚拿意向书，分享一下面经 <a href="https://www.nowcoder.com/discuss/210872" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/210872</a></p><p>Java</p><p>【陌陌，云从科技，字节跳动】日常实习java面经-陌陌，云从科技，字节跳动 <a href="https://www.nowcoder.com/discuss/350072" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/350072</a></p><p>【有赞、字节跳动、网易、华为、美团、滴滴】6家Java后端社招面经 <a href="https://www.nowcoder.com/discuss/349126" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/349126</a></p><p>【阿里、腾讯、字节跳动】总结秋招 回馈牛客（阿里+腾讯+头条 Java面经） <a href="https://www.nowcoder.com/discuss/342084" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/342084</a></p><p>【知乎、快看漫画、快手、字节跳动】社招-一年经验-Java开发-知乎/快看漫画/快手/头条面经 <a href="https://www.nowcoder.com/discuss/331681" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/331681</a></p><p>【蚂蚁金服、字节跳动】蚂蚁金服和字节跳动Java社招面经 <a href="https://www.nowcoder.com/discuss/315199" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/315199</a></p><p>【字节跳动】北京字节跳动游戏JAVA游戏服务器回馈一下攒人品 <a href="https://www.nowcoder.com/discuss/308109" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/308109</a></p><p>【字节跳动】字节跳动Java后端视频面一面凉经 <a href="https://www.nowcoder.com/discuss/302831" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/302831</a></p><p>【字节跳动】字节跳动java后台已上岸，发个面经回馈牛油 <a href="https://www.nowcoder.com/discuss/215891" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/215891</a></p><p>【字节跳动】头条java后端提前批一面凉经 <a href="https://www.nowcoder.com/discuss/207272" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207272</a></p><p>【字节跳动】字节跳动Java后台一面面经 <a href="https://www.nowcoder.com/discuss/207262" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207262</a></p><p>【字节跳动】头条提前批Java后端工程师面经 <a href="https://www.nowcoder.com/discuss/206411" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/206411</a></p><p>【字节跳动】【java】头条提前批一面（2019-07-07） <a href="https://www.nowcoder.com/discuss/203984" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/203984</a></p><p>【字节跳动】字节跳动-提前批-Java后台 - 一面面经（QAQ） <a href="https://www.nowcoder.com/discuss/204596" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/204596</a></p><p>【字节跳动】字节跳动-提前批-Java后台 - 一面面经（QAQ） <a href="https://www.nowcoder.com/discuss/204596" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/204596</a></p><p>C++</p><p>【字节跳动】字节跳动-抖音C++开发实习一二面凉经 <a href="https://www.nowcoder.com/discuss/342523" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/342523</a></p><p>【小米、海格、旷视、快看、美团、百度、快手、字节跳动】算法转C++开发，我的秋招面经(&gt;o&lt;) <a href="https://www.nowcoder.com/discuss/302094" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/302094</a></p><p>【字节跳动】字节c++一面 <a href="https://www.nowcoder.com/discuss/298886" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/298886</a></p><p>【百度、京东方、美团、 小米、字节跳动】秋招总结(C++，附部分面经) <a href="https://www.nowcoder.com/discuss/291376" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/291376</a></p><p>【字节跳动】字节跳动 基础架构C++服务端开发面经 <a href="https://www.nowcoder.com/discuss/241129" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/241129</a></p><p>【阿里、滴滴、腾讯、贝壳、字节跳动、网易、】发一波C++面经攒人品，希望8月能收获offer <a href="https://www.nowcoder.com/discuss/228118" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/228118</a></p><p>【字节跳动】字节跳动 C++深圳后端 四面面经 意向书已get <a href="https://www.nowcoder.com/discuss/21736" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/21736</a></p><p>【字节跳动】字节跳动C++一面凉经 <a href="https://www.nowcoder.com/discuss/210321" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/210321</a></p><p>【字节跳动】字节二面（凉面）C++ 后端 <a href="https://www.nowcoder.com/discuss/209688" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/209688</a></p><p>【字节跳动】头条C++开发二面凉经 <a href="https://www.nowcoder.com/discuss/209636" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/209636</a></p><p>【字节跳动】头条C++ 一二面凉经 <a href="https://www.nowcoder.com/discuss/207322" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207322</a></p><p>【字节跳动】字节跳动 C++后端 一面 面经 <a href="https://www.nowcoder.com/discuss/207260" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207260</a></p><p>【字节跳动】字节跳动C++研发工程师（三面全通过） <a href="https://www.nowcoder.com/discuss/208173" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/208173</a></p><p>【字节跳动】字节跳动 互娱 C++ 一面 <a href="https://www.nowcoder.com/discuss/208969" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/208969</a></p><p>【字节跳动】字节跳动C++提前批一面面经 <a href="https://www.nowcoder.com/discuss/206156" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/206156</a></p><p>【字节跳动】字节跳动 C++开发工程师 面经 <a href="https://www.nowcoder.com/discuss/206522" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/206522</a></p><p>【字节跳动】字节跳动，刚刚出炉的C++一面凉经 <a href="https://www.nowcoder.com/discuss/206425" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/206425</a></p><p>【字节跳动】字节跳动 成都效率工程后端C++提前批三面凉面 <a href="https://www.nowcoder.com/discuss/205353" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/205353</a></p><p>【字节跳动】字节跳动 成都效率工程后端C++提前批三面凉面 <a href="https://www.nowcoder.com/discuss/205353" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/205353</a></p><p>【字节跳动】头条ios开发 一面C++ <a href="https://www.nowcoder.com/discuss/306888" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/306888</a></p><p>前端</p><p>【字节跳动、浦发】非科班查硕的秋招前端面经整理 <a href="https://www.nowcoder.com/discuss/349699" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/349699</a></p><p>【字节跳动】字节跳动-效率工程 一二三面面筋 + 前端笔记分享 <a href="https://www.nowcoder.com/discuss/337035" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/337035</a></p><p>【字节跳动 】回馈牛客 字节跳动前端面经 <a href="https://www.nowcoder.com/discuss/***898" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/***898</a></p><p>【酷狗、字节跳动、CVTE、猿辅导】前端两年社招面经总结 <a href="https://www.nowcoder.com/discuss/316450" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/316450</a></p><p>【字节跳动】字节跳动前端面经 <a href="https://www.nowcoder.com/discuss/308745" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/308745</a></p><p>【字节跳动】字节跳动-头条研发 前端一二面凉 <a href="https://www.nowcoder.com/discuss/294450" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/294450</a></p><p>【字节跳动】头条抖音散招前端凉经 <a href="https://www.nowcoder.com/discuss/286453" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/286453</a></p><p>【字节跳动】字节跳动前端一面凉经 <a href="https://www.nowcoder.com/discuss/279144" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/279144</a></p><p>【字节跳动】「前端」19年第一次面试 面筋 攒人品 许愿顺利 <a href="https://www.nowcoder.com/discuss/276007" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/276007</a></p><p>【阿里、字节跳动、携程、美团】我的秋招总结（前端） <a href="https://www.nowcoder.com/discuss/273606" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/273606</a></p><p>【字节跳动】字节前端一面 <a href="https://www.nowcoder.com/discuss/274438" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/274438</a></p><p>【字节跳动】字节跳动 前端面经 <a href="https://www.nowcoder.com/discuss/268116" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/268116</a></p><p>【字节跳动】字节跳动前端一面凉经 <a href="https://www.nowcoder.com/discuss/226798" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/226798</a></p><p>【字节跳动】字节前端一面凉经 <a href="https://www.nowcoder.com/discuss/226691" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/226691</a></p><p>【字节跳动、猿辅导】字节提前批+猿辅导一面 前端 面经 <a href="https://www.nowcoder.com/discuss/220884" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/220884</a></p><p>【字节跳动】字节跳动前端面经, 已拿意向书 <a href="https://www.nowcoder.com/discuss/213424" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/213424</a></p><p>【字节跳动】字节跳动 深圳抖音 提前批前端 三面+HR面 已拿意向书 <a href="https://www.nowcoder.com/discuss/213863" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/213863</a></p><p>【字节跳动、瓜子、360、猿辅导、中信银行、老虎】头条猿辅导瓜子老虎证券等前端面经 <a href="https://www.nowcoder.com/discuss/213693" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/213693</a></p><p>【字节跳动】抖音前端凉经 <a href="https://www.nowcoder.com/discuss/212448" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/212448</a></p><p>【字节跳动】字节跳动提前批前端，已拿意向书 <a href="https://www.nowcoder.com/discuss/210817" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/210817</a></p><p>【字节跳动】字节跳动提前批前端一面凉经 <a href="https://www.nowcoder.com/discuss/210083" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/210083</a></p><p>【字节跳动】字节跳动 互娱 前端一面凉经 <a href="https://www.nowcoder.com/discuss/207553" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207553</a></p><p>【字节跳动】字节跳动ToB业务前端提前批一面凉面 <a href="https://www.nowcoder.com/discuss/207409" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207409</a></p><p>【字节跳动】字节跳动提前批前端三面面经 <a href="https://www.nowcoder.com/discuss/208384" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/208384</a></p><p>【字节跳动】字节跳动提前批前端3面+HR面 面经 <a href="https://www.nowcoder.com/discuss/208931" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/208931</a></p><p>【字节跳动】字节前端一面凉经 <a href="https://www.nowcoder.com/discuss/206457" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/206457</a></p><p>【字节跳动】字节跳动游戏平台 前端三面凉经 <a href="https://www.nowcoder.com/discuss/205511" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/205511</a></p><p>【字节跳动】字节跳动提前批前端岗一面面经 <a href="https://www.nowcoder.com/discuss/205969" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/205969</a></p><p>【字节跳动】字节跳动提前批前端岗一面面经 <a href="https://www.nowcoder.com/discuss/205969" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/205969</a></p><p>【字节跳动】字节跳动to B提前批前端一面（攒个人品） <a href="https://www.nowcoder.com/discuss/203874" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/203874</a></p><p>【字节跳动】记一次字节跳动前端面试，四轮技术面通过，已拿offer <a href="https://www.nowcoder.com/discuss/204314" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/204314</a></p><p>【字节跳动】字节跳动一面总结（前端技术岗） <a href="https://www.nowcoder.com/discuss/204829" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/204829</a></p><p>移动端</p><p>ios</p><p>【字节跳动】头条ios开发 一面C++ <a href="https://www.nowcoder.com/discuss/306888" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/306888</a></p><p>【字节跳动】双非本科非科班 抖音Android面筋（被调剂到iOS了） <a href="https://www.nowcoder.com/discuss/300246" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/300246</a></p><p>【字节跳动】回馈牛客！【深圳字节跳动】ios移动端已拿意向书 <a href="https://www.nowcoder.com/discuss/212124" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/212124</a></p><p>安卓</p><p>【字节跳动】字节安卓社招面经来啦 <a href="https://www.nowcoder.com/discuss/302228" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/302228</a></p><p>【字节跳动】字节安卓开发一二三hr面面经，赠送春招实习面经 <a href="https://www.nowcoder.com/discuss/276777" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/276777</a></p><p>【字节跳动、滴滴、哔哩哔哩、腾讯】安卓方向秋招面经记录 <a href="https://www.nowcoder.com/discuss/229649" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/229649</a></p><p>【字节跳动、OPPO】字节跳动、oppo安卓开发面筋 <a href="https://www.nowcoder.com/discuss/223431" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/223431</a></p><p>【字节跳动】补发：字节跳动安卓开发实习三轮面经 <a href="https://www.nowcoder.com/discuss/203703" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/203703</a></p><p>【字节跳动】头条提前批安卓岗面经 <a href="https://www.nowcoder.com/discuss/204672" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/204672</a></p><p>测试/测开</p><p>【字节跳动】字节跳动测试开发—二面面经 <a href="https://www.nowcoder.com/discuss/351722" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/351722</a></p><p>【字节跳动】字节跳动头条研发—-测试开发一面面经 <a href="https://www.nowcoder.com/discuss/351378" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/351378</a></p><p>【字节跳动】字节跳动测试开发一面面经 <a href="https://www.nowcoder.com/discuss/348347" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/348347</a></p><p>【字节跳动】字节跳动，测试工程师面经 <a href="https://www.nowcoder.com/discuss/344652" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/344652</a></p><p>【字节跳动】字节跳动-互娱研发-测试工程师 <a href="https://www.nowcoder.com/discuss/326346" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/326346</a></p><p>【字节跳动】还愿字节+测试面经 <a href="https://www.nowcoder.com/discuss/311344" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/311344</a></p><p>【字节跳动】字节跳动测试开发内推(实习生/秋招) <a href="https://www.nowcoder.com/discuss/302486" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/302486</a></p><p>【字节跳动】字节跳动测试开发工程师三次面试凉经 <a href="https://www.nowcoder.com/discuss/298626" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/298626</a></p><p>【字节跳动】字节跳动测试工程师-头条研发面经 <a href="https://www.nowcoder.com/discuss/299077" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/299077</a></p><p>【字节跳动】字节跳动测试开发（测开）一、二、三技术面经 <a href="https://www.nowcoder.com/discuss/289856" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/289856</a></p><p>【字节跳动】字节跳动，客户端测试开发岗一面 <a href="https://www.nowcoder.com/discuss/275572" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/275572</a></p><p>【字节跳动】2019.07字节跳动 测试开发技术面 <a href="https://www.nowcoder.com/discuss/213808" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/213808</a></p><p>【字节跳动】字节提前批测试开发三面 <a href="https://www.nowcoder.com/discuss/210***" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/210***</a></p><p>【字节跳动】回馈一下牛客网（字节跳动测试开发一二面凉经） <a href="https://www.nowcoder.com/discuss/209199" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/209199</a></p><p>【字节跳动】回馈一下牛客网（字节跳动测试开发一二面凉经） <a href="https://www.nowcoder.com/discuss/209199" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/209199</a></p><p>【字节跳动】2019字节跳动秋招提前批测试开发岗一面 <a href="https://www.nowcoder.com/discuss/203384" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/203384</a></p><p>【字节跳动】面经：字节跳动测试开发提前批面经 <a href="https://www.nowcoder.com/discuss/203453" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/203453</a></p><p>【字节跳动】字节跳动游戏测试开发二面凉经 <a href="https://www.nowcoder.com/discuss/204107" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/204107</a></p><p>【字节跳动】字节跳动 测试开发提前批一二面 <a href="https://www.nowcoder.com/discuss/205153" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/205153</a></p><p>【字节跳动】字节跳动测试提前批一面 <a href="https://www.nowcoder.com/discuss/203485" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/203485</a></p><p>【字节跳动】字节跳动 测试一面凉经 <a href="https://www.nowcoder.com/discuss/205286" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/205286</a></p><p>【字节跳动】头条测试工程师一面 <a href="https://www.nowcoder.com/discuss/205092" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/205092</a></p><p>【字节跳动】字节测开实习一面(视频面) <a href="https://www.nowcoder.com/discuss/341318" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/341318</a></p><p>【字节跳动】字节 测开 三面 凉经 <a href="https://www.nowcoder.com/discuss/317807" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/317807</a></p><p>【字节跳动】字节测开1-4面面经（收到意向书） <a href="https://www.nowcoder.com/discuss/304858" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/304858</a></p><p>【字节跳动】字节跳动测试开发（测开）一、二、三技术面经 <a href="https://www.nowcoder.com/discuss/289856" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/289856</a></p><p>【字节跳动】测开面经 <a href="https://www.nowcoder.com/discuss/214526" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/214526</a></p><p>【字节跳动】【还愿】头条提前批测开面经 <a href="https://www.nowcoder.com/discuss/213349" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/213349</a></p><p>【字节跳动】字节跳动提前批测开劝退一面面经 <a href="https://www.nowcoder.com/discuss/207520" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207520</a></p><p>【字节跳动】抖音火山测开凉经 <a href="https://www.nowcoder.com/discuss/208097" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/208097</a></p><p>【字节跳动】字节跳动 游戏测开一二三面面经 <a href="https://www.nowcoder.com/discuss/204117" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/204117</a></p><p>【字节跳动】字节跳动游戏提前批-杭州-测开三面 <a href="https://www.nowcoder.com/discuss/204318" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/204318</a></p><p>数据分析</p><p>【字节跳动】字节 数据分析面经 <a href="https://www.nowcoder.com/discuss/344423" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/344423</a></p><p>【字节跳动/网易 】字节跳动/网易 数据分析 社招面经 <a href="https://www.nowcoder.com/discuss/330721" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/330721</a></p><p>【字节跳动】字节跳动数据分析一面、二面面经（已凉） <a href="https://www.nowcoder.com/discuss/322985" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/322985</a></p><p>【字节跳动】字节跳动 数据分析 10月的offer 部分面经 <a href="https://www.nowcoder.com/discuss/322770" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/322770</a></p><p>【字节跳动】攒人品贴 - 字节/头条数据分析面试一面二面 <a href="https://www.nowcoder.com/discuss/314832" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/314832</a></p><p>【字节跳动】字节跳动 数据分析二面 面试已完成？（附简单面经） <a href="https://www.nowcoder.com/discuss/301369" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/301369</a></p><p>【字节跳动】字节跳动数据分析一面 <a href="https://www.nowcoder.com/discuss/267795" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/267795</a></p><p>【字节跳动】字节跳动_数据分析： 一面：0828凉凉 <a href="https://www.nowcoder.com/discuss/236629" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/236629</a></p><p>【字节跳动】字节跳动 数据分析 一面 <a href="https://www.nowcoder.com/discuss/230722" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/230722</a></p><p>【字节跳动】字节跳动数据分析一面凉经… <a href="https://www.nowcoder.com/discuss/219080" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/219080</a></p><p>【字节跳动】字节跳动秋招 数据分析 一面 <a href="https://www.nowcoder.com/discuss/219004" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/219004</a></p><p>【字节跳动】字节跳动 数据分析 产品方向 日常实习 面经 <a href="https://www.nowcoder.com/discuss/207493" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207493</a></p><p>【爱奇艺、字节跳动、映客直播】我的面试经历-数据分析实习生 <a href="https://www.nowcoder.com/discuss/204273" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/204273</a></p><p>算法</p><p>【小米、海格、旷视、快看、美团、百度、快手、字节跳动】算法转C++开发，我的秋招面经(&gt;o&lt;) <a href="https://www.nowcoder.com/discuss/302094" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/302094</a></p><p>【字节跳动】技术面试前半段基础知识答得不好，为什么还要接着问算法题 <a href="https://www.nowcoder.com/discuss/207765" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207765</a></p><p>【百度、字节跳动】算法面经：百度，字节跳动 <a href="https://www.nowcoder.com/discuss/350817" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/350817</a></p><p>【字节跳动】回报牛客：发一下字节算法工程师面经，时间久了只能发个大概。 <a href="https://www.nowcoder.com/discuss/330565" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/330565</a></p><p>【VIVO、TP_LINK、字节跳动、百度、华为】秋招总结：非机器学习科班学生漫长的算法工程师上岸之旅 <a href="https://www.nowcoder.com/discuss/326300" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/326300</a></p><p>【字节跳动】字节跳动——机器人算法工程师（视频面试） <a href="https://www.nowcoder.com/discuss/323272" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/323272</a></p><p>【TP_LINK、拼多多、欢聚时代、旷视、美团、字节跳动】回馈牛客，发一波2019算法秋招面经 <a href="https://www.nowcoder.com/discuss/313708" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/313708</a></p><p>【360、微博、百度、字节跳动】广告算法秋招总面经 <a href="https://www.nowcoder.com/discuss/312020" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/312020</a></p><p>【字节跳动】字节跳动效率工程团队 算法实习生 一面凉经 <a href="https://www.nowcoder.com/discuss/311673" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/311673</a></p><p>【字节跳动、百度、依图、拼多多、海康、美团】算法上岸，特别回馈一下牛客上，发一波面经，祝各位前途似锦 <a href="https://www.nowcoder.com/discuss/302700" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/302700</a></p><p>【字节跳动、华为】【面经】字节跳动/华为 算法实习面试 <a href="https://www.nowcoder.com/discuss/275818" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/275818</a></p><p>【依图、海康、商汤、大疆、字节跳动】秋招小结：感受+面经（CV算法岗） - 09.07 <a href="https://www.nowcoder.com/discuss/248664" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/248664</a></p><p>【字节跳动】字节跳动 头条 算法 面经 已拿offer意向书 <a href="https://www.nowcoder.com/discuss/235500" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/235500</a></p><p>【字节跳动】字节跳动-ailab-视觉算法面经 <a href="https://www.nowcoder.com/discuss/229358" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/229358</a></p><p>【字节跳动】字节跳动算法岗一二面面经 <a href="https://www.nowcoder.com/discuss/227743" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/227743</a></p><p>【字节跳动】字节跳动算法工程师岗一二三面经 <a href="https://www.nowcoder.com/discuss/226960" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/226960</a></p><p>【字节跳动】字节跳动算法二面凉经 <a href="https://www.nowcoder.com/discuss/226706" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/226706</a></p><p>【字节跳动】字节跳动算法岗一面凉经 <a href="https://www.nowcoder.com/discuss/226619" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/226619</a></p><p>【字节跳动】头条提前批算法面经（2技术面+1leader面） <a href="https://www.nowcoder.com/discuss/220966" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/220966</a></p><p>【字节跳动】字节跳动 算法 已拿意向书 <a href="https://www.nowcoder.com/discuss/216672" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/216672</a></p><p>【字节跳动】字节跳动算法岗提前批面经 <a href="https://www.nowcoder.com/discuss/215883" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/215883</a></p><p>【字节跳动】头条算法提前批三面面经 <a href="https://www.nowcoder.com/discuss/213671" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/213671</a></p><p>【字节跳动】还愿，收到字节跳动提前批算法岗offer了 <a href="https://www.nowcoder.com/discuss/212439" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/212439</a></p><p>【字节跳动】回馈牛客，字节算法三面许愿求offer <a href="https://www.nowcoder.com/discuss/211763" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/211763</a></p><p>【字节跳动】深圳抖音图像图形算法三面面经(已获意向书) <a href="https://www.nowcoder.com/discuss/211382" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/211382</a></p><p>【字节跳动】字节跳动计算机视觉算法面经 <a href="https://www.nowcoder.com/discuss/210829" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/210829</a></p><p>【字节跳动】[字节跳动/头条] 算法提前批三轮面经，前来回馈广大牛油们 <a href="https://www.nowcoder.com/discuss/210036" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/210036</a></p><p>【字节跳动】字节跳动算法岗三面面经 <a href="https://www.nowcoder.com/discuss/207105" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207105</a></p><p>【字节跳动】字节跳动提前批算法工程师面经 <a href="https://www.nowcoder.com/discuss/207092" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207092</a></p><p>【字节跳动】OPPO视频面（NLP算法），凉经 <a href="https://www.nowcoder.com/discuss/206740" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/206740</a></p><p>【字节跳动】字节跳动头条研发算法一面 <a href="https://www.nowcoder.com/discuss/207317" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207317</a></p><p>【字节跳动】算法岗提前批凉经【字节跳动+京东】 <a href="https://www.nowcoder.com/discuss/207287" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207287</a></p><p>【字节跳动】头条 机器学习算法一面 <a href="https://www.nowcoder.com/discuss/207712" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/207712</a></p><p>【字节跳动】字节跳动算法工程师面经+个人疑问 <a href="https://www.nowcoder.com/discuss/209478" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/209478</a></p><p>【字节跳动】字节跳动 AILab提前批算法工程师面经(已收到offer) <a href="https://www.nowcoder.com/discuss/206226" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/206226</a></p><p>【字节跳动】字节跳动CV算法一面凉经 <a href="https://www.nowcoder.com/discuss/206593" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/206593</a></p><p>【字节跳动】【字节跳动算法岗提前批1+2视频面】趁热分享 <a href="https://www.nowcoder.com/discuss/205964" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/205964</a></p><p>【字节跳动】字节跳动ai lab cv算法面经（我来反馈攒人品了） <a href="https://www.nowcoder.com/discuss/205843" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/205843</a></p><p>【字节跳动】字节跳动 Data 算法工程师 广告/AML 提前批3面面经 <a href="https://www.nowcoder.com/discuss/205736" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/205736</a></p><p>【字节跳动】头条算法最新凉经 <a href="https://www.nowcoder.com/discuss/206065" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/206065</a></p><p>【字节跳动】【字节跳动算法岗提前批1+2视频面】趁热分享 <a href="https://www.nowcoder.com/discuss/205964" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/205964</a></p><p>【字节跳动】头条机器学习算法岗面试记录 <a href="https://www.nowcoder.com/discuss/205260" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/205260</a></p><p>非技术</p><p>运营</p><p>【字节跳动】字节跳动商业产品运营经理三面面经 <a href="https://www.nowcoder.com/discuss/232127" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/232127</a></p><p>【字节跳动】字节跳动产品运营面经（已完成一二三面 许愿意向书） <a href="https://www.nowcoder.com/discuss/226872" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/226872</a></p><p>【字节跳动】字节跳动商业化运营管培生面经 <a href="https://www.nowcoder.com/discuss/324886" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/324886</a></p><p>【字节跳动】字节跳动商业化运营管培 base成都 三面过经 <a href="https://www.nowcoder.com/discuss/291433" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/291433</a></p><p>【字节跳动】字节跳动游戏提前批游戏运营管理面经（3面+HR） <a href="https://www.nowcoder.com/discuss/210136" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/210136</a></p><p>商业化</p><p>【字节跳动】字节商业化产品实习面经，在线许愿 <a href="https://www.nowcoder.com/discuss/347555" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/347555</a></p><p>【字节跳动】字节跳动商业化运营管培生面经 <a href="https://www.nowcoder.com/discuss/324886" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/324886</a></p><p>【字节跳动】字节跳动商业化运营管培 base成都 三面过经 <a href="https://www.nowcoder.com/discuss/291433" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/291433</a></p><p>【字节跳动】字节跳动商业化营销策划一面面经-base厦门la分公司 <a href="https://www.nowcoder.com/discuss/299516" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/299516</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;# 字节&lt;/p&gt;
&lt;p&gt;作者：*?&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://www.nowcoder.com/discuss/485900?source_id=profile_create&amp;amp;channel=1009&quot; target=&quot;_blank&quot; r
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/09/29/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8B%20ArrayBlockingQueue/"/>
    <id>http://yoursite.com/2020/09/29/源码阅读之 ArrayBlockingQueue/</id>
    <published>2020-09-29T12:16:10.375Z</published>
    <updated>2020-09-29T12:16:10.509Z</updated>
    
    <content type="html"><![CDATA[<p>源码阅读之 ArrayBlockingQueue</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;源码阅读之 ArrayBlockingQueue&lt;/p&gt;

      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Linux 权限.</title>
    <link href="http://yoursite.com/2020/09/12/linux%E6%9D%83%E9%99%90/"/>
    <id>http://yoursite.com/2020/09/12/linux权限/</id>
    <published>2020-09-12T06:56:15.000Z</published>
    <updated>2020-10-28T09:02:50.640Z</updated>
    
    <content type="html"><![CDATA[<p>在 Linux 中，增加用户或改变用户的组属性可以使用 <code>useradd</code> 或者 <code>usermod</code> 命令。<code>useradd</code> 增加一个新用户或者更新默认新用户信息。<code>usermod</code> 则是更改用户帐户属性，例如将其添加到一个已有的组中。</p><p>在 Linux 用户系统中存在两类组。第一类是主要用户组，第二类是附加用户组。所有的用户帐户及相关信息都存储在 <code>/etc/passwd</code> 文件中，<code>/etc/shadow</code> 和 <code>/etc/group</code> 文件存储了用户信息。</p><h2 id="useradd-示例-–-增加一个新用户到附加用户组-¶"><a href="#useradd-示例-–-增加一个新用户到附加用户组-¶" class="headerlink" title="useradd 示例 – 增加一个新用户到附加用户组 ¶"></a>useradd 示例 – 增加一个新用户到附加用户组 <a href="#useradd_1">¶</a></h2><p>新增加一个用户并将其列入一个已有的用户组中需要用到 <code>useradd</code> 命令。如果还没有这个用户组，可以先创建该用户组。</p><p>命令参数如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">useradd -G &#123;group-name&#125; username</span><br></pre></td></tr></table></figure><p>例如，我们要创建一个新用户 xjj并将其添加到用户组 developers 中。首先需要以 root 用户身份登录到系统中。先确认一下是否存在 developers 这个用户组，在命令行输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\# grep developers /etc/group</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">developers:x:1124:</span><br></pre></td></tr></table></figure><p>如果看不到任何输出，那么就需要先创建这个用户组了，使用 <code>groupadd</code> 命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\# groupadd xjj</span><br></pre></td></tr></table></figure><p>然后创建用户 xjj并将其加入到 developers 用户组：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\# useradd -G xjj dl</span><br></pre></td></tr></table></figure><p>为用户 xjj设置密码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\# passwd xjj</span><br></pre></td></tr></table></figure><p>为确保已经将该用户正确的添加到 developers 用户组中，可以查看该用户的属性，使用 <code>id</code> 命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\# id xjj</span><br></pre></td></tr></table></figure><p>前面命令中用到的大写的 G （-G） 参数就是为了将用户添加到一个附加用户组中，而同时还会为此用户创建一个属于他自己的新组 如果要将该用户同时增加到多个附加用户组中，可以使用英文半角的逗号来分隔多个附加组名（不要加空格）。例如，同时将 xjj 增加到 admins, ftp, www, 和 developers 用户组中，可以输入以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\# useradd -G admins,ftp,www,developers cnzhx</span><br></pre></td></tr></table></figure><h2 id="useradd-示例-–-增加一个新用户到主要用户组-¶"><a href="#useradd-示例-–-增加一个新用户到主要用户组-¶" class="headerlink" title="useradd 示例 – 增加一个新用户到主要用户组 ¶"></a>useradd 示例 – 增加一个新用户到主要用户组 <a href="#useradd_2">¶</a></h2><p>要增加用户 xjj到组 developers，可以使用下面的指令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">\# useradd -g developers xjj </span><br><span class="line"># id xjj</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uid=1123(cnzhx) gid=1124(developers) groups=1124(developers)</span><br></pre></td></tr></table></figure><p>请注意如前面的示例的区别，这里使用了小写字母 g （-g）作为参数，此时用户的主要用户组不再是 xjj而直接就是 developers。</p><p>小写字母 g （-g）将新增加的用户初始化为指定为登录组（主要用户组）。此组名必须已经存在。组号（gid）即是此已有组的组号。</p><h2 id="usermod-示例-–-将一个已有用户增加到一个已有用户组中-¶"><a href="#usermod-示例-–-将一个已有用户增加到一个已有用户组中-¶" class="headerlink" title="usermod 示例 – 将一个已有用户增加到一个已有用户组中 ¶"></a>usermod 示例 – 将一个已有用户增加到一个已有用户组中 <a href="#usermod">¶</a></h2><p>将一个已有用户 xjj增加到一个已有用户组 apache 中，使此用户组成为该用户的附加用户组，可以使用带 -a 参数的 <code>usermod</code>  指令。-a 代表 append， 也就是将用户添加到新用户组中而不必离开原有的其他用户组。不过需要与 -G 选项配合使用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\# usermod -a -G apache xjj</span><br></pre></td></tr></table></figure><p>如果要同时将 xjj 的主要用户组改为 apache，则直接使用 -g 选项：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\# usermod -g apache xjj</span><br></pre></td></tr></table></figure><p>如果要将一个用户从某个组中删除，则</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gpasswd -d user group</span><br></pre></td></tr></table></figure><p>但是这个时候需要保证 group 不是 user 的主组。</p><h2 id="附：管理用户（user）和用户组（group）的相关工具或命令-¶"><a href="#附：管理用户（user）和用户组（group）的相关工具或命令-¶" class="headerlink" title="附：管理用户（user）和用户组（group）的相关工具或命令 ¶"></a>附：管理用户（user）和用户组（group）的相关工具或命令 <a href="#commands">¶</a></h2><p><strong>1）管理用户（user）的工具或命令</strong></p><p><code>useradd    注：添加用户  adduser    注：添加用户  passwd     注：为用户设置密码  usermod    注：修改用户命令，可以通过usermod 来修改登录名、用户的家目录等等；  pwcov      注：同步用户从/etc/passwd 到/etc/shadow  pwck       注：pwck是校验用户配置文件/etc/passwd 和/etc/shadow 文件内容是否合法或完整；  pwunconv   注：是pwcov 的立逆向操作，是从/etc/shadow和 /etc/passwd 创建/etc/passwd ，然后会删除 /etc/shadow 文件；  finger     注：查看用户信息工具  id         注：查看用户的UID、GID及所归属的用户组  chfn       注：更改用户信息工具  su         注：用户切换工具  sudo       注：sudo 是通过另一个用户来执行命令（execute a command as another user），su 是用来切换用户，然后通过切换到的用户来完成相应的任务，但sudo 能后面直接执行命令，比如sudo 不需要root 密码就可以执行root 赋与的执行只有root才能执行相应的命令；但得通过visudo 来编辑/etc/sudoers来实现；  visudo     注：visodo 是编辑 /etc/sudoers 的命令；也可以不用这个命令，直接用vi 来编辑 /etc/sudoers 的效果是一样的；  sudoedit   注：和sudo 功能差不多；</code></p><p><strong>2）管理用户组（group）的工具或命令</strong><br><code>groupadd    注：添加用户组；  groupdel    注：删除用户组；  groupmod    注：修改用户组信息  groups      注：显示用户所属的用户组  grpck  grpconv     注：通过/etc/group和/etc/gshadow 的文件内容来同步或创建/etc/gshadow ，如果/etc/gshadow 不存在则创建；  grpunconv   注：通过/etc/group 和/etc/gshadow 文件内容来同步或创建/etc/group ，然后删除gshadow文件；</code></p><p>将一个用户添加到某个组，即可让此用户拥有该组的权限。比如在<a href="https://cnzhx.net/blog/vps-centos-6-lamp-phpmyadmin/" title="Linode VPS 上 CentOS 6 安装 LAMP + phpMyAdmin 记录" target="_blank" rel="noopener">配置 VPS 上的 LAMP 服务器</a>的时候，运行网站的 apache 用户修改的文件，如果服务器管理用户 cnzhx（可以通过 ssh 登录到服务器）需要修改此文件的话，就可以将 xjj加入到 apache 组中达到目的</p><h2 id="更改文件权限-（chmod-命令）"><a href="#更改文件权限-（chmod-命令）" class="headerlink" title="更改文件权限 （chmod 命令）"></a>更改文件权限 （chmod 命令）</h2><h3 id="一般使用格式"><a href="#一般使用格式" class="headerlink" title="一般使用格式"></a>一般使用格式</h3><blockquote><p>chmod [可选项] <mode> <file...></file...></mode></p></blockquote><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">可选项：</span><br><span class="line">  -c, --changes          like verbose but report only when a change is made (若该档案权限确实已经更改，才显示其更改动作)</span><br><span class="line">  -f, --silent, --quiet  suppress most error messages  （若该档案权限无法被更改也不要显示错误讯息）</span><br><span class="line">  -v, --verbose          output a diagnostic <span class="keyword">for</span> every file processed（显示权限变更的详细资料）</span><br><span class="line">       --no-preserve-root  <span class="keyword">do</span> not treat <span class="string">'/'</span> specially (the default)</span><br><span class="line">       --preserve-root    fail to operate recursively on <span class="string">'/'</span></span><br><span class="line">       --reference=RFILE  use RFILE<span class="string">'s mode instead of MODE values</span></span><br><span class="line"><span class="string">  -R, --recursive        change files and directories recursively （以递归的方式对目前目录下的所有档案与子目录进行相同的权限变更)</span></span><br><span class="line"><span class="string">       --help显示此帮助信息</span></span><br><span class="line"><span class="string">       --version显示版本信息</span></span><br><span class="line"><span class="string">mode ：权限设定字串，详细格式如下：</span></span><br><span class="line"><span class="string">[ugoa...][[+-=][rwxX]...][,...]，其中</span></span><br><span class="line"><span class="string">[ugoa...]</span></span><br><span class="line"><span class="string">u 表示该档案的拥有者，g 表示与该档案的拥有者属于同一个群体(group)者，o 表示其他以外的人，a 表示所有（包含上面三者）。</span></span><br><span class="line"><span class="string">[+-=]</span></span><br><span class="line"><span class="string">+ 表示增加权限，- 表示取消权限，= 表示唯一设定权限。</span></span><br><span class="line"><span class="string">[rwxX]</span></span><br><span class="line"><span class="string">r 表示可读取，w 表示可写入，x 表示可执行，X 表示只有当该档案是个子目录或者该档案已经被设定过为可执行。</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">file...</span></span><br><span class="line"><span class="string">文件列表（单个或者多个文件、文件夹）</span></span><br></pre></td></tr></table></figure><p>范例：</p><ul><li>设置所有用户可读取文件 a.conf</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chmod ugo+r a.sh </span><br><span class="line">或 </span><br><span class="line">chmod a+r  a.conf</span><br></pre></td></tr></table></figure><ul><li>设置 <a href="http://c.sh/" target="_blank" rel="noopener">c.sh</a> 只有 拥有者可以读写及执行</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod u+rwx c.sh</span><br></pre></td></tr></table></figure><ul><li>设置文件 a.conf 与 b.xml 权限为拥有者与其所属同一个群组 可读写，其它组可读不可写</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod a+r,ug+w,o-w a.conf b.xml</span><br></pre></td></tr></table></figure><ul><li>设置当前目录下的所有档案与子目录皆设为任何人可读写</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod -R a+rw *</span><br></pre></td></tr></table></figure><h3 id="数字权限使用格式"><a href="#数字权限使用格式" class="headerlink" title="数字权限使用格式"></a>数字权限使用格式</h3><p>在这种使用方式中，首先我们需要了解数字如何表示权限。 首先，我们规定 数字 4 、2 和 1 表示读、写、执行权限（具体原因可见下节权限详解内容），即 r=4，w=2，x=1 。此时其他的权限组合也可以用其他的八进制数字表示出来，如： rwx = 4 + 2 + 1 = 7 rw = 4 + 2 = 6 rx = 4 +1 = 5 即</p><p>若要同时设置 rwx (可读写运行） 权限则将该权限位 设置 为 4 + 2 + 1 = 7 若要同时设置 rw- （可读写不可运行）权限则将该权限位 设置 为 4 + 2 = 6 若要同时设置 r-x （可读可运行不可写）权限则将该权限位 设置 为 4 +1 = 5</p><p>上面我们提到，每个文件都可以针对三个粒度，设置不同的 rwx(读写执行)权限。即我们可以用用三个 8 进制数字分别表示 拥有者 、群组 、其它组 ( u、 g 、o) 的权限详情，并用 chmod 直接加三个 8 进制数字的方式直接改变文件权限。语法格式为 ：</p><blockquote><p>chmod <abc> file…</abc></p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">其中</span><br><span class="line">a,b,c各为一个数字，分别代表User、Group、及Other的权限。</span><br><span class="line">相当于简化版的</span><br><span class="line">chmod u=权限,g=权限,o=权限 file...</span><br><span class="line">而此处的权限将用8进制的数字来表示User、Group、及Other的读、写、执行权限</span><br></pre></td></tr></table></figure><p>范例：</p><ul><li>设置所有人可以读写及执行</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 777 file  (等价于  chmod u=rwx,g=rwx,o=rwx file 或  chmod a=rwx file)</span><br></pre></td></tr></table></figure><ul><li>设置拥有者可读写，其他人不可读写执行</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 600 file (等价于  chmod u=rw,g=---,o=--- file 或 chmod u=rw,go-rwx file )</span><br></pre></td></tr></table></figure><h2 id="更改文件拥有者（chown-命令）"><a href="#更改文件拥有者（chown-命令）" class="headerlink" title="更改文件拥有者（chown 命令）"></a>更改文件拥有者（chown 命令）</h2><p>linux/Unix 是多人多工作业系统，每个的文件都有拥有者（所有者），如果我们想变更文件的拥有者（利用 chown 将文件拥有者加以改变），一般只有系统管理员 (root) 拥有此操作权限，而普通用户则没有权限将自己或者别人的文件的拥有者设置为别人。</p><p>语法格式：</p><blockquote><p>chown [可选项] user[:group] file…</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">使用权限：root</span><br><span class="line"></span><br><span class="line">说明：</span><br><span class="line">[可选项] : 同上文chmod</span><br><span class="line">user : 新的文件拥有者的使用者 </span><br><span class="line">group : 新的文件拥有者的使用者群体(group)</span><br></pre></td></tr></table></figure><p>范例：</p><ul><li>设置文件 d.key、e.scrt 的拥有者设为 users 群体的 tom</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chown tom:users file d.key e.scrt</span><br></pre></td></tr></table></figure><ul><li>设置当前目录下与子目录下的所有文件的拥有者为 users 群体的 James</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chown -R James:users  *</span><br></pre></td></tr></table></figure><h2 id="二、Linux-权限详解"><a href="#二、Linux-权限详解" class="headerlink" title="二、Linux 权限详解"></a>二、Linux 权限详解</h2><p>Linux 系统上对文件的权限有着严格的控制，用于如果相对某个文件执行某种操作，必须具有对应的权限方可执行成功。这也是 Linux 有别于 Windows 的机制，也是基于这个权限机智，Linux 可以有效防止病毒自我运行，因为运行的条件是必须要有运行的权限，而这个权限在 Linux 是用户所赋予的。</p><p>Linux 的文件权限有以下设定：</p><ul><li>Linux 下文件的权限类型一般包括读，写，执行。对应字母为 r、w、x。</li><li>Linux 下权限的属组有 拥有者 、群组 、其它组 三种。每个文件都可以针对这三个属组（粒度），设置不同的 rwx(读写执行) 权限。</li><li>通常情况下，一个文件只能归属于一个用户和组， 如果其它的用户想有这个文件的权限，则可以将该用户加入具备权限的群组，一个用户可以同时归属于多个组。</li></ul><p>如果我们要表示一个文件的所有权限详情，有两种方式：</p><ul><li>第一种是十位二进制表示法，(三个属组每个使用二进制位，再加一个最高位共十位)，可简化为三位八进制形式</li><li>另外一种十二位二进制表示法 (十二个二进制位)，可简化为四位八进制形式</li></ul><h2 id="十位权限表示"><a href="#十位权限表示" class="headerlink" title="十位权限表示"></a>十位权限表示</h2><p>常见的权限表示形式有：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">-rw------- (600)      只有拥有者有读写权限。</span><br><span class="line">-rw-r--r-- (644)      只有 拥有者有读写权限；而 属组用户和 其他用户只有读权限。</span><br><span class="line">-rwx------ (700)     只有拥有者有读、写、执行权限。</span><br><span class="line">-rwxr-xr-x (755)    拥有者有读、写、执行权限；而属组用户和其他用户只有读、执行权限。</span><br><span class="line">-rwx--x--x (711)    拥有者有读、写、执行权限；而属组用户和其他用户只有执行权限。</span><br><span class="line">-rw-rw-rw- (666)   所有用户都有文件读、写权限。</span><br><span class="line">-rwxrwxrwx (777)  所有用户都有读、写、执行权限。</span><br></pre></td></tr></table></figure><p>后九位解析： 我们知道 Linux 权限总共有三个属组，这里我们给每个属组使用三个位置来定义三种操作（读、写、执行）权限，合起来则是权限的后九位。 上面我们用字符表示权限，其中 - 代表无权限，r 代表读权限，w 代表写权限，x 代表执行权限。</p><p>实际上，后九位每个位置的意义（代表某个属组的某个权限）都是固定的，如果我们将各个位置权限的有无用二进制数 1 和 0 来代替，则只读、只写、只执行权限，可以用三位二进制数表示为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">r-- = 100</span><br><span class="line">-w- = 010</span><br><span class="line">--x = 001</span><br><span class="line">--- = 000</span><br></pre></td></tr></table></figure><p>转换成八进制数，则为 r=4, w=2, x=1, -=0（这也就是用数字设置权限时为何是 4 代表读，2 代表写，1 代表执行）</p><p>实际上，我们可以将所有的权限用二进制形式表现出来，并进一步转变成八进制数字：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">rwx = 111 = 7</span><br><span class="line">rw- = 110 = 6</span><br><span class="line">r-x = 101 = 5</span><br><span class="line">r-- = 100 = 4</span><br><span class="line">-wx = 011 = 3</span><br><span class="line">-w- = 010 = 2</span><br><span class="line">--x = 001 = 1</span><br><span class="line">--- = 000 = 0</span><br></pre></td></tr></table></figure><p>由上可以得出，每个属组的所有的权限都可以用一位八进制数表示，每个数字都代表了不同的权限（权值）。如 最高的权限为是 7，代表可读，可写，可执行。</p><p>故 如果我们将每个属组的权限都用八进制数表示，则文件的权限可以表示为三位八进制数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-rw------- =  600</span><br><span class="line">-rw-rw-rw- =  666</span><br><span class="line">-rwxrwxrwx = 777</span><br></pre></td></tr></table></figure><p>关于第一位最高位的解释： 上面我们说到了权限表示中后九位的含义，剩下的第一位代表的是文件的类型，类型可以是下面几个中的一个：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">d代表的是目录(directroy)</span><br><span class="line">-代表的是文件(regular file)</span><br><span class="line">s代表的是套字文件(socket)</span><br><span class="line">p代表的管道文件(pipe)或命名管道文件(named pipe)</span><br><span class="line">l代表的是符号链接文件(symbolic link)</span><br><span class="line">b代表的是该文件是面向块的设备文件(block-oriented device file)</span><br><span class="line">c代表的是该文件是面向字符的设备文件(charcter-oriented device file)</span><br></pre></td></tr></table></figure><h2 id="十二位权限（Linux-附加权限）"><a href="#十二位权限（Linux-附加权限）" class="headerlink" title="十二位权限（Linux 附加权限）"></a>十二位权限（Linux 附加权限）</h2><h3 id="附加权限相关概念"><a href="#附加权限相关概念" class="headerlink" title="附加权限相关概念"></a>附加权限相关概念</h3><p>linux 除了设置正常的读写操作权限外，还有关于一类设置也是涉及到权限，叫做 Linxu 附加权限。包括 SET 位权限（suid，sgid）和粘滞位权限（sticky）。</p><p><strong>SET 位权限：</strong></p><p>suid/sgid 是为了使 “没有取得特权用户要完成一项必须要有特权才可以执行的任务” 而产生的。 一般用于给可执行的程序或脚本文件进行设置，其中 SUID 表示对属主用户增加 SET 位权限，SGID 表示对属组内用户增加 SET 位权限。执行文件被设置了 SUID、SGID 权限后，任何用户执行该文件时，将获得该文件属主、属组账号对应的身份。在许多环境中，suid 和 sgid 很管用，但是不恰当地使用这些位可能使系统的安全遭到破坏。所以应该尽量避免使用 SET 位权限程序。（passwd 命令是为数不多的必须使用 “suid” 的命令之一）。</p><ul><li>suid(set User ID,set UID) 的意思是进程执行一个文件时通常保持进程拥有者的 UID。然而，如果设置了可执行文件的 suid 位，进程就获得了该文件拥有者的 UID。</li><li>sgid(set Group ID,set GID) 意思也是一样，只是把上面的进程拥有者改成进程组就好了。</li></ul><p>SET 位权限表示形式（10 位权限）：</p><p>如果一个文件被设置了 suid 或 sgid 位，会分别表现在所有者或同组用户的权限的可执行位上；如果文件设置了 suid 还设置了 x（执行）位，则相应的执行位表示为 s(小写)。但是，如果没有设置 x 位，它将表示为 S(大写)。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1、-rwsr-xr-x 表示设置了suid，且拥有者有可执行权限</span><br><span class="line">2、-rwSr--r-- 表示suid被设置，但拥有者没有可执行权限</span><br><span class="line">3、-rwxr-sr-x 表示sgid被设置，且群组用户有可执行权限</span><br><span class="line">4、-rw-r-Sr-- 表示sgid被设置，但群组用户没有可执行权限</span><br></pre></td></tr></table></figure><p>设置方式：</p><p>SET 位权限可以通过 chmod 命令设置，给文件加 suid 和 sgid 的命令如下 (类似于上面 chmod 赋予一般权限的命令)：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">chmod u+s filename 设置suid位</span><br><span class="line">chmod u<span class="_">-s</span> filename 去掉suid设置</span><br><span class="line">chmod g+s filename 设置sgid位</span><br><span class="line">chmod g<span class="_">-s</span> filename 去掉sgid设置</span><br></pre></td></tr></table></figure><h4 id="粘滞位权限："><a href="#粘滞位权限：" class="headerlink" title="粘滞位权限："></a>粘滞位权限：</h4><p>粘滞位权限即 sticky。一般用于为目录设置特殊的附加权限，当目录被设置了粘滞位权限后，即便用户对该目录有写的权限，也不能删除该目录中其他用户的文件数据。设置了粘滞位权限的目录，是用 ls 查看其属性时，其他用户权限处的 x 将变为 t。 使用 chmod 命令设置目录权限时，+t、-t 权限模式可分别用于添加、移除粘滞位权限。</p><p>粘滞位权限表示形式（10 位权限）：</p><p>一个文件或目录被设置了粘滞位权限，会表现在其他组用户的权限的可执行位上。如果文件设置了 sticky 还设置了 x（执行）位，其他组用户的权限的可执行位为 t(小写)。但是，如果没有设置 x 位，它将表示为 T(大写)。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1、-rwsr-xr-t 表示设置了粘滞位且其他用户组有可执行权限</span><br><span class="line">2、-rwSr--r-T 表示设置了粘滞位但其他用户组没有可执行权限</span><br></pre></td></tr></table></figure><p>设置方式：</p><p>sticky 权限同样可以通过 chmod 命令设置：</p><blockquote><p>chmod +t &lt;文件列表..&gt;</p></blockquote><h3 id="十二位的权限表示方法"><a href="#十二位的权限表示方法" class="headerlink" title="十二位的权限表示方法"></a>十二位的权限表示方法</h3><p>附加权限除了用十位权限形式表示外，还可以用用十二位字符表示。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">11 10 9 8 7 6 5 4 3 2 1 0</span><br><span class="line">S  G  T r w x r w x r w x</span><br></pre></td></tr></table></figure><p>SGT 分别表示 SUID 权限、SGID 权限、和 粘滞位权限，这十二位分别对应关系如下：</p><p>第 11 位为 SUID 位，第 10 位为 SGID 位，第 9 位为 sticky 位，第 8-0 位对应于上面的三组 rwx 位（后九位）。</p><p>在这十二位的每一位上都置值。如果有相应的权限则为 1， 没有此权限则为 0。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-rw-r-sr-- 的值为： 0 1 0  1 1 0  1 0 0  1 0 0</span><br><span class="line">-rwsr-xr-x 的值为： 1 0 0  1 1 1  1 0 1  1 0 1</span><br><span class="line">-rwsr-sr-x 的值为： 1 1 0  1 1 1  1 0 1  1 0 1 </span><br><span class="line">-rwsr-sr-t 的值为： 1 1 1  1 1 1  1 0 1  1 0 1</span><br></pre></td></tr></table></figure><p>如果将则前三位 SGT 也转换成一个二进制数，则</p><ul><li>suid 的八进制数字是 4</li><li>sgid 的代表数字是 2</li><li>sticky 位代表数字是 1</li></ul><p>这样我们就可以将十二位权限三位三位的转化为 4 个八进制数。其中</p><ul><li>最高的一位八进制数就是 suid，sgdi，sticky 的权值。</li><li>第二位为 拥有者的权值</li><li>第三位为 所属组的权值</li><li>最后一位为 其他组的权值</li></ul><h3 id="附加权限的八进制形式"><a href="#附加权限的八进制形式" class="headerlink" title="附加权限的八进制形式"></a>附加权限的八进制形式</h3><p>通过上面，我们知道，正常权限和附加权限可以用 4 位八进制数表示。类似于正常权限的数字权限赋值模式（使用三位八进制数字赋值）</p><blockquote><p>chmod <abc> file…</abc></p></blockquote><p>我们可以进一步使用 4 位八进制数字同时赋值正常权限和附加权限。</p><blockquote><p>chmod <sabc> file…</sabc></p></blockquote><p>其中 s 是表示附加权限的把八进制数字，abc 与之前一致，分别是对应 User、Group、及 Other（拥有者、群组、其他组）的权限。因为 SUID 对应八进制数字是 4，SGID 对于八进制数字是 2，则 “4755” 表示设置 SUID 权限，“6755”表示同时设置 SUID、SGID 权限。</p><p>我们进一步将上小节的例子中的二进制数转变为八进制表示形式，则</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-rw-r-sr-- = 0 1 0 1 1 0 1 0 0 1 0 0 = 2644 </span><br><span class="line">-rwsr-xr-x = 1 0 0 1 1 1 1 0 1 1 0 1 = 4755</span><br><span class="line">-rwsr-sr-x = 1 1 0 1 1 1 1 0 1 1 0 1 = 6755</span><br><span class="line">-rwsr-sr-t = 1 1 1 1 1 1 1 0 1 1 0 1 = 7755</span><br></pre></td></tr></table></figure><p>对比范例：</p><ul><li>设置 netlogin 的权限为拥有者可读写执行，群组和其他权限为可读可执行</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 755 netlogin</span><br></pre></td></tr></table></figure><ul><li>设置 netlogin 的权限为拥有者可读写执行，群组和其他权限为可读可执行，并且设置 suid</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 4755 netlogin</span><br></pre></td></tr></table></figure><p>chmod 4755 与 chmod 755 对比多了附加权限值 4，这个 4 表示其他用户执行文件时，具有与所有者同样的权限（设置了 SUID）。</p><blockquote><p>为什么要设置 4755 而不是 755？<br>假设 netlogin 是 root 用户创建的一个上网认证程序，如果其他用户要上网也要用到这个程序，那就需要 root 用户运行 chmod 755 netlogin 命令使其他用户也能运行 netlogin。但假如 netlogin 执行时需要访问一些只有 root 用户才有权访问的文件，那么其他用户执行 netlogin 时可能因为权限不够还是不能上网。这种情况下，就可以用 chmod 4755 netlogin 设置其他用户在执行 netlogin 也有 root 用户的权限，从而顺利上网。</p></blockquote><p>在 Linux 命令中，<code>chmod</code>用于<strong>修改文件或者目录的权限</strong>。对于文件或者目录的普通权限，共有 3 种，分别为：</p><ul><li><code>r</code>：读取；</li><li><code>w</code>：写入；</li><li><code>x</code>：执行。</li></ul><p>此外，还有 3 种特殊权限，分别为：</p><ul><li><code>suid</code>：Set User ID；</li><li><code>sgid</code>：Set Group ID；</li><li><code>sticky</code>：粘滞位。</li></ul><p>在此，我们仅介绍如何利用<code>chmod</code>修改文件及目录的普通权限。</p><h3 id="权限范围及代号"><a href="#权限范围及代号" class="headerlink" title="权限范围及代号"></a>权限范围及代号</h3><p>文件及目录的权限范围，包括：</p><ul><li><code>u</code>：User，即文件或目录的拥有者；</li><li><code>g</code>：Group，即文件或目录的所属群组；</li><li><code>o</code>：Other，除了文件或目录拥有者或所属群组之外，其他用户皆属于这个范围；</li><li><code>a</code>：All，即全部的用户，包含拥有者、所属群组以及其他用户。</li></ul><p>权限的代号包括：</p><ul><li><code>r</code>：读取权限，数字代号为<code>4</code>；</li><li><code>w</code>：写入权限，数字代号为<code>2</code>；</li><li><code>x</code>：执行或切换权限，数字代号为<code>1</code>；</li><li><code>-</code>：不具任何权限，数字代号为<code>0</code>；</li><li><code>s</code>：当文件被执行时，根据<code>who</code>参数指定的用户类型设置文件的<code>setuid</code>或者<code>setgid</code>权限。</li></ul><h3 id="语法及选项说明"><a href="#语法及选项说明" class="headerlink" title="语法及选项说明"></a>语法及选项说明</h3><ul><li><p><code>chmod</code>语法：</p><ul><li><code>chmod [-cfRv][--help][--version][&lt;权限范围&gt;+/-/=&lt;权限设置...&gt;][文件或目录...]</code></li><li><code>chmod [-cfRv][--help][--version][数字代号][文件或目录...]</code></li><li><code>chmod [-cfRv][--help][--reference=&lt;参考文件或目录&gt;][--version][文件或目录...]</code></li></ul></li><li><p>选项说明:</p><ul><li><code>-c</code>或<code>--changes</code>：效果类似<code>-v</code>参数，但仅返回更改的部分；</li><li><code>-f</code>或<code>--quiet</code>或<code>--silent</code>：不显示错误信息；</li><li><code>-R</code>或<code>--recursive</code>：递归处理，将指定目录下的所有文件及子目录一并处理；</li><li><code>-v</code>或<code>--verbose</code>：显示指令执行过程；</li><li><code>--help</code>：显示在线帮助信息；</li><li><code>--reference=&lt;参考文件或目录&gt;</code>：把指定文件或目录的权限全部设成和参考文件或目录的权限相同；</li><li><code>--version</code>：显示版本信息；</li><li><code>&lt;权限范围&gt;+&lt;权限设置&gt;</code>：开启权限范围的文件或目录的该项权限设置；</li><li><code>&lt;权限范围&gt;-&lt;权限设置&gt;</code>：关闭权限范围的文件或目录的该项权限设置；</li><li><code>&lt;权限范围&gt;=&lt;权限设置&gt;</code>：指定权限范围的文件或目录的该项权限设置。</li></ul></li></ul><ul><li><p>将用户加入到su组. </p><p>  su 到root 用户.<br>  vim /etc/sudoers<br>  leleyi(用户名)     ALL=(ALL)       ALL.<br>  包保存即可.</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在 Linux 中，增加用户或改变用户的组属性可以使用 &lt;code&gt;useradd&lt;/code&gt; 或者 &lt;code&gt;usermod&lt;/code&gt; 命令。&lt;code&gt;useradd&lt;/code&gt; 增加一个新用户或者更新默认新用户信息。&lt;code&gt;usermod&lt;/code&gt; 
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/09/10/%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81%E6%AE%B5/"/>
    <id>http://yoursite.com/2020/09/10/常用代码段/</id>
    <published>2020-09-10T13:26:36.301Z</published>
    <updated>2020-09-10T13:26:15.468Z</updated>
    
    <content type="html"><![CDATA[<p>PyTorch 最好的资料是<a href="https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/index.html" target="_blank" rel="noopener">官方文档</a>。本文是 PyTorch 常用代码段，在参考资料 <a href="张皓：PyTorch Cookbook">1</a> 的基础上做了一些修补，方便使用时查阅。</p><h2 id="1-基本配置"><a href="#1-基本配置" class="headerlink" title="1. 基本配置"></a>1. 基本配置</h2><h3 id="导入包和版本查询"><a href="#导入包和版本查询" class="headerlink" title="导入包和版本查询"></a>导入包和版本查询</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line">print(torch.__version__)</span><br><span class="line">print(torch.version.cuda)</span><br><span class="line">print(torch.backends.cudnn.version())</span><br><span class="line">print(torch.cuda.get_device_name(<span class="number">0</span>))</span><br></pre></td></tr></table></figure><h3 id="可复现性"><a href="#可复现性" class="headerlink" title="可复现性"></a>可复现性</h3><p>在硬件设备（CPU、GPU）不同时，完全的可复现性无法保证，即使随机种子相同。但是，在同一个设备上，应该保证可复现性。具体做法是，在程序开始的时候固定 torch 的随机种子，同时也把 numpy 的随机种子固定。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">torch.manual_seed(<span class="number">0</span>)</span><br><span class="line">torch.cuda.manual_seed_all(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br></pre></td></tr></table></figure><h3 id="显卡设置"><a href="#显卡设置" class="headerlink" title="显卡设置"></a>显卡设置</h3><p>如果只需要一张显卡</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Device configuration</span></span><br><span class="line">device = torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br></pre></td></tr></table></figure><p>如果需要指定多张显卡，比如 0，1 号显卡。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">'CUDA_VISIBLE_DEVICES'</span>] = <span class="string">'0,1'</span></span><br></pre></td></tr></table></figure><p>也可以在命令行运行代码时设置显卡：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span> python train.py</span><br></pre></td></tr></table></figure><p>清除显存</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cuda.empty_cache()</span><br></pre></td></tr></table></figure><p>也可以使用在命令行重置 GPU 的指令</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi --gpu-reset -i [gpu_id]</span><br></pre></td></tr></table></figure><h2 id="2-张量-Tensor-处理"><a href="#2-张量-Tensor-处理" class="headerlink" title="2. 张量 (Tensor) 处理"></a>2. 张量 (Tensor) 处理</h2><h3 id="张量的数据类型"><a href="#张量的数据类型" class="headerlink" title="张量的数据类型"></a>张量的数据类型</h3><p>PyTorch 有 9 种 CPU 张量类型和 9 种 GPU 张量类型。</p><p>![][img-0]</p><h3 id="张量基本信息"><a href="#张量基本信息" class="headerlink" title="张量基本信息"></a>张量基本信息</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor = torch.randn(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line">print(tensor.type())  <span class="comment"># 数据类型</span></span><br><span class="line">print(tensor.size())  <span class="comment"># 张量的shape，是个元组</span></span><br><span class="line">print(tensor.dim())   <span class="comment"># 维度的数量</span></span><br></pre></td></tr></table></figure><h3 id="命名张量"><a href="#命名张量" class="headerlink" title="命名张量"></a>命名张量</h3><p>张量命名是一个非常有用的方法，这样可以方便地使用维度的名字来做索引或其他操作，大大提高了可读性、易用性，防止出错。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在PyTorch 1.3之前，需要使用注释</span></span><br><span class="line"><span class="comment"># Tensor[N, C, H, W]</span></span><br><span class="line">images = torch.randn(<span class="number">32</span>, <span class="number">3</span>, <span class="number">56</span>, <span class="number">56</span>)</span><br><span class="line">images.sum(dim=<span class="number">1</span>)</span><br><span class="line">images.select(dim=<span class="number">1</span>, index=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># PyTorch 1.3之后</span></span><br><span class="line">NCHW = [‘N’, ‘C’, ‘H’, ‘W’]</span><br><span class="line">images = torch.randn(<span class="number">32</span>, <span class="number">3</span>, <span class="number">56</span>, <span class="number">56</span>, names=NCHW)</span><br><span class="line">images.sum(<span class="string">'C'</span>)</span><br><span class="line">images.select(<span class="string">'C'</span>, index=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 也可以这么设置</span></span><br><span class="line">tensor = torch.rand(<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">2</span>,names=(<span class="string">'C'</span>, <span class="string">'N'</span>, <span class="string">'H'</span>, <span class="string">'W'</span>))</span><br><span class="line"><span class="comment"># 使用align_to可以对维度方便地排序</span></span><br><span class="line">tensor = tensor.align_to(<span class="string">'N'</span>, <span class="string">'C'</span>, <span class="string">'H'</span>, <span class="string">'W'</span>)</span><br></pre></td></tr></table></figure><h3 id="数据类型转换"><a href="#数据类型转换" class="headerlink" title="数据类型转换"></a>数据类型转换</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置默认类型，pytorch中的FloatTensor远远快于DoubleTensor</span></span><br><span class="line">torch.set_default_tensor_type(torch.FloatTensor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 类型转换</span></span><br><span class="line">tensor = tensor.cuda()</span><br><span class="line">tensor = tensor.cpu()</span><br><span class="line">tensor = tensor.float()</span><br><span class="line">tensor = tensor.long()</span><br></pre></td></tr></table></figure><h3 id="torch-Tensor-与-np-ndarray-转换"><a href="#torch-Tensor-与-np-ndarray-转换" class="headerlink" title="torch.Tensor 与 np.ndarray 转换"></a><strong>torch.Tensor 与 np.ndarray 转换</strong></h3><p>除了 CharTensor，其他所有 CPU 上的张量都支持转换为 numpy 格式然后再转换回来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ndarray = tensor.cpu().numpy()</span><br><span class="line">tensor = torch.from_numpy(ndarray).float()</span><br><span class="line">tensor = torch.from_numpy(ndarray.copy()).float() <span class="comment"># If ndarray has negative stride.</span></span><br></pre></td></tr></table></figure><h3 id="Torch-tensor-与-PIL-Image-转换"><a href="#Torch-tensor-与-PIL-Image-转换" class="headerlink" title="Torch.tensor 与 PIL.Image 转换"></a><strong>Torch.tensor 与 PIL.Image 转换</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch中的张量默认采用[N, C, H, W]的顺序，并且数据范围在[0,1]，需要进行转置和规范化</span></span><br><span class="line"><span class="comment"># torch.Tensor -&gt; PIL.Image</span></span><br><span class="line">image = PIL.Image.fromarray(torch.clamp(tensor*<span class="number">255</span>, min=<span class="number">0</span>, max=<span class="number">255</span>).byte().permute(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>).cpu().numpy())</span><br><span class="line">image = torchvision.transforms.functional.to_pil_image(tensor)  <span class="comment"># Equivalently way</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># PIL.Image -&gt; torch.Tensor</span></span><br><span class="line">path = <span class="string">r'./figure.jpg'</span></span><br><span class="line">tensor = torch.from_numpy(np.asarray(PIL.Image.open(path))).permute(<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>).float() / <span class="number">255</span></span><br><span class="line">tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path)) <span class="comment"># Equivalently way</span></span><br></pre></td></tr></table></figure><h3 id="np-ndarray-与-PIL-Image-的转换"><a href="#np-ndarray-与-PIL-Image-的转换" class="headerlink" title="np.ndarray 与 PIL.Image 的转换"></a><strong>np.ndarray 与 PIL.Image 的转换</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">image = PIL.Image.fromarray(ndarray.astype(np.uint8))</span><br><span class="line"></span><br><span class="line">ndarray = np.asarray(PIL.Image.open(path))</span><br></pre></td></tr></table></figure><h3 id="从只包含一个元素的张量中提取值"><a href="#从只包含一个元素的张量中提取值" class="headerlink" title="从只包含一个元素的张量中提取值"></a><strong>从只包含一个元素的张量中提取值</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">value = torch.rand(<span class="number">1</span>).item()</span><br></pre></td></tr></table></figure><h3 id="张量形变"><a href="#张量形变" class="headerlink" title="张量形变"></a><strong>张量形变</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在将卷积层输入全连接层的情况下通常需要对张量做形变处理，</span></span><br><span class="line"><span class="comment"># 相比torch.view，torch.reshape可以自动处理输入张量不连续的情况。</span></span><br><span class="line">tensor = torch.rand(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">shape = (<span class="number">6</span>, <span class="number">4</span>)</span><br><span class="line">tensor = torch.reshape(tensor, shape)</span><br></pre></td></tr></table></figure><h3 id="打乱顺序"><a href="#打乱顺序" class="headerlink" title="打乱顺序"></a><strong>打乱顺序</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor = tensor[torch.randperm(tensor.size(<span class="number">0</span>))]  <span class="comment"># 打乱第一个维度</span></span><br></pre></td></tr></table></figure><h3 id="水平翻转"><a href="#水平翻转" class="headerlink" title="水平翻转"></a><strong>水平翻转</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch不支持tensor[::-1]这样的负步长操作，水平翻转可以通过张量索引实现</span></span><br><span class="line"><span class="comment"># 假设张量的维度为[N, D, H, W].</span></span><br><span class="line">tensor = tensor[:,:,:,torch.arange(tensor.size(<span class="number">3</span>) - <span class="number">1</span>, <span class="number">-1</span>, <span class="number">-1</span>).long()]</span><br></pre></td></tr></table></figure><h3 id="复制张量"><a href="#复制张量" class="headerlink" title="复制张量"></a><strong>复制张量</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Operation                 |  New/Shared memory | Still in computation graph |</span></span><br><span class="line">tensor.clone()            <span class="comment"># |        New         |          Yes               |</span></span><br><span class="line">tensor.detach()           <span class="comment"># |      Shared        |          No                |</span></span><br><span class="line">tensor.detach.clone()()   <span class="comment"># |        New         |          No                |</span></span><br></pre></td></tr></table></figure><h3 id="张量拼接"><a href="#张量拼接" class="headerlink" title="张量拼接"></a><strong>张量拼接</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">注意torch.cat和torch.stack的区别在于torch.cat沿着给定的维度拼接，</span></span><br><span class="line"><span class="string">而torch.stack会新增一维。例如当参数是3个10x5的张量，torch.cat的结果是30x5的张量，</span></span><br><span class="line"><span class="string">而torch.stack的结果是3x10x5的张量。</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">tensor = torch.cat(list_of_tensors, dim=<span class="number">0</span>)</span><br><span class="line">tensor = torch.stack(list_of_tensors, dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h3 id="将整数标签转为-one-hot-编码"><a href="#将整数标签转为-one-hot-编码" class="headerlink" title="将整数标签转为 one-hot 编码"></a><strong>将整数标签转为 one-hot 编码</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pytorch的标记默认从0开始</span></span><br><span class="line">tensor = torch.tensor([<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line">N = tensor.size(<span class="number">0</span>)</span><br><span class="line">num_classes = <span class="number">4</span></span><br><span class="line">one_hot = torch.zeros(N, num_classes).long()</span><br><span class="line">one_hot.scatter_(dim=<span class="number">1</span>, index=torch.unsqueeze(tensor, dim=<span class="number">1</span>), src=torch.ones(N, num_classes).long())</span><br></pre></td></tr></table></figure><h3 id="得到非零元素"><a href="#得到非零元素" class="headerlink" title="得到非零元素"></a><strong>得到非零元素</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">torch.nonzero(tensor)               <span class="comment"># index of non-zero elements</span></span><br><span class="line">torch.nonzero(tensor==<span class="number">0</span>)            <span class="comment"># index of zero elements</span></span><br><span class="line">torch.nonzero(tensor).size(<span class="number">0</span>)       <span class="comment"># number of non-zero elements</span></span><br><span class="line">torch.nonzero(tensor == <span class="number">0</span>).size(<span class="number">0</span>)  <span class="comment"># number of zero elements</span></span><br></pre></td></tr></table></figure><h3 id="判断两个张量相等"><a href="#判断两个张量相等" class="headerlink" title="判断两个张量相等"></a><strong>判断两个张量相等</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.allclose(tensor1, tensor2)  <span class="comment"># float tensor</span></span><br><span class="line">torch.equal(tensor1, tensor2)     <span class="comment"># int tensor</span></span><br></pre></td></tr></table></figure><h3 id="张量扩展"><a href="#张量扩展" class="headerlink" title="张量扩展"></a><strong>张量扩展</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Expand tensor of shape 64*512 to shape 64*512*7*7.</span></span><br><span class="line">tensor = torch.rand(<span class="number">64</span>,<span class="number">512</span>)</span><br><span class="line">torch.reshape(tensor, (<span class="number">64</span>, <span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>)).expand(<span class="number">64</span>, <span class="number">512</span>, <span class="number">7</span>, <span class="number">7</span>)</span><br></pre></td></tr></table></figure><h3 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a><strong>矩阵乘法</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Matrix multiplcation: (m*n) * (n*p) * -&gt; (m*p).</span></span><br><span class="line">result = torch.mm(tensor1, tensor2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Batch matrix multiplication: (b*m*n) * (b*n*p) -&gt; (b*m*p)</span></span><br><span class="line">result = torch.bmm(tensor1, tensor2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Element-wise multiplication.</span></span><br><span class="line">result = tensor1 * tensor2</span><br></pre></td></tr></table></figure><h3 id="计算两组数据之间的两两欧式距离"><a href="#计算两组数据之间的两两欧式距离" class="headerlink" title="计算两组数据之间的两两欧式距离"></a><strong>计算两组数据之间的两两欧式距离</strong></h3><p>利用 broadcast 机制</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dist = torch.sqrt(torch.sum((X1[:,<span class="literal">None</span>,:] - X2) ** <span class="number">2</span>, dim=<span class="number">2</span>))</span><br></pre></td></tr></table></figure><h2 id="3-模型定义和操作"><a href="#3-模型定义和操作" class="headerlink" title="3. 模型定义和操作"></a>3. 模型定义和操作</h2><h3 id="一个简单两层卷积网络的示例"><a href="#一个简单两层卷积网络的示例" class="headerlink" title="一个简单两层卷积网络的示例"></a>一个简单两层卷积网络的示例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># convolutional neural network (2 convolutional layers)</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_classes=<span class="number">10</span>)</span>:</span></span><br><span class="line">        super(ConvNet, self).__init__()</span><br><span class="line">        self.layer1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">16</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>))</span><br><span class="line">        self.layer2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">32</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>))</span><br><span class="line">        self.fc = nn.Linear(<span class="number">7</span>*<span class="number">7</span>*<span class="number">32</span>, num_classes)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        out = self.layer1(x)</span><br><span class="line">        out = self.layer2(out)</span><br><span class="line">        out = out.reshape(out.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        out = self.fc(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = ConvNet(num_classes).to(device)</span><br></pre></td></tr></table></figure><p>卷积层的计算和展示可以用<a href="https://link.zhihu.com/?target=https%3A//ezyang.github.io/convolution-visualizer/index.html" target="_blank" rel="noopener">这个网站</a>辅助。</p><h3 id="双线性汇合（bilinear-pooling）"><a href="#双线性汇合（bilinear-pooling）" class="headerlink" title="双线性汇合（bilinear pooling）"></a><strong>双线性汇合（bilinear pooling）</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X = torch.reshape(N, D, H * W)                        <span class="comment"># Assume X has shape N*D*H*W</span></span><br><span class="line">X = torch.bmm(X, torch.transpose(X, <span class="number">1</span>, <span class="number">2</span>)) / (H * W)  <span class="comment"># Bilinear pooling</span></span><br><span class="line"><span class="keyword">assert</span> X.size() == (N, D, D)</span><br><span class="line">X = torch.reshape(X, (N, D * D))</span><br><span class="line">X = torch.sign(X) * torch.sqrt(torch.abs(X) + <span class="number">1e-5</span>)   <span class="comment"># Signed-sqrt normalization</span></span><br><span class="line">X = torch.nn.functional.normalize(X)                  <span class="comment"># L2 normalization</span></span><br></pre></td></tr></table></figure><h3 id="多卡同步-BN（Batch-normalization）"><a href="#多卡同步-BN（Batch-normalization）" class="headerlink" title="多卡同步 BN（Batch normalization）"></a><strong>多卡同步 BN（Batch normalization）</strong></h3><p>当使用 torch.nn.DataParallel 将代码运行在多张 GPU 卡上时，PyTorch 的 BN 层默认操作是各卡上数据独立地计算均值和标准差，同步 BN 使用所有卡上的数据一起计算 BN 层的均值和标准差，缓解了当批量大小（batch size）比较小时对均值和标准差估计不准的情况，是在目标检测等任务中一个有效的提升性能的技巧。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sync_bn = torch.nn.SyncBatchNorm(num_features, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, </span><br><span class="line">                                 track_running_stats=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="将已有网络的所有-BN-层改为同步-BN-层"><a href="#将已有网络的所有-BN-层改为同步-BN-层" class="headerlink" title="将已有网络的所有 BN 层改为同步 BN 层"></a>将已有网络的所有 BN 层改为同步 BN 层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convertBNtoSyncBN</span><span class="params">(module, process_group=None)</span>:</span></span><br><span class="line">    <span class="string">'''Recursively replace all BN layers to SyncBN layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        module[torch.nn.Module]. Network</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(module, torch.nn.modules.batchnorm._BatchNorm):</span><br><span class="line">        sync_bn = torch.nn.SyncBatchNorm(module.num_features, module.eps, module.momentum, </span><br><span class="line">                                         module.affine, module.track_running_stats, process_group)</span><br><span class="line">        sync_bn.running_mean = module.running_mean</span><br><span class="line">        sync_bn.running_var = module.running_var</span><br><span class="line">        <span class="keyword">if</span> module.affine:</span><br><span class="line">            sync_bn.weight = module.weight.clone().detach()</span><br><span class="line">            sync_bn.bias = module.bias.clone().detach()</span><br><span class="line">        <span class="keyword">return</span> sync_bn</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> name, child_module <span class="keyword">in</span> module.named_children():</span><br><span class="line">            setattr(module, name) = convert_syncbn_model(child_module, process_group=process_group))</span><br><span class="line">        <span class="keyword">return</span> module</span><br></pre></td></tr></table></figure><h3 id="类似-BN-滑动平均"><a href="#类似-BN-滑动平均" class="headerlink" title="类似 BN 滑动平均"></a><strong>类似 BN 滑动平均</strong></h3><p>如果要实现类似 BN 滑动平均的操作，在 forward 函数中要使用原地（inplace）操作给滑动平均赋值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BN</span><span class="params">(torch.nn.Module)</span></span></span><br><span class="line"><span class="class">    <span class="title">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        ...</span><br><span class="line">        self.register_buffer(<span class="string">'running_mean'</span>, torch.zeros(num_features))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        ...</span><br><span class="line">        self.running_mean += momentum * (current - self.running_mean)</span><br></pre></td></tr></table></figure><h3 id="计算模型整体参数量"><a href="#计算模型整体参数量" class="headerlink" title="计算模型整体参数量"></a><strong>计算模型整体参数量</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">num_parameters = sum(torch.numel(parameter) <span class="keyword">for</span> parameter <span class="keyword">in</span> model.parameters())</span><br></pre></td></tr></table></figure><h3 id="查看网络中的参数"><a href="#查看网络中的参数" class="headerlink" title="查看网络中的参数"></a><strong>查看网络中的参数</strong></h3><p>可以通过 model.state_dict() 或者 model.named_parameters() 函数查看现在的全部可训练参数（包括通过继承得到的父类中的参数）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">params = list(model.named_parameters())</span><br><span class="line">(name, param) = params[<span class="number">28</span>]</span><br><span class="line">print(name)</span><br><span class="line">print(param.grad)</span><br><span class="line">print(<span class="string">'-------------------------------------------------'</span>)</span><br><span class="line">(name2, param2) = params[<span class="number">29</span>]</span><br><span class="line">print(name2)</span><br><span class="line">print(param2.grad)</span><br><span class="line">print(<span class="string">'----------------------------------------------------'</span>)</span><br><span class="line">(name1, param1) = params[<span class="number">30</span>]</span><br><span class="line">print(name1)</span><br><span class="line">print(param1.grad)</span><br></pre></td></tr></table></figure><h3 id="模型可视化（使用-pytorchviz）"><a href="#模型可视化（使用-pytorchviz）" class="headerlink" title="模型可视化（使用 pytorchviz）"></a>模型可视化（使用 pytorchviz）</h3><p><a href="https://link.zhihu.com/?target=https%3A//github.com/szagoruyko/pytorchviz" target="_blank" rel="noopener">szagoruyko/pytorchviz​github.com<img src="https://picb.zhimg.com/v2-3ee5eebec876a1c1fe96ed3383fca2a0_ipico.jpg" alt="图标"></a></p><h3 id="类似-Keras-的-model-summary-输出模型信息（使用-pytorch-summary-）"><a href="#类似-Keras-的-model-summary-输出模型信息（使用-pytorch-summary-）" class="headerlink" title="类似 Keras 的 model.summary() 输出模型信息（使用 pytorch-summary ）"></a><strong>类似 Keras 的 model.summary() 输出模型信息（</strong>使用 pytorch-summary <strong>）</strong></h3><p><a href="https://link.zhihu.com/?target=https%3A//github.com/sksq96/pytorch-summary" target="_blank" rel="noopener">sksq96/pytorch-summary​github.com<img src="https://pic2.zhimg.com/v2-eb795090467aa2558529459fded14d03_ipico.jpg" alt="图标"></a></p><p><strong>模型权重初始化</strong></p><p>注意 model.modules() 和 model.children() 的区别：model.modules() 会迭代地遍历模型的所有子层，而 model.children() 只会遍历模型下的一层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Common practise for initialization.</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> model.modules():</span><br><span class="line">    <span class="keyword">if</span> isinstance(layer, torch.nn.Conv2d):</span><br><span class="line">        torch.nn.init.kaiming_normal_(layer.weight, mode=<span class="string">'fan_out'</span>,</span><br><span class="line">                                      nonlinearity=<span class="string">'relu'</span>)</span><br><span class="line">        <span class="keyword">if</span> layer.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            torch.nn.init.constant_(layer.bias, val=<span class="number">0.0</span>)</span><br><span class="line">    <span class="keyword">elif</span> isinstance(layer, torch.nn.BatchNorm2d):</span><br><span class="line">        torch.nn.init.constant_(layer.weight, val=<span class="number">1.0</span>)</span><br><span class="line">        torch.nn.init.constant_(layer.bias, val=<span class="number">0.0</span>)</span><br><span class="line">    <span class="keyword">elif</span> isinstance(layer, torch.nn.Linear):</span><br><span class="line">        torch.nn.init.xavier_normal_(layer.weight)</span><br><span class="line">        <span class="keyword">if</span> layer.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            torch.nn.init.constant_(layer.bias, val=<span class="number">0.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialization with given tensor.</span></span><br><span class="line">layer.weight = torch.nn.Parameter(tensor)</span><br></pre></td></tr></table></figure><h3 id="提取模型中的某一层"><a href="#提取模型中的某一层" class="headerlink" title="提取模型中的某一层"></a><strong>提取模型中的某一层</strong></h3><p>modules() 会返回模型中所有模块的迭代器，它能够访问到最内层，比如 self.layer1.conv1 这个模块，还有一个与它们相对应的是 name_children() 属性以及 named_modules(), 这两个不仅会返回模块的迭代器，还会返回网络层的名字。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取模型中的前两层</span></span><br><span class="line">new_model = nn.Sequential(*list(model.children())[:<span class="number">2</span>] </span><br><span class="line"><span class="comment"># 如果希望提取出模型中的所有卷积层，可以像下面这样操作：</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> model.named_modules():</span><br><span class="line">    <span class="keyword">if</span> isinstance(layer[<span class="number">1</span>],nn.Conv2d):</span><br><span class="line">         conv_model.add_module(layer[<span class="number">0</span>],layer[<span class="number">1</span>])</span><br></pre></td></tr></table></figure><h3 id="部分层使用预训练模型"><a href="#部分层使用预训练模型" class="headerlink" title="部分层使用预训练模型"></a><strong>部分层使用预训练模型</strong></h3><p>注意如果保存的模型是 torch.nn.DataParallel，则当前的模型也需要是</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load_state_dict(torch.load(<span class="string">'model.pth'</span>), strict=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h3 id="将在-GPU-保存的模型加载到-CPU"><a href="#将在-GPU-保存的模型加载到-CPU" class="headerlink" title="将在 GPU 保存的模型加载到 CPU"></a><strong>将在 GPU 保存的模型加载到 CPU</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load_state_dict(torch.load(<span class="string">'model.pth'</span>, map_location=<span class="string">'cpu'</span>))</span><br></pre></td></tr></table></figure><h2 id="导入另一个模型的相同部分到新的模型"><a href="#导入另一个模型的相同部分到新的模型" class="headerlink" title="导入另一个模型的相同部分到新的模型"></a>导入另一个模型的相同部分到新的模型</h2><p>模型导入参数时，如果两个模型结构不一致，则直接导入参数会报错。用下面方法可以把另一个模型的相同的部分导入到新的模型中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model_new代表新的模型</span></span><br><span class="line"><span class="comment"># model_saved代表其他模型，比如用torch.load导入的已保存的模型</span></span><br><span class="line">model_new_dict = model_new.state_dict()</span><br><span class="line">model_common_dict = &#123;k:v <span class="keyword">for</span> k, v <span class="keyword">in</span> model_saved.items() <span class="keyword">if</span> k <span class="keyword">in</span> model_new_dict.keys()&#125;</span><br><span class="line">model_new_dict.update(model_common_dict)</span><br><span class="line">model_new.load_state_dict(model_new_dict)</span><br></pre></td></tr></table></figure><h2 id="4-数据处理"><a href="#4-数据处理" class="headerlink" title="4. 数据处理"></a><strong>4. 数据处理</strong></h2><h3 id="计算数据集的均值和标准差"><a href="#计算数据集的均值和标准差" class="headerlink" title="计算数据集的均值和标准差"></a><strong>计算数据集的均值和标准差</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_mean_and_std</span><span class="params">(dataset)</span>:</span></span><br><span class="line">    <span class="comment"># 输入PyTorch的dataset，输出均值和标准差</span></span><br><span class="line">    mean_r = <span class="number">0</span></span><br><span class="line">    mean_g = <span class="number">0</span></span><br><span class="line">    mean_b = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> img, _ <span class="keyword">in</span> dataset:</span><br><span class="line">        img = np.asarray(img) <span class="comment"># change PIL Image to numpy array</span></span><br><span class="line">        mean_b += np.mean(img[:, :, <span class="number">0</span>])</span><br><span class="line">        mean_g += np.mean(img[:, :, <span class="number">1</span>])</span><br><span class="line">        mean_r += np.mean(img[:, :, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    mean_b /= len(dataset)</span><br><span class="line">    mean_g /= len(dataset)</span><br><span class="line">    mean_r /= len(dataset)</span><br><span class="line"></span><br><span class="line">    diff_r = <span class="number">0</span></span><br><span class="line">    diff_g = <span class="number">0</span></span><br><span class="line">    diff_b = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    N = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> img, _ <span class="keyword">in</span> dataset:</span><br><span class="line">        img = np.asarray(img)</span><br><span class="line"></span><br><span class="line">        diff_b += np.sum(np.power(img[:, :, <span class="number">0</span>] - mean_b, <span class="number">2</span>))</span><br><span class="line">        diff_g += np.sum(np.power(img[:, :, <span class="number">1</span>] - mean_g, <span class="number">2</span>))</span><br><span class="line">        diff_r += np.sum(np.power(img[:, :, <span class="number">2</span>] - mean_r, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">        N += np.prod(img[:, :, <span class="number">0</span>].shape)</span><br><span class="line"></span><br><span class="line">    std_b = np.sqrt(diff_b / N)</span><br><span class="line">    std_g = np.sqrt(diff_g / N)</span><br><span class="line">    std_r = np.sqrt(diff_r / N)</span><br><span class="line"></span><br><span class="line">    mean = (mean_b.item() / <span class="number">255.0</span>, mean_g.item() / <span class="number">255.0</span>, mean_r.item() / <span class="number">255.0</span>)</span><br><span class="line">    std = (std_b.item() / <span class="number">255.0</span>, std_g.item() / <span class="number">255.0</span>, std_r.item() / <span class="number">255.0</span>)</span><br><span class="line">    <span class="keyword">return</span> mean, std</span><br></pre></td></tr></table></figure><h3 id="常用训练和验证数据预处理"><a href="#常用训练和验证数据预处理" class="headerlink" title="常用训练和验证数据预处理"></a><strong>常用训练和验证数据预处理</strong></h3><p>其中 ToTensor 操作会将 PIL.Image 或形状为 H×W×D，数值范围为 [0, 255] 的 np.ndarray 转换为形状为 D×H×W，数值范围为 [0.0, 1.0] 的 torch.Tensor。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">train_transform = torchvision.transforms.Compose([</span><br><span class="line">    torchvision.transforms.RandomResizedCrop(size=<span class="number">224</span>,</span><br><span class="line">                                             scale=(<span class="number">0.08</span>, <span class="number">1.0</span>)),</span><br><span class="line">    torchvision.transforms.RandomHorizontalFlip(),</span><br><span class="line">    torchvision.transforms.ToTensor(),</span><br><span class="line">    torchvision.transforms.Normalize(mean=(<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>),</span><br><span class="line">                                     std=(<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>)),</span><br><span class="line"> ])</span><br><span class="line"> val_transform = torchvision.transforms.Compose([</span><br><span class="line">    torchvision.transforms.Resize(<span class="number">256</span>),</span><br><span class="line">    torchvision.transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">    torchvision.transforms.ToTensor(),</span><br><span class="line">    torchvision.transforms.Normalize(mean=(<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>),</span><br><span class="line">                                     std=(<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>)),</span><br><span class="line">])</span><br></pre></td></tr></table></figure><h2 id="5-模型训练和测试"><a href="#5-模型训练和测试" class="headerlink" title="5. 模型训练和测试"></a>5. 模型训练和测试</h2><h3 id="分类模型训练代码"><a href="#分类模型训练代码" class="headerlink" title="分类模型训练代码"></a>分类模型训练代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Loss and optimizer</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train the model</span></span><br><span class="line">total_step = len(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i ,(images, labels) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        images = images.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Forward pass</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Backward and optimizer</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (i+<span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Epoch: [&#123;&#125;/&#123;&#125;], Step: [&#123;&#125;/&#123;&#125;], Loss: &#123;&#125;'</span></span><br><span class="line">                  .format(epoch+<span class="number">1</span>, num_epochs, i+<span class="number">1</span>, total_step, loss.item()))</span><br></pre></td></tr></table></figure><h3 id="分类模型测试代码"><a href="#分类模型测试代码" class="headerlink" title="分类模型测试代码"></a>分类模型测试代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Test the model</span></span><br><span class="line">model.eval()  <span class="comment"># eval mode(batch norm uses moving mean/variance </span></span><br><span class="line">              <span class="comment">#instead of mini-batch mean/variance)</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        images = images.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        outputs = model(images)</span><br><span class="line">        _, predicted = torch.max(outputs.data, <span class="number">1</span>)</span><br><span class="line">        total += labels.size(<span class="number">0</span>)</span><br><span class="line">        correct += (predicted == labels).sum().item()</span><br><span class="line">        </span><br><span class="line">    print(<span class="string">'Test accuracy of the model on the 10000 test images: &#123;&#125; %'</span></span><br><span class="line">          .format(<span class="number">100</span> * correct / total))</span><br><span class="line"></span><br><span class="line">​```python</span><br><span class="line"></span><br><span class="line"><span class="comment">### 自定义 loss</span></span><br><span class="line"></span><br><span class="line">继承 torch.nn.Module 类写自己的 loss。</span><br><span class="line"></span><br><span class="line">​```python</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyLoss</span><span class="params">(torch.nn.Moudle)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(MyLoss, self).__init__()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, y)</span>:</span></span><br><span class="line">        loss = torch.mean((x - y) ** <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><h3 id="标签平滑（label-smoothing）"><a href="#标签平滑（label-smoothing）" class="headerlink" title="标签平滑（label smoothing）"></a><strong>标签平滑（label smoothing）</strong></h3><p>写一个 label_smoothing.py 的文件，然后在训练代码里引用，用 LSR 代替交叉熵损失即可。label_smoothing.py 内容如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LSR</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, e=<span class="number">0.1</span>, reduction=<span class="string">'mean'</span>)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line"></span><br><span class="line">        self.log_softmax = nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line">        self.e = e</span><br><span class="line">        self.reduction = reduction</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_one_hot</span><span class="params">(self, labels, classes, value=<span class="number">1</span>)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">            Convert labels to one hot vectors</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            labels: torch tensor in format [label1, label2, label3, ...]</span></span><br><span class="line"><span class="string">            classes: int, number of classes</span></span><br><span class="line"><span class="string">            value: label value in one hot vector, default to 1</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            return one hot format labels in shape [batchsize, classes]</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line"></span><br><span class="line">        one_hot = torch.zeros(labels.size(<span class="number">0</span>), classes)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#labels and value_added  size must match</span></span><br><span class="line">        labels = labels.view(labels.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        value_added = torch.Tensor(labels.size(<span class="number">0</span>), <span class="number">1</span>).fill_(value)</span><br><span class="line"></span><br><span class="line">        value_added = value_added.to(labels.device)</span><br><span class="line">        one_hot = one_hot.to(labels.device)</span><br><span class="line"></span><br><span class="line">        one_hot.scatter_add_(<span class="number">1</span>, labels, value_added)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> one_hot</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_smooth_label</span><span class="params">(self, target, length, smooth_factor)</span>:</span></span><br><span class="line">        <span class="string">"""convert targets to one-hot format, and smooth</span></span><br><span class="line"><span class="string">        them.</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            target: target in form with [label1, label2, label_batchsize]</span></span><br><span class="line"><span class="string">            length: length of one-hot format(number of classes)</span></span><br><span class="line"><span class="string">            smooth_factor: smooth factor for label smooth</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            smoothed labels in one hot format</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        one_hot = self._one_hot(target, length, value=<span class="number">1</span> - smooth_factor)</span><br><span class="line">        one_hot += smooth_factor / (length - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> one_hot.to(target.device)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, target)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> x.size(<span class="number">0</span>) != target.size(<span class="number">0</span>):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'Expected input batchsize (&#123;&#125;) to match target batch_size(&#123;&#125;)'</span></span><br><span class="line">                    .format(x.size(<span class="number">0</span>), target.size(<span class="number">0</span>)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> x.dim() &lt; <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'Expected input tensor to have least 2 dimensions(got &#123;&#125;)'</span></span><br><span class="line">                    .format(x.size(<span class="number">0</span>)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> x.dim() != <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'Only 2 dimension tensor are implemented, (got &#123;&#125;)'</span></span><br><span class="line">                    .format(x.size()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        smoothed_target = self._smooth_label(target, x.size(<span class="number">1</span>), self.e)</span><br><span class="line">        x = self.log_softmax(x)</span><br><span class="line">        loss = torch.sum(- x * smoothed_target, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.reduction == <span class="string">'none'</span>:</span><br><span class="line">            <span class="keyword">return</span> loss</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">elif</span> self.reduction == <span class="string">'sum'</span>:</span><br><span class="line">            <span class="keyword">return</span> torch.sum(loss)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">elif</span> self.reduction == <span class="string">'mean'</span>:</span><br><span class="line">            <span class="keyword">return</span> torch.mean(loss)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'unrecognized option, expect reduction to be one of none, mean, sum'</span>)</span><br></pre></td></tr></table></figure><p>或者直接在训练文件里做 label smoothing</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> images, labels <span class="keyword">in</span> train_loader:</span><br><span class="line">    images, labels = images.cuda(), labels.cuda()</span><br><span class="line">    N = labels.size(<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># C is the number of classes.</span></span><br><span class="line">    smoothed_labels = torch.full(size=(N, C), fill_value=<span class="number">0.1</span> / (C - <span class="number">1</span>)).cuda()</span><br><span class="line">    smoothed_labels.scatter_(dim=<span class="number">1</span>, index=torch.unsqueeze(labels, dim=<span class="number">1</span>), value=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">    score = model(images)</span><br><span class="line">    log_prob = torch.nn.functional.log_softmax(score, dim=<span class="number">1</span>)</span><br><span class="line">    loss = -torch.sum(log_prob * smoothed_labels) / N</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure><h3 id="Mixup-训练"><a href="#Mixup-训练" class="headerlink" title="Mixup 训练"></a>Mixup 训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">beta_distribution = torch.distributions.beta.Beta(alpha, alpha)</span><br><span class="line"><span class="keyword">for</span> images, labels <span class="keyword">in</span> train_loader:</span><br><span class="line">    images, labels = images.cuda(), labels.cuda()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Mixup images and labels.</span></span><br><span class="line">    lambda_ = beta_distribution.sample([]).item()</span><br><span class="line">    index = torch.randperm(images.size(<span class="number">0</span>)).cuda()</span><br><span class="line">    mixed_images = lambda_ * images + (<span class="number">1</span> - lambda_) * images[index, :]</span><br><span class="line">    label_a, label_b = labels, labels[index]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Mixup loss.</span></span><br><span class="line">    scores = model(mixed_images)</span><br><span class="line">    loss = (lambda_ * loss_function(scores, label_a)</span><br><span class="line">            + (<span class="number">1</span> - lambda_) * loss_function(scores, label_b))</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure><h3 id="L1-正则化"><a href="#L1-正则化" class="headerlink" title="L1 正则化"></a><strong>L1 正则化</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">l1_regularization = torch.nn.L1Loss(reduction=<span class="string">'sum'</span>)</span><br><span class="line">loss = ...  <span class="comment"># Standard cross-entropy loss</span></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">    loss += torch.sum(torch.abs(param))</span><br><span class="line">loss.backward()</span><br></pre></td></tr></table></figure><h3 id="不对偏置项进行权重衰减（weight-decay）"><a href="#不对偏置项进行权重衰减（weight-decay）" class="headerlink" title="不对偏置项进行权重衰减（weight decay）"></a><strong>不对偏置项进行权重衰减（weight decay）</strong></h3><p>pytorch 里的 weight decay 相当于 l2 正则</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bias_list = (param <span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters() <span class="keyword">if</span> name[<span class="number">-4</span>:] == <span class="string">'bias'</span>)</span><br><span class="line">others_list = (param <span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters() <span class="keyword">if</span> name[<span class="number">-4</span>:] != <span class="string">'bias'</span>)</span><br><span class="line">parameters = [&#123;<span class="string">'parameters'</span>: bias_list, <span class="string">'weight_decay'</span>: <span class="number">0</span>&#125;,                </span><br><span class="line">              &#123;<span class="string">'parameters'</span>: others_list&#125;]</span><br><span class="line">optimizer = torch.optim.SGD(parameters, lr=<span class="number">1e-2</span>, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">1e-4</span>)</span><br></pre></td></tr></table></figure><h3 id="梯度裁剪（gradient-clipping）"><a href="#梯度裁剪（gradient-clipping）" class="headerlink" title="梯度裁剪（gradient clipping）"></a><strong>梯度裁剪（gradient clipping）</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=<span class="number">20</span>)</span><br></pre></td></tr></table></figure><h3 id="得到当前学习率"><a href="#得到当前学习率" class="headerlink" title="得到当前学习率"></a><strong>得到当前学习率</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># If there is one global learning rate (which is the common case).</span></span><br><span class="line">lr = next(iter(optimizer.param_groups))[<span class="string">'lr'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># If there are multiple learning rates for different layers.</span></span><br><span class="line">all_lr = []</span><br><span class="line"><span class="keyword">for</span> param_group <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">    all_lr.append(param_group[<span class="string">'lr'</span>])</span><br></pre></td></tr></table></figure><p>另一种方法，在一个 batch 训练代码里，当前的 lr 是 optimizer.param_groups[0][‘lr’]</p><h3 id="学习率衰减"><a href="#学习率衰减" class="headerlink" title="学习率衰减"></a><strong>学习率衰减</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Reduce learning rate when validation accuarcy plateau.</span></span><br><span class="line">scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=<span class="string">'max'</span>, patience=<span class="number">5</span>, verbose=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">80</span>):</span><br><span class="line">    train(...)</span><br><span class="line">    val(...)</span><br><span class="line">    scheduler.step(val_acc)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Cosine annealing learning rate.</span></span><br><span class="line">scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=<span class="number">80</span>)</span><br><span class="line"><span class="comment"># Reduce learning rate by 10 at given epochs.</span></span><br><span class="line">scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[<span class="number">50</span>, <span class="number">70</span>], gamma=<span class="number">0.1</span>)</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">80</span>):</span><br><span class="line">    scheduler.step()    </span><br><span class="line">    train(...)</span><br><span class="line">    val(...)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Learning rate warmup by 10 epochs.</span></span><br><span class="line">scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=<span class="keyword">lambda</span> t: t / <span class="number">10</span>)</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">10</span>):</span><br><span class="line">    scheduler.step()</span><br><span class="line">    train(...)</span><br><span class="line">    val(...)</span><br></pre></td></tr></table></figure><h3 id="优化器链式更新"><a href="#优化器链式更新" class="headerlink" title="优化器链式更新"></a>优化器链式更新</h3><p>从 1.4 版本开始，torch.optim.lr_scheduler 支持链式更新（chaining），即用户可以定义两个 schedulers，并交替在训练中使用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> SGD</span><br><span class="line"><span class="keyword">from</span> torch.optim.lr_scheduler <span class="keyword">import</span> ExponentialLR, StepLR</span><br><span class="line">model = [torch.nn.Parameter(torch.randn(<span class="number">2</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>))]</span><br><span class="line">optimizer = SGD(model, <span class="number">0.1</span>)</span><br><span class="line">scheduler1 = ExponentialLR(optimizer, gamma=<span class="number">0.9</span>)</span><br><span class="line">scheduler2 = StepLR(optimizer, step_size=<span class="number">3</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">    print(epoch, scheduler2.get_last_lr()[<span class="number">0</span>])</span><br><span class="line">    optimizer.step()</span><br><span class="line">    scheduler1.step()</span><br><span class="line">    scheduler2.step()</span><br></pre></td></tr></table></figure><h3 id="模型训练可视化"><a href="#模型训练可视化" class="headerlink" title="模型训练可视化"></a>模型训练可视化</h3><p>PyTorch 可以使用 tensorboard 来可视化训练过程。</p><p>安装和运行 TensorBoard。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorboard</span><br><span class="line">tensorboard --logdir=runs</span><br></pre></td></tr></table></figure><p>使用 SummaryWriter 类来收集和可视化相应的数据，放了方便查看，可以使用不同的文件夹，比如’Loss/train’和’Loss/test’。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> n_iter <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    writer.add_scalar(<span class="string">'Loss/train'</span>, np.random.random(), n_iter)</span><br><span class="line">    writer.add_scalar(<span class="string">'Loss/test'</span>, np.random.random(), n_iter)</span><br><span class="line">    writer.add_scalar(<span class="string">'Accuracy/train'</span>, np.random.random(), n_iter)</span><br><span class="line">    writer.add_scalar(<span class="string">'Accuracy/test'</span>, np.random.random(), n_iter)</span><br></pre></td></tr></table></figure><h3 id="保存与加载断点"><a href="#保存与加载断点" class="headerlink" title="保存与加载断点"></a><strong>保存与加载断点</strong></h3><p>注意为了能够恢复训练，我们需要同时保存模型和优化器的状态，以及当前的训练轮数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">start_epoch = <span class="number">0</span></span><br><span class="line"><span class="comment"># Load checkpoint.</span></span><br><span class="line"><span class="keyword">if</span> resume: <span class="comment"># resume为参数，第一次训练时设为0，中断再训练时设为1</span></span><br><span class="line">    model_path = os.path.join(<span class="string">'model'</span>, <span class="string">'best_checkpoint.pth.tar'</span>)</span><br><span class="line">    <span class="keyword">assert</span> os.path.isfile(model_path)</span><br><span class="line">    checkpoint = torch.load(model_path)</span><br><span class="line">    best_acc = checkpoint[<span class="string">'best_acc'</span>]</span><br><span class="line">    start_epoch = checkpoint[<span class="string">'epoch'</span>]</span><br><span class="line">    model.load_state_dict(checkpoint[<span class="string">'model'</span>])</span><br><span class="line">    optimizer.load_state_dict(checkpoint[<span class="string">'optimizer'</span>])</span><br><span class="line">    print(<span class="string">'Load checkpoint at epoch &#123;&#125;.'</span>.format(start_epoch))</span><br><span class="line">    print(<span class="string">'Best accuracy so far &#123;&#125;.'</span>.format(best_acc))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train the model</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(start_epoch, num_epochs): </span><br><span class="line">    ... </span><br><span class="line"></span><br><span class="line">    <span class="comment"># Test the model</span></span><br><span class="line">    ...</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># save checkpoint</span></span><br><span class="line">    is_best = current_acc &gt; best_acc</span><br><span class="line">    best_acc = max(current_acc, best_acc)</span><br><span class="line">    checkpoint = &#123;</span><br><span class="line">        <span class="string">'best_acc'</span>: best_acc,</span><br><span class="line">        <span class="string">'epoch'</span>: epoch + <span class="number">1</span>,</span><br><span class="line">        <span class="string">'model'</span>: model.state_dict(),</span><br><span class="line">        <span class="string">'optimizer'</span>: optimizer.state_dict(),</span><br><span class="line">    &#125;</span><br><span class="line">    model_path = os.path.join(<span class="string">'model'</span>, <span class="string">'checkpoint.pth.tar'</span>)</span><br><span class="line">    best_model_path = os.path.join(<span class="string">'model'</span>, <span class="string">'best_checkpoint.pth.tar'</span>)</span><br><span class="line">    torch.save(checkpoint, model_path)</span><br><span class="line">    <span class="keyword">if</span> is_best:</span><br><span class="line">        shutil.copy(model_path, best_model_path)</span><br></pre></td></tr></table></figure><h3 id="提取-ImageNet-预训练模型某层的卷积特征"><a href="#提取-ImageNet-预训练模型某层的卷积特征" class="headerlink" title="提取 ImageNet 预训练模型某层的卷积特征"></a><strong>提取 ImageNet 预训练模型某层的卷积特征</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># VGG-16 relu5-3 feature.</span></span><br><span class="line">model = torchvision.models.vgg16(pretrained=<span class="literal">True</span>).features[:<span class="number">-1</span>]</span><br><span class="line"><span class="comment"># VGG-16 pool5 feature.</span></span><br><span class="line">model = torchvision.models.vgg16(pretrained=<span class="literal">True</span>).features</span><br><span class="line"><span class="comment"># VGG-16 fc7 feature.</span></span><br><span class="line">model = torchvision.models.vgg16(pretrained=<span class="literal">True</span>)</span><br><span class="line">model.classifier = torch.nn.Sequential(*list(model.classifier.children())[:<span class="number">-3</span>])</span><br><span class="line"><span class="comment"># ResNet GAP feature.</span></span><br><span class="line">model = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">model = torch.nn.Sequential(collections.OrderedDict(</span><br><span class="line">    list(model.named_children())[:<span class="number">-1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    model.eval()</span><br><span class="line">    conv_representation = model(image)</span><br></pre></td></tr></table></figure><h3 id="提取-ImageNet-预训练模型多层的卷积特征"><a href="#提取-ImageNet-预训练模型多层的卷积特征" class="headerlink" title="提取 ImageNet 预训练模型多层的卷积特征"></a><strong>提取 ImageNet 预训练模型多层的卷积特征</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeatureExtractor</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""Helper class to extract several convolution features from the given</span></span><br><span class="line"><span class="string">    pre-trained model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Attributes:</span></span><br><span class="line"><span class="string">        _model, torch.nn.Module.</span></span><br><span class="line"><span class="string">        _layers_to_extract, list&lt;str&gt; or set&lt;str&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Example:</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; model = torchvision.models.resnet152(pretrained=True)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; model = torch.nn.Sequential(collections.OrderedDict(</span></span><br><span class="line"><span class="string">                list(model.named_children())[:-1]))</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; conv_representation = FeatureExtractor(</span></span><br><span class="line"><span class="string">                pretrained_model=model,</span></span><br><span class="line"><span class="string">                layers_to_extract=&#123;'layer1', 'layer2', 'layer3', 'layer4'&#125;)(image)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, pretrained_model, layers_to_extract)</span>:</span></span><br><span class="line">        torch.nn.Module.__init__(self)</span><br><span class="line">        self._model = pretrained_model</span><br><span class="line">        self._model.eval()</span><br><span class="line">        self._layers_to_extract = set(layers_to_extract)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            conv_representation = []</span><br><span class="line">            <span class="keyword">for</span> name, layer <span class="keyword">in</span> self._model.named_children():</span><br><span class="line">                x = layer(x)</span><br><span class="line">                <span class="keyword">if</span> name <span class="keyword">in</span> self._layers_to_extract:</span><br><span class="line">                    conv_representation.append(x)</span><br><span class="line">            <span class="keyword">return</span> conv_representation</span><br></pre></td></tr></table></figure><h3 id="微调全连接层"><a href="#微调全连接层" class="headerlink" title="微调全连接层"></a><strong>微调全连接层</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br><span class="line">model.fc = nn.Linear(<span class="number">512</span>, <span class="number">100</span>)  <span class="comment"># Replace the last fc layer</span></span><br><span class="line">optimizer = torch.optim.SGD(model.fc.parameters(), lr=<span class="number">1e-2</span>, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">1e-4</span>)</span><br></pre></td></tr></table></figure><h3 id="以较大学习率微调全连接层，较小学习率微调卷积层"><a href="#以较大学习率微调全连接层，较小学习率微调卷积层" class="headerlink" title="以较大学习率微调全连接层，较小学习率微调卷积层"></a><strong>以较大学习率微调全连接层，较小学习率微调卷积层</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">finetuned_parameters = list(map(id, model.fc.parameters()))</span><br><span class="line">conv_parameters = (p <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> id(p) <span class="keyword">not</span> <span class="keyword">in</span> finetuned_parameters)</span><br><span class="line">parameters = [&#123;<span class="string">'params'</span>: conv_parameters, <span class="string">'lr'</span>: <span class="number">1e-3</span>&#125;, </span><br><span class="line">              &#123;<span class="string">'params'</span>: model.fc.parameters()&#125;]</span><br><span class="line">optimizer = torch.optim.SGD(parameters, lr=<span class="number">1e-2</span>, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">1e-4</span>)</span><br></pre></td></tr></table></figure><h2 id="6-其他注意事项"><a href="#6-其他注意事项" class="headerlink" title="6. 其他注意事项"></a>6. 其他注意事项</h2><ul><li>不要使用太大的线性层。因为 nn.Linear(m,n) 使用的是 ![][img-1] 的内存，线性层太大很容易超出现有显存。</li><li>不要在太长的序列上使用 RNN。因为 RNN 反向传播使用的是 BPTT 算法，其需要的内存和输入序列的长度呈线性关系。</li><li>model(x) 前用 model.train() 和 model.eval() 切换网络状态。</li><li>不需要计算梯度的代码块用 with torch.no_grad() 包含起来。</li><li>model.eval() 和 torch.no_grad() 的区别在于，model.eval() 是将网络切换为测试状态，例如 BN 和 dropout 在训练和测试阶段使用不同的计算方法。torch.no_grad() 是关闭 PyTorch 张量的自动求导机制，以减少存储使用和加速计算，得到的结果无法进行 loss.backward()。</li><li>model.zero_grad() 会把整个模型的参数的梯度都归零, 而 optimizer.zero_grad() 只会把传入其中的参数的梯度归零.</li><li>torch.nn.CrossEntropyLoss 的输入不需要经过 Softmax。torch.nn.CrossEntropyLoss 等价于 torch.nn.functional.log_softmax + torch.nn.NLLLoss。</li><li>loss.backward() 前用 optimizer.zero_grad() 清除累积梯度。</li><li>torch.utils.data.DataLoader 中尽量设置 pin_memory=True，对特别小的数据集如 MNIST 设置 pin_memory=False 反而更快一些。num_workers 的设置需要在实验中找到最快的取值。</li><li>用 del 及时删除不用的中间变量，节约 GPU 存储。</li><li>使用 inplace 操作可节约 GPU 存储，如</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = torch.nn.functional.relu(x, inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">*   减少 CPU 和 GPU 之间的数据传输。例如如果你想知道一个 epoch 中每个 mini-batch 的 loss 和准确率，先将它们累积在 GPU 中等一个 epoch 结束之后一起传输回 CPU 会比每个 mini-batch 都进行一次 GPU 到 CPU 的传输更快。</span><br><span class="line">*   使用半精度浮点数 half() 会有一定的速度提升，具体效率依赖于 GPU 型号。需要小心数值精度过低带来的稳定性问题。</span><br><span class="line">*   时常使用 <span class="keyword">assert</span> tensor.size() == (N, D, H, W) 作为调试手段，确保张量维度和你设想中一致。</span><br><span class="line">*   除了标记 y 外，尽量少使用一维张量，使用 n*<span class="number">1</span> 的二维张量代替，可以避免一些意想不到的一维张量计算结果。</span><br><span class="line">*   统计代码各部分耗时</span><br></pre></td></tr></table></figure><p>with torch.autograd.profiler.profile(enabled=True, use_cuda=False) as profile:<br>    …<br>print(profile)</p><h1 id="或者在命令行运行"><a href="#或者在命令行运行" class="headerlink" title="或者在命令行运行"></a>或者在命令行运行</h1><p>python -m torch.utils.bottleneck main.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">*   使用 TorchSnooper 来调试 PyTorch 代码，程序在执行的时候，就会自动 <span class="keyword">print</span> 出来每一行的执行结果的 tensor 的形状、数据类型、设备、是否需要梯度的信息。</span><br></pre></td></tr></table></figure><h1 id="pip-install-torchsnooper"><a href="#pip-install-torchsnooper" class="headerlink" title="pip install torchsnooper"></a>pip install torchsnooper</h1><p>import torchsnooper</p><h1 id="对于函数，使用修饰器"><a href="#对于函数，使用修饰器" class="headerlink" title="对于函数，使用修饰器"></a>对于函数，使用修饰器</h1><p>@torchsnooper.snoop()</p><h1 id="如果不是函数，使用-with-语句来激活-TorchSnooper，把训练的那个循环装进-with-语句中去。"><a href="#如果不是函数，使用-with-语句来激活-TorchSnooper，把训练的那个循环装进-with-语句中去。" class="headerlink" title="如果不是函数，使用 with 语句来激活 TorchSnooper，把训练的那个循环装进 with 语句中去。"></a>如果不是函数，使用 with 语句来激活 TorchSnooper，把训练的那个循环装进 with 语句中去。</h1><p>with torchsnooper.snoop():<br>    原本的代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[https://github.com/zasdfgbnm/TorchSnooper​github.com](https://link.zhihu.com/?target=https%3A//github.com/zasdfgbnm/TorchSnooper)</span><br><span class="line"></span><br><span class="line">*   模型可解释性，使用 captum 库</span><br><span class="line"></span><br><span class="line">[https://captum.ai/​captum.ai](https://link.zhihu.com/?target=https%3A//captum.ai/)</span><br><span class="line"></span><br><span class="line">参考资料：</span><br><span class="line">-----</span><br><span class="line"></span><br><span class="line">1.  [张皓：PyTorch Cookbook（常用代码段整理合集）](https://zhuanlan.zhihu.com/p/59205847?)</span><br><span class="line">2.  PyTorch 官方[文档](https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/tensors.html)和[示例](https://link.zhihu.com/?target=https%3A//pytorch.org/tutorials/)</span><br><span class="line">3.  [https://pytorch.org/docs/stable/notes/faq.html](https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/notes/faq.html)</span><br><span class="line">4.  [https://github.com/szagoruyko/pytorchviz](https://link.zhihu.com/?target=https%3A//github.com/szagoruyko/pytorchviz)</span><br><span class="line">5.  [https://github.com/sksq96/pytorch-summary](https://link.zhihu.com/?target=https%3A//github.com/sksq96/pytorch-summary)</span><br><span class="line"><span class="number">6.</span>  其他</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;PyTorch 最好的资料是&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/index.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官方文档&lt;/
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Authorisation not recognised</title>
    <link href="http://yoursite.com/2020/08/20/Authorisation/"/>
    <id>http://yoursite.com/2020/08/20/Authorisation/</id>
    <published>2020-08-20T13:44:15.000Z</published>
    <updated>2020-08-20T00:41:33.508Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Authorisation-not-recognised"><a href="#Authorisation-not-recognised" class="headerlink" title="Authorisation not recognised"></a>Authorisation not recognised</h3><p><strong>Can’t open display: localhost:10.0</strong></p><p>Learn how to resolve Authorisation not recognized error while using xterm in Linux_</p><p><img src="https://z5.kerneltalks.com/wp-content/uploads/2020/06/MobaXterm-X11-proxy-Authorisation-not-recognised.png" alt>error</p><h4 id="Error"><a href="#Error" class="headerlink" title="Error :"></a>Error :</h4><p>Sometimes your users complain they can’t use GUI via X server from Linux box (in this case mobaXterm). They are receiving their display authorization is not recognized. An error like below –</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">appuser@kerneltalks@ xclock</span><br><span class="line">MobaXterm X11 proxy: Authorisation not recognised</span><br><span class="line">Error: Can<span class="string">'t open display: localhost:10.0</span></span><br></pre></td></tr></table></figure><p>Sometimes these errors show up when you switch user from the root account or any other account.</p><h4 id="Quick-Solution"><a href="#Quick-Solution" class="headerlink" title="Quick Solution:"></a>Quick Solution:</h4><p><strong>Login directly with</strong> user<strong> on which you want to use xclock</strong></p><p><code>appuser</code> needs to log in directly on the server and you won’t see this issue. Most of the time it arises once you su to <code>appuser</code> from root or different users.</p><p>Read further if you have to switch user and then use x-term.</p><p><code>appuser</code> need to add its entry to authorization. This entry will be the last entry in <code>.Xauthority</code> file in a home directory of the previous user with which you have logged in the server in the first place. Let’s say its <code>root</code> in our case. i.e. we logged in as <code>root</code> and then su to <code>appuser</code></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@kerneltalks <span class="comment"># xauth -f .Xauthority list |tail -1</span></span><br><span class="line">kerneltalks/unix:10 MIT-MAGIC-COOKIE-1 df22dfc7df88b60f0653198cc85f543c</span><br><span class="line"> </span><br><span class="line">appuser@kerneltalks $ xauth add kerneltalks/unix:10 MIT-MAGIC-COOKIE-1 df22dfc7df88b60f0653198cc85f543c</span><br></pre></td></tr></table></figure><p>So here we got values from root home directory file and then we added it in using xauth in currently su user i.e. <code>appuser</code></p><p>and you are good to go!</p><h4 id="Bit-of-an-explanation"><a href="#Bit-of-an-explanation" class="headerlink" title="Bit of an explanation :"></a>Bit of an explanation :</h4><p>This error occurs since your ID doesn’t have the authorization to connect to the X server.  Let’s walk through how to resolve this error. List out authorization entries for displays using <code>xauth list</code></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">appuser@kerneltalks $ xauth list</span><br><span class="line">kerneltalks/unix:12  MIT-MAGIC-COOKIE-1  60c402df81f68e721qwe531d1c99c1eb</span><br><span class="line">kerneltalks/unix:11  MIT-MAGIC-COOKIE-1  ad81da801d778fqwe6aea383635be27d</span><br><span class="line">kerneltalks/unix:10  MIT-MAGIC-COOKIE-1  0bd591485031d0ae670475g46db1b8b9</span><br></pre></td></tr></table></figure><p>The output shows entries column wise –</p><ol><li>Display name</li><li>Protocol name (MIT-MAGIC-COOKIE-1 referred to single period)</li><li>hexkey</li></ol><p>If you have many sessions and you are on test/dev environment and you are the only one using your system you can remove all the above entries using xauth remove to make sure you have a clean slate and getting only your session cookie. Or, you can save this output for reference. Log in again, try  <code>xclock</code> and new the entry will be generated. Compare the latest output with the older one and get your new entry filtered out. Or as mentioned above in a quick solution it will be last entry in <code>.Xauthority</code> file in a home directory of <code>appuser</code>. You can not read  <code>.Xauthority</code> file like text file so you have to use <code>xauth -f</code> command to view its content.</p><p>Logout from all sessions. Login again with the app user and run <code>xclock</code> once. This will generate a new session cookie token which you can see in <code>xauth list</code> .</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">appuser@kerneltalks $ xauth list</span><br><span class="line">kerneltalks/unix:10  MIT-MAGIC-COOKIE-1  df22dfc7df88b60f0653198cc85f543c</span><br></pre></td></tr></table></figure><p>Now, grab this entry and add authorization using below command –</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appuser@kerneltalks $ xauth add APCSFIOGWDV02/unix:10  MIT-MAGIC-COOKIE-1  df22dfc7df88b60f0653198cc85f543c</span><br></pre></td></tr></table></figure><p>and that’s it. You <code>xclock</code> should work now!</p><hr><h4 id="Error-1"><a href="#Error-1" class="headerlink" title="Error :"></a>Error :</h4><p>You are seeing below error in mobaXterm</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X11-forwarding  : ✘  (disabled or not supported by server)</span><br></pre></td></tr></table></figure><h4 id="Solution"><a href="#Solution" class="headerlink" title="Solution :"></a>Solution :</h4><p>The best way to make sure you have all X11 stuff installed is to run the install package <code>xclock</code>. Additionally, you need to install <code>xauth</code> package as well.</p><p>Secondly, make sure you have <code>X11Forwarding yes</code> set in your <code>/etc/ssh/sshd_config</code>. If not then set and restart sshd daemon.</p><p>That’s all! Try re-logging to the server and it should work. You should see the below message after login using MobXterm.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X11-forwarding  : ✔  (remote display is forwarded through SSH)</span><br></pre></td></tr></table></figure><p><a href="https://kerneltalks.com/troubleshooting/mobaxterm-x11-proxy-authorisation-not-recognised/" target="_blank" rel="noopener">原文连接</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Authorisation-not-recognised&quot;&gt;&lt;a href=&quot;#Authorisation-not-recognised&quot; class=&quot;headerlink&quot; title=&quot;Authorisation not recognised&quot;&gt;&lt;/a&gt;Au
      
    
    </summary>
    
    
      <category term="other" scheme="http://yoursite.com/categories/other/"/>
    
    
  </entry>
  
  <entry>
    <title>Domain name system</title>
    <link href="http://yoursite.com/2020/08/13/nslookup/"/>
    <id>http://yoursite.com/2020/08/13/nslookup/</id>
    <published>2020-08-13T13:42:15.000Z</published>
    <updated>2020-08-14T00:41:11.462Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Domain-name-system"><a href="#Domain-name-system" class="headerlink" title="Domain name system"></a>Domain name system</h2><h3 id="Part1"><a href="#Part1" class="headerlink" title="Part1"></a>Part1</h3><ol><li><p>List 3 different protocols that appear in the protocol column in the unfiltered<br> packet-listing window in step 7 above.</p><p><img src="image-20200813143931097.png" alt="image-20200813143931097"></p></li><li><p>How long did it take from when the HTTP GET message was sent until the HTTP<br> OK reply was received? (By default, the value of the Time column in the packet listing window is the amount of time, in seconds, since Wireshark tracing began.</p><p><img src="image-20200813144423850.png" alt="image-20200813144423850"></p></li></ol><p>To display the Time field in time-of-day format, select the Wireshark View pull<br>down menu, then select Time Display Format, then select Time-of-day.)</p><ol><li><p>What is the Internet address of the gaia.cs.umass.edu (also known as www.net.<br> cs.umass.edu)? What is the Internet address of your computer</p><p><img src="image-20200813144743605.png" alt="image-20200813144743605"></p></li><li><p>Print the two HTTP messages (GET and OK) referred to in question 2 above. To<br> do so, select Print from the Wireshark File command menu, and select the<br> “Selected Packet Only” and “Print as displayed” radial buttons, and then click<br> OK.</p><p><img src="image-20200813145358276.png" alt="image-20200813145358276"></p></li></ol><h3 id="Part2"><a href="#Part2" class="headerlink" title="Part2"></a>Part2</h3><p><strong>PREREQUISITES</strong> </p><pre><code>1. Computer Networking: A Top-Down Approach, 7th ed., J.F. Kurose and K.W. Ross (Chapter 1 and Chapter 2) TASK </code></pre><p><strong>TASK</strong></p><pre><code>1. Install Wireshark (lab. 1 part 1) – you already have all information.2. Use nslookup to analyze DNS messages 3. Use ipconfig to analyze DNS messages 4. Use Wireshark to analyze DNS messages</code></pre><h4 id="nslookup"><a href="#nslookup" class="headerlink" title="nslookup"></a>nslookup</h4><ol><li><p>Run nslookup to obtain the IP-address of a Web-server in China. What is the IP-address of that server</p><p><img src="image-20200813140126152.png" alt="image-20200813140126152"></p></li><li><p>Run nslookup to determine the authoritative dNs servers for a university in Europe</p><p><img src="image-20200813140220702.png" alt="image-20200813140220702"></p></li><li><p>Run nslookup so that one of the dns servers obtained in Question 2 is queried for the mail servers for Yandex mail(or any other What is its iP address?</p><p><img src="image-20200813141637442.png" alt="image-20200813141637442"></p></li><li><p>Make screenshots of your command line and put them in the report put them in the report along with the answers to questions</p></li></ol><h4 id="Ipconfig"><a href="#Ipconfig" class="headerlink" title="Ipconfig"></a>Ipconfig</h4><p><img src="image-20200813140706733.png" alt="image-20200813140706733"></p><p><img src="image-20200813141105155.png" alt="image-20200813141105155"></p><p><img src="image-20200813141148746.png" alt="image-20200813141148746"></p><h4 id="Tracing-DNS-with-Wireshark"><a href="#Tracing-DNS-with-Wireshark" class="headerlink" title="Tracing DNS with Wireshark"></a><strong>Tracing DNS with Wireshark</strong></h4><ul><li>Use ipconfig to empty the dns cache in your host</li><li>Open your browser and empty your browser cache. (With Internet Explorer, go to Tools menu and select Internet Options; then in the general tab select Delete Files.</li><li>Open Wireshark and enter ip addr =- your ip address into the filter, where you obtain your IP address with ipconfig. This filter removes all packets that neither originate nor are destined to your host</li><li>Start packet capture in Wireshark</li><li>With your browser, visit the some Web page</li><li>Stop packet capture</li></ul><ol><li><p>Locate the DNS query and response messages. are then sent over UDP or TCP?</p><p> <img src="image-20200813150611186.png" alt="image-20200813150611186"></p></li></ol><p>​    It can be seen from the query message information and the response messages information they are Sending message via <strong>UDP</strong>.</p><ol><li><p>What is the destination port for the DNS query message? What is the source port of DNS response message?</p><p> <img src="image-20200813150750618.png" alt="image-20200813150750618"></p><p> <img src="image-20200813151051501.png" alt="image-20200813151051501"></p><p> Ports are both <strong>53</strong></p></li><li><p>To what IP address is the DNS query message sent? Use ipconfig to determine the IP address of your local DNS server. Are these two IP addresses the same.</p><p>  <img src="image-20200813151609517.png" alt="image-20200813151609517"></p><p> <img src="image-20200813151711412.png" alt="image-20200813151711412"></p><p> both are <strong>202.101.172.35</strong></p></li><li><p>Examine the DNS query message. What Type’of DNS query is it? Does the query message contain any“ answers”?</p></li></ol><p><img src="image-20200813152007576.png" alt="image-20200813152007576"></p><pre><code>Type:A and query message does not contain any &quot;answers&quot;.</code></pre><ol><li><p>Examine the DNS response message. How many answers are provided? what do each of these answers contain?</p><p> <img src="image-20200813152229592.png" alt="image-20200813152229592"></p><p> See the picture.</p></li><li><p>Does this web page contain images? Before retrieving each image, does your host issue new DNS queries?</p><p> <img src="image-20200813152229592.png" alt="image-20200813152229592"></p><p> None</p></li></ol><h3 id="Part3"><a href="#Part3" class="headerlink" title="Part3"></a>Part3</h3><h4 id="nslookup-domain"><a href="#nslookup-domain" class="headerlink" title="nslookup domain"></a>nslookup domain</h4><ul><li><p>Start packet capture.</p></li><li><p>Do 𝑛𝑠𝑙𝑜𝑜𝑘𝑢𝑝 𝑤𝑤𝑤.ℎ𝑑𝑢.𝑒𝑑𝑢.𝑐𝑛</p><p><img src="image-20200813153853249.png" alt="image-20200813153853249"></p></li><li><p>Stop packet capture. You should get a trace that looks something like the following (on the last pictures).</p></li></ul><ol><li><p>What is the destination port for the DNS query message? What is the source port of DNS response message?</p><p><img src="image-20200813154043327.png" alt="image-20200813154043327"></p><p>The destination port for the DNS query message is <strong>53</strong>.</p><p>The source port of DNS response message is also <strong>53</strong>.</p></li><li><p>To what IP address is the DNS query message sent? Is this the IP address of your default local DNS server</p><p><img src="image-20200813154248959.png" alt="image-20200813154248959"></p><p><img src="image-20200813153853249.png" alt="image-20200813153853249"></p><p>Same as the IP address of the local DNS server</p></li><li><p>Examine the DNS query message. What “Type” of DNS query is it? Does the query message contain any “answers”? </p><p><img src="image-20200813154557227.png" alt="image-20200813154557227"></p></li><li><p>Examine the DNS response message. How many “answers” are provided? What do each of these answers contain?</p><p><img src="image-20200813154731464.png" alt="image-20200813154731464"></p><p>have 3 answers. </p></li></ol><h4 id="nslookup-type"><a href="#nslookup-type" class="headerlink" title="nslookup -type"></a>nslookup -type</h4><p>Now repeat the previous experiment, but instead issue the command:</p><p>​                    𝑛𝑠𝑙𝑜𝑜𝑘𝑢𝑝 – 𝑡𝑦𝑝𝑒=𝑁𝑆 𝑎𝑑𝑑𝑟𝑒𝑠𝑠<em> 𝑤ℎ𝑎𝑡 </em> 𝑦𝑜𝑢_𝑤𝑎𝑛𝑡</p><p><strong>nslookup -type = NS baidu.com</strong></p><p><img src="image-20200813155226270.png" alt="image-20200813155226270"></p><p>Answer the following questions:</p><ol><li><p>To what IP address is the DNS query message sent? Is this the IP address of your default local DNS server?</p><p><img src="image-20200813155813591.png" alt="image-20200813155813591"></p><p>Same as the IP address of the local DNS server.</p></li><li><p>Examine the DNS query message. What “Type” of DNS query is it? Does the query message contain any “answers”?</p><p><img src="image-20200813155822201.png" alt="image-20200813155822201"></p><p>Type: NS </p><p>query message does not contain any “answers”.</p></li><li><p>Examine the DNS response message. What nameservers does the response message provide?</p><p><img src="image-20200813155925788.png" alt="image-20200813155925788"></p><p>result obtained in Wireshark is the same as the result obtained by running in nslookup.</p></li></ol><h4 id="nslookup-𝑦𝑜𝑢𝑟-𝐷𝑁𝑆"><a href="#nslookup-𝑦𝑜𝑢𝑟-𝐷𝑁𝑆" class="headerlink" title="nslookup 𝑦𝑜𝑢𝑟 _ 𝐷𝑁𝑆"></a>nslookup 𝑦𝑜𝑢𝑟 _ 𝐷𝑁𝑆</h4><p>Now repeat the previous experiment, but instead issue the command:</p><p>​                    𝑛𝑠𝑙𝑜𝑜𝑘𝑢𝑝 𝑎𝑑𝑑𝑟𝑒𝑠𝑠 <em> 𝑤ℎ𝑎𝑡 </em> 𝑦𝑜𝑢 <em> 𝑤𝑎𝑛𝑡 𝑦𝑜𝑢𝑟 </em> 𝐷𝑁𝑆</p><p><strong>nslookup www.baidu.com 114.114.114.114</strong></p><p><img src="image-20200813160230801.png" alt="image-20200813160230801"></p><p>Answer the following questions:</p><ol><li><p>To what IP address is the DNS query message sent? Is this the IP address of your default local DNS server? If not, what does the IP address correspond to?</p><p><img src="image-20200813160716347.png" alt="image-20200813160716347"></p><p> They are not the same.This ip corresponds to the ip specified last by entering “nslookup baidu.com 114.114.114.114” in the terminal.</p></li><li><p>Examine the DNS query message. What “Type” of DNS query is it? Does the query message contain any “answers”?</p><p><img src="image-20200813160716347.png" alt="image-20200813160716347"></p><p>Type: A </p><p>query message does not contain any “answers”.</p></li><li><p>Examine the DNS response message. How many “answers” are provided? What does each of these answers contain?</p><p><img src="image-20200813160906241.png" alt="image-20200813160906241"></p><p>you can see from the picture above, it contains 3 answers</p><p>The result is the same as the result obtained by nslookup in the Terminal.</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Domain-name-system&quot;&gt;&lt;a href=&quot;#Domain-name-system&quot; class=&quot;headerlink&quot; title=&quot;Domain name system&quot;&gt;&lt;/a&gt;Domain name system&lt;/h2&gt;&lt;h3 id=&quot;P
      
    
    </summary>
    
    
      <category term="other" scheme="http://yoursite.com/categories/other/"/>
    
    
  </entry>
  
</feed>
