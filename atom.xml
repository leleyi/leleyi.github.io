<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>FILE</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-07-12T07:02:28.947Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Les</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Learn to rank</title>
    <link href="http://yoursite.com/2020/07/12/Learn2Rank/"/>
    <id>http://yoursite.com/2020/07/12/Learn2Rank/</id>
    <published>2020-07-12T06:56:15.000Z</published>
    <updated>2020-07-12T07:02:28.947Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Learn-to-rank"><a href="#Learn-to-rank" class="headerlink" title="Learn to rank"></a>Learn to rank</h1><p>在信息检索中, 检索rank可以由多种算法获得, 或者是检索的结果还可以受外部信息所影响.将这些信息融合起来排名可能会获得更好的排序结果.<br>如:<br><img src="20200711163650350_6358.png" alt="png"><br>我们可以看到有不同的排序结果.将这多组数据进行在排序.在这 我们将得分 以$s_i(d)$表示, $i$ 为rank. d- document, $r_i(d)$</p><h3 id="无监督的reranking方法"><a href="#无监督的reranking方法" class="headerlink" title="无监督的reranking方法"></a>无监督的reranking方法</h3><h4 id="Score-based-methods"><a href="#Score-based-methods" class="headerlink" title="Score-based methods"></a>Score-based methods</h4><ul><li><p>Comb*<br>  $CombMAX(d) = max{s_0(d), …,s_n(d)}$</p><p>  $CombMIN(d) = min{s_0(d), …,s_n(d)}$</p><p>  $CombSUM(d) = \sum_i(s_i(d))$</p><script type="math/tex; mode=display">\operatorname{CombMNZ}(d)=\left|\left\{i \mid d \in \operatorname{Rank}_{i}\right\}\right| \cdot \sum_{i} s_{i}(d)</script><p>  CombSUM 例子:<br>  <img src="20200711165912563_19363.png" alt="png"><br>  我们也可以将数据归一化之后再进行SUM操作.<br>  $\frac {score - u} {\alpha}$<br>  直接Comb的方式过于简单,我们很容易想到将不同的rank赋予不同的权重.</p><script type="math/tex; mode=display">\operatorname{wCombSUM}(d)=\sum_{i} w_{i} s_{i}(d)</script><script type="math/tex; mode=display">\operatorname{wComb} M N Z(d)=\left|\left\{i \mid d \in \operatorname{Rank}_{i}\right\}\right| \cdot \operatorname{w} \operatorname{CombSUM}(d)</script></li></ul><p>那么如何来确定这些权重呢.?</p><ol><li>我们凭借经验手动设置</li><li>通过机器学习的方式.<h4 id="Rank-based-融合"><a href="#Rank-based-融合" class="headerlink" title="Rank-based 融合"></a>Rank-based 融合</h4></li></ol><ul><li><p>Bordafuse</p><p> 混合排名将每种排名分数加起来. 即就纯粹根据各种算法的排名来打分.如图:<br> <img src="20200711171554979_372.png" alt="png"></p></li><li>Condorect<br>根据各种算法战胜其他算法的次数进行排名.<br><img src="20200712082852047_29522.png" alt="png"><br><img src="20200712083012487_27249.png" alt="png">   </li><li><p>Reciprocal Rank Fusion(RRF)<br>根据排名的倒数作为其文档的权重.<br>$RRFscore(d) = \sum_i \frac{1}{k + r_i{d}}$<br>k 作为参数可以调节.<br><img src="20200712083312233_23519.png" alt="png"></p><h4 id="Learning-to-Rank"><a href="#Learning-to-Rank" class="headerlink" title="Learning to Rank"></a>Learning to Rank</h4><p><img src="20200712084032594_18408.png" alt="png"><br>使用机器学习的方式自动学习到如何rank.</p></li><li><p>逐点的方式.<br>  对相关分数进行回归，将文档分类为“相关”和“非相关”<br>  以$(q, d, r)$ 三元数据集合进行训练.出模型.通过$q,d$ 预测 $s$</p></li><li>逐对的方式.<br>  给定两个文档，预测部分排名<br>  通过预测部分排名来查找全局的顺序:<br>  <img src="20200712084724596_13505.png" alt="png"></li><li>逐列的方式.<br>  给出两个相同项目的排名列表，哪个更好.<ul><li>考虑许多排名特征.</li><li>排名模型是加权线性模型.</li><li>线性模型优化最终排名的顺序.<script type="math/tex; mode=display">ReRanker(d)=w_{1} s_{1}(d)+w_{2} s_{2}(d)+\ldots+w_{n} s_{n}(d)</script><img src="20200712085133960_17800.png" alt="png"></li></ul></li></ul><ul><li>参考 · André Mourão, João Magalhães</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Learn-to-rank&quot;&gt;&lt;a href=&quot;#Learn-to-rank&quot; class=&quot;headerlink&quot; title=&quot;Learn to rank&quot;&gt;&lt;/a&gt;Learn to rank&lt;/h1&gt;&lt;p&gt;在信息检索中, 检索rank可以由多种算法获得, 或
      
    
    </summary>
    
    
      <category term="information retrieval" scheme="http://yoursite.com/categories/information-retrieval/"/>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2020/07/12/rank/"/>
    <id>http://yoursite.com/2020/07/12/rank/</id>
    <published>2020-07-12T06:39:48.851Z</published>
    <updated>2020-07-11T13:50:29.783Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Rank"><a href="#Rank" class="headerlink" title="Rank"></a>Rank</h3><ul><li><strong>P@notic Model</strong><br>  以作者为中心, 将作者所有的文本汇集(mate-document),并且向量化(vec-mate), 通过query与vec-mate的相似度来排序.进而获取专家排序.  - 简单但是准确度低.</li><li><p><strong>Voting Model</strong><br>  以文档为中心, 首先计算出query与document的相似度.并排序.<br> $\text {RRFscore}(d)=\sum<em>{i} \frac{1}{k+r</em>{i}(d)}, \quad k=0 \text { (for this example)}$<br>  $r_i$ the rank of i,比如 候选作者是排名第2,3,7的文档的作者, 则他的得分为<br>  $\frac{1}{2} + \frac{1}{3} +\frac{1}{7} = 0.976$.将相关作者得分排序的到结果.<br>  将最相关的文档的作者,和作者的文章数量都考虑到了.<br>  其他技术:</p><pre><code>  Comb*:综合各个方式结果.</code></pre></li><li><p><strong>Propagation Model</strong><br>  传播模型是基于图的方式.因为文档与作者之间天然就是一个二分图. :<br>  采用随机游走的方式,让图收敛.<br>目前来看的话, 投票模型的效果是最好的. </p></li></ul><p><strong>Modeling Multi-step Relevance Propagation for Expert Finding</strong></p><ol><li>不仅仅将专家文本的内容作为专家线索, 并且将其相连或者间接相连的文章作为证据. </li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Rank&quot;&gt;&lt;a href=&quot;#Rank&quot; class=&quot;headerlink&quot; title=&quot;Rank&quot;&gt;&lt;/a&gt;Rank&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;P@notic Model&lt;/strong&gt;&lt;br&gt;  以作者为中心, 将作者所有的文本汇集(m
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>CentOs Poxy</title>
    <link href="http://yoursite.com/2020/02/26/CentOsPoxy/"/>
    <id>http://yoursite.com/2020/02/26/CentOsPoxy/</id>
    <published>2020-02-26T06:57:15.000Z</published>
    <updated>2020-02-26T07:14:20.696Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CentOs-Poxy"><a href="#CentOs-Poxy" class="headerlink" title="CentOs Poxy"></a>CentOs Poxy</h1><p>使用vmware 装了个centos. 但是需要Google. 本机已经使用ssr.可以访问.</p><ol><li>首先将vm网络设置为桥接</li></ol><p>虚拟机- 设置<br><img src="20200226113957464_28044.png" alt="png"></p><p>2.将本机ssr设置为<br>帮助 - 选项设置<br><img src="20200226114136407_25977.png" alt="png"></p><p>3.打开虚拟机器设置网络代理<br>System - Preference - Network Proxy<br>此处设置的ip地址为宿主机的ip<br><img src="20200226114649104_4762.png" alt="png"></p><p>4.ok测试<br><img src="20200226114819288_15728.png" alt="png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;CentOs-Poxy&quot;&gt;&lt;a href=&quot;#CentOs-Poxy&quot; class=&quot;headerlink&quot; title=&quot;CentOs Poxy&quot;&gt;&lt;/a&gt;CentOs Poxy&lt;/h1&gt;&lt;p&gt;使用vmware 装了个centos. 但是需要Google. 本机
      
    
    </summary>
    
    
      <category term="tool" scheme="http://yoursite.com/categories/tool/"/>
    
    
  </entry>
  
  <entry>
    <title>STDP手写数字识别</title>
    <link href="http://yoursite.com/2019/11/09/eth_mnist/"/>
    <id>http://yoursite.com/2019/11/09/eth_mnist/</id>
    <published>2019-11-09T08:40:15.000Z</published>
    <updated>2019-11-13T00:51:22.738Z</updated>
    
    <content type="html"><![CDATA[<h3 id="STDP手写数字识别"><a href="#STDP手写数字识别" class="headerlink" title="STDP手写数字识别"></a>STDP手写数字识别</h3><p><img src="mnist.png" alt="image.png"></p><p>数字识别的SNN，其基于具有更高生物似然性的机制，即基于电导而不是基于电流的突触，具有随时间变化的体重变化，横向抑制和自适应峰值阈值的基于脉冲时序的可塑性(STDP)<br>采用无监督的学习方式。</p><p><a href="https://pypi.org/project/bindsnet/" target="_blank" rel="noopener">bindsnet</a> 一个Python软件包，用于使用PyTorch Tensor功能在CPU或GPU上模拟脉冲神经网络（SNN）</p><ol><li><p>首先在github上将项目搂下来。<a href="https://gitlab.com/aiCTX/sinabs" target="_blank" rel="noopener">sinabs</a></p></li><li><p>进入项目根目录（有setup.py）进行本地pip安装 ：  pip install -e<br>bindsnet已经帮助我们以及把脉冲编码，神经元模型等定义好了，方便极了。</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time <span class="keyword">as</span> t</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> bindsnet.encoding <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> bindsnet.datasets <span class="keyword">import</span> MNIST</span><br><span class="line"><span class="keyword">from</span> bindsnet.encoding <span class="keyword">import</span> PoissonEncoder</span><br><span class="line"><span class="keyword">from</span> bindsnet.models <span class="keyword">import</span> DiehlAndCook2015</span><br><span class="line"><span class="keyword">from</span> bindsnet.network.monitors <span class="keyword">import</span> Monitor</span><br><span class="line"><span class="keyword">from</span> bindsnet.utils <span class="keyword">import</span> get_square_weights, get_square_assignments</span><br><span class="line"><span class="keyword">from</span> bindsnet.evaluation <span class="keyword">import</span> all_activity, proportion_weighting, assign_labels</span><br><span class="line"><span class="keyword">from</span> bindsnet.analysis.plotting <span class="keyword">import</span> (</span><br><span class="line">    plot_input,</span><br><span class="line">    plot_spikes,</span><br><span class="line">    plot_weights,</span><br><span class="line">    plot_assignments,</span><br><span class="line">    plot_performance,</span><br><span class="line">    plot_voltages,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  all_activity spikes(n_samples, time, n_neurons)</span></span><br><span class="line">n_neurons = <span class="number">100</span> <span class="comment"># 神经元个数</span></span><br><span class="line">step = <span class="number">1.0</span> <span class="comment"># 步长 z  即以时间驱动模拟策略（未验证）</span></span><br><span class="line">time = <span class="number">250</span> <span class="comment"># 模拟周期</span></span><br><span class="line">update_interval = <span class="number">250</span>  <span class="comment"># time / step</span></span><br><span class="line">spike_record = torch.zeros(update_interval, time, <span class="number">100</span>) <span class="comment"># 记录脉冲数据</span></span><br></pre></td></tr></table></figure><h4 id="构建网络"><a href="#构建网络" class="headerlink" title="构建网络"></a>构建网络</h4><p>使用binsnet中 diehl&amp;Cook模型,我们暂时不用去关心模型的细节。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">network = DiehlAndCook2015(</span><br><span class="line">    n_inpt = <span class="number">28</span> * <span class="number">28</span>,</span><br><span class="line">    n_neurons = n_neurons,</span><br><span class="line">    exc = <span class="number">22.5</span>,                        <span class="comment"># 表示从兴奋 到 抑制的突触强度</span></span><br><span class="line">    inh = <span class="number">120</span>,                         <span class="comment"># 表示从抑制 到 兴奋的突出强度</span></span><br><span class="line">    dt = step,                          <span class="comment"># 模拟时间步长</span></span><br><span class="line">    norm = <span class="number">78.4</span>,                       <span class="comment"># 输入层到兴奋层连接权归一化常数。</span></span><br><span class="line">    theta_plus = <span class="number">0.05</span>,                 </span><br><span class="line">    inpt_shape = (<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">network</span><br></pre></td></tr></table></figure><pre><code>DiehlAndCook2015(  (X): Input()  (Ae): DiehlAndCookNodes()  (Ai): LIFNodes()  (X_to_Ae): Connection(    (source): Input()    (target): DiehlAndCookNodes()  )  (Ae_to_Ai): Connection(    (source): DiehlAndCookNodes()    (target): LIFNodes()  )  (Ai_to_Ae): Connection(    (source): LIFNodes()    (target): DiehlAndCookNodes()  ))</code></pre><h4 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h4><p>通过Bindsnet封装的数据集， 可以直接调用，将数据进行脉冲编码。<br>Possion编码是一个频率编码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_poisson</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">100</span>]:  <span class="comment"># number of nodes in layer</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> [<span class="number">1000</span>]:  <span class="comment"># number of timesteps</span></span><br><span class="line">            datum = torch.empty(n).uniform_(<span class="number">20</span>, <span class="number">100</span>)  <span class="comment"># Generate firing rates.</span></span><br><span class="line">            spikes = poisson(datum, time=t)  <span class="comment"># Encode as spikes.</span></span><br><span class="line">            <span class="keyword">assert</span> spikes.size() == torch.Size((t, n))</span><br><span class="line">            <span class="keyword">return</span> spikes</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spikes = test_poisson()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dataset = MNIST(</span><br><span class="line">    PoissonEncoder(time=time, dt=step),<span class="comment"># time 每个输入变量的泊松脉冲序列的长度。</span></span><br><span class="line">    <span class="literal">None</span>,</span><br><span class="line">    root=os.path.join(<span class="string">"data"</span>, <span class="string">"MNIST"</span>),  <span class="comment"># 数据路径</span></span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=transforms.Compose(</span><br><span class="line">        [transforms.ToTensor(), transforms.Lambda(<span class="keyword">lambda</span> x: x * <span class="number">128</span>)]</span><br><span class="line">    ),</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset</span><br></pre></td></tr></table></figure><pre><code>Dataset TorchvisionDatasetWrapper    Number of datapoints: 60000    Root location: data\MNIST    Split: Train    StandardTransformTransform: Compose(               ToTensor()               Lambda()           )</code></pre><h4 id="使用Monitor来记录-exc-和-inh层-voltage"><a href="#使用Monitor来记录-exc-和-inh层-voltage" class="headerlink" title="使用Monitor来记录 exc 和 inh层 voltage"></a>使用Monitor来记录 exc 和 inh层 voltage</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">exc_voltage_monitor = Monitor(network.layers[<span class="string">"Ae"</span>], [<span class="string">"v"</span>], time=time)</span><br><span class="line">inh_voltage_monitor = Monitor(network.layers[<span class="string">"Ai"</span>], [<span class="string">"v"</span>], time=time)</span><br><span class="line">network.add_monitor(exc_voltage_monitor, name=<span class="string">"exc_voltage"</span>)</span><br><span class="line">network.add_monitor(inh_voltage_monitor, name=<span class="string">"inh_voltage"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 监听脉冲，以及电压值</span></span><br><span class="line">spikes = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> set(network.layers):</span><br><span class="line">    <span class="comment">##print(layer)</span></span><br><span class="line">    spikes[layer] = Monitor(network.layers[layer], state_vars=[<span class="string">"s"</span>], time=time)</span><br><span class="line">    network.add_monitor(spikes[layer], name=<span class="string">"%s_spikes"</span> % layer)</span><br><span class="line"><span class="comment">#print("====")</span></span><br><span class="line">voltages = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> set(network.layers) - &#123;<span class="string">"X"</span>&#125;:</span><br><span class="line">    <span class="comment">#print(layer)</span></span><br><span class="line">    voltages[layer] = Monitor(network.layers[layer], state_vars=[<span class="string">"v"</span>], time=time)</span><br><span class="line">    network.add_monitor(voltages[layer], name=<span class="string">"%s_voltages"</span> % layer)</span><br></pre></td></tr></table></figure><h4 id="训练网络"><a href="#训练网络" class="headerlink" title="训练网络"></a>训练网络</h4><ul><li>精度计算</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算精度</span></span><br><span class="line">accuracy = &#123;<span class="string">"all"</span>: [], <span class="string">"proportion"</span>: []&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Neuron assignments and spike proportions.</span></span><br><span class="line">n_classes = <span class="number">10</span></span><br><span class="line">assignments = -torch.ones(<span class="number">100</span>)</span><br><span class="line">proportions = torch.zeros(<span class="number">100</span>, <span class="number">10</span>)</span><br><span class="line">rates = torch.zeros(<span class="number">100</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cal_accuracy</span><span class="params">(all_activity_pred, proportion_pred)</span>:</span></span><br><span class="line">    </span><br><span class="line">    accuracy[<span class="string">"all"</span>].append(</span><br><span class="line">        <span class="number">100</span> * torch.sum(label_tensor.long() == all_activity_pred).item() / len(label_tensor)</span><br><span class="line">    )</span><br><span class="line">    accuracy[<span class="string">"proportion"</span>].append(</span><br><span class="line">        <span class="number">100</span> * torch.sum(label_tensor.long() == proportion_pred).item() / len(label_tensor)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    print(</span><br><span class="line">        <span class="string">"\nAll activity accuracy: %.2f (last), %.2f (average), %.2f (best)"</span></span><br><span class="line">        % (</span><br><span class="line">            accuracy[<span class="string">"all"</span>][<span class="number">-1</span>],</span><br><span class="line">            np.mean(accuracy[<span class="string">"all"</span>]),</span><br><span class="line">            np.max(accuracy[<span class="string">"all"</span>]),</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">    print(</span><br><span class="line">        <span class="string">"Proportion weighting accuracy: %.2f (last), %.2f (average), %.2f (best)\n"</span></span><br><span class="line">        % (</span><br><span class="line">            accuracy[<span class="string">"proportion"</span>][<span class="number">-1</span>],</span><br><span class="line">            np.mean(accuracy[<span class="string">"proportion"</span>]),</span><br><span class="line">            np.max(accuracy[<span class="string">"proportion"</span>]),</span><br><span class="line">        )</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><ul><li>画图</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw</span><span class="params">(batch, exc_voltagesl,inh_voltages )</span>:</span></span><br><span class="line">    inpt_ims, inpt_axes = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    spike_ims, spike_axes = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    weights_im = <span class="literal">None</span></span><br><span class="line">    assigns_im = <span class="literal">None</span></span><br><span class="line">    perf_ax = <span class="literal">None</span></span><br><span class="line">    voltage_axes, voltage_ims = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    image = batch[<span class="string">"image"</span>].view(<span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    inpt = inputs[<span class="string">"X"</span>].view(time, <span class="number">784</span>).sum(<span class="number">0</span>).view(<span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    input_exc_weights = network.connections[(<span class="string">"X"</span>, <span class="string">"Ae"</span>)].w</span><br><span class="line">    square_weights = get_square_weights( <span class="comment"># n_sqrt =  10  = int(np.ceil(np.sqrt(n_neurons)))</span></span><br><span class="line">        <span class="comment"># piex, n_neruons  </span></span><br><span class="line">        input_exc_weights.view(<span class="number">784</span>, <span class="number">100</span>), <span class="number">10</span>, <span class="number">28</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    square_assignments = get_square_assignments(assignments, <span class="number">10</span>)</span><br><span class="line">    spikes_ = &#123;layer: spikes[layer].get(<span class="string">"s"</span>) <span class="keyword">for</span> layer <span class="keyword">in</span> spikes&#125;</span><br><span class="line">    voltages = &#123;<span class="string">"Ae"</span>: exc_voltages, <span class="string">"Ai"</span>: inh_voltages&#125;</span><br><span class="line">    inpt_axes, inpt_ims = plot_input(</span><br><span class="line">        image, inpt, label=batch[<span class="string">"label"</span>], axes=inpt_axes, ims=inpt_ims</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    spike_ims, spike_axes = plot_spikes(spikes_, ims=spike_ims, axes=spike_axes)</span><br><span class="line">    weights_im = plot_weights(square_weights, im=weights_im)</span><br><span class="line">    assigns_im = plot_assignments(square_assignments, im=assigns_im)</span><br><span class="line">    perf_ax = plot_performance(accuracy, ax=perf_ax)</span><br><span class="line">    voltage_ims, voltage_axes = plot_voltages(</span><br><span class="line">        voltages, ims=voltage_ims, axes=voltage_axes, plot_type=<span class="string">"line"</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    plt.pause(<span class="number">1e-8</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"\nBegin training.\n"</span>)</span><br><span class="line">start = t()</span><br><span class="line">n_epochs = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epochs):</span><br><span class="line">    labels = []</span><br><span class="line">    </span><br><span class="line"><span class="comment">#     # 每迭代10次 计算一次训练时间</span></span><br><span class="line"><span class="comment">#     if epoch % 10 == 0:</span></span><br><span class="line"><span class="comment">#         print("Progress: %d / %d (%.4f seconds)" % (epoch, n_epochs, t() - start))</span></span><br><span class="line"><span class="comment">#         start = t()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载以及处理好的数据。</span></span><br><span class="line">    dataloader = torch.utils.data.DataLoader( <span class="comment">#, num_workers=1, pin_memory=False</span></span><br><span class="line">        dataset, batch_size=<span class="number">1</span>, shuffle=<span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> step, batch <span class="keyword">in</span> enumerate(tqdm(dataloader)):</span><br><span class="line">        <span class="comment"># 获取训练样本                           #time    </span></span><br><span class="line">        inputs = &#123;<span class="string">"X"</span>: batch[<span class="string">"encoded_image"</span>].view(<span class="number">250</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)&#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">250</span> == <span class="number">0</span> <span class="keyword">and</span> step &gt; <span class="number">0</span>:</span><br><span class="line">            </span><br><span class="line">            label_tensor = torch.tensor(labels)</span><br><span class="line"></span><br><span class="line">            <span class="comment">#  使用在所有神经元上具有最高平均脉冲活动的标签对数据进行分类</span></span><br><span class="line">            <span class="comment">#  all_activity spikes(n_samples, time, n_neurons)</span></span><br><span class="line">            all_activity_pred = all_activity(</span><br><span class="line">                spikes=spike_record, assignments=assignments, n_labels=n_classes</span><br><span class="line">            )</span><br><span class="line">            <span class="comment"># 使用在所有神经元上具有最高平均脉冲活动的标签对数据进行分类，并按类别比例加权。</span></span><br><span class="line">            proportion_pred = proportion_weighting(</span><br><span class="line">                spikes=spike_record,</span><br><span class="line">                assignments=assignments,</span><br><span class="line">                proportions=proportions,</span><br><span class="line">                n_labels=n_classes,</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            cal_accuracy(all_activity_pred, proportion_pred)</span><br><span class="line">            <span class="comment"># 计算精确度</span></span><br><span class="line">           </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 根据最高的平均脉冲活动 为（excitatory）神经元——分配标签</span></span><br><span class="line">            assignments, proportions, rates = assign_labels(</span><br><span class="line">                spikes=spike_record,</span><br><span class="line">                labels=label_tensor,</span><br><span class="line">                n_labels=n_classes,</span><br><span class="line">                rates=rates,</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            labels = []</span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">        labels.append(batch[<span class="string">"label"</span>])</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        network.run(inpts=inputs, time=<span class="number">250</span>, input_time_dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获得 voltage 记录</span></span><br><span class="line">        exc_voltages = exc_voltage_monitor.get(<span class="string">"v"</span>)</span><br><span class="line">        inh_voltages = inh_voltage_monitor.get(<span class="string">"v"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 记录spike</span></span><br><span class="line">        spike_record[step % update_interval] = spikes[<span class="string">"Ae"</span>].get(<span class="string">"s"</span>).squeeze()</span><br><span class="line"> </span><br><span class="line">        polt = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">if</span> polt:</span><br><span class="line">            <span class="keyword">if</span>(step % <span class="number">1000</span> == <span class="number">0</span>):</span><br><span class="line">                draw(batch, exc_voltages,inh_voltages)</span><br><span class="line"></span><br><span class="line">        network.reset_() <span class="comment">#api已经修改</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">"Progress: %d / %d (%.4f seconds)"</span> % (epoch + <span class="number">1</span>, n_epochs, t() - start))</span><br><span class="line">print(<span class="string">"Training complete.\n"</span>)</span><br></pre></td></tr></table></figure><pre><code>Begin training.</code></pre><p>​    </p><pre><code>  0%|                                                                                        | 0/60000 [00:00&lt;?, ?it/s]</code></pre><p><img src="output_22_2.png" alt="png"></p><p><img src="output_22_3.png" alt="png"></p><p><img src="output_22_4.png" alt="png"></p><p><img src="output_22_5.png" alt="png"></p><p><img src="output_22_6.png" alt="png"></p><p><img src="output_22_7.png" alt="png"></p><p>……………………………………………………………….two years later…………………………………………………………………………..</p><p><img src="output_22_828.png" alt="png"></p><p><img src="output_22_829.png" alt="png"></p><p><img src="output_22_830.png" alt="png"></p><p><img src="output_22_831.png" alt="png"></p><p><img src="output_22_832.png" alt="png"></p><p><img src="output_22_833.png" alt="png"></p><pre><code> 99%|█████████████████████████████████████████████████████████████████████████ | 59250/60000 [4:50:13&lt;03:40,  3.41it/s]</code></pre><p>​<br>​    All activity accuracy: 78.00 (last), 76.35 (average), 86.80 (best)<br>​    Proportion weighting accuracy: 78.40 (last), 77.21 (average), 86.80 (best)</p><p>​    </p><pre><code> 99%|█████████████████████████████████████████████████████████████████████████▍| 59500/60000 [4:51:27&lt;02:26,  3.41it/s]</code></pre><p>​<br>​    All activity accuracy: 77.60 (last), 76.36 (average), 86.80 (best)<br>​    Proportion weighting accuracy: 77.60 (last), 77.21 (average), 86.80 (best)</p><p>​    </p><pre><code>100%|█████████████████████████████████████████████████████████████████████████▋| 59750/60000 [4:52:40&lt;01:13,  3.40it/s]</code></pre><p>​    All activity accuracy: 74.80 (last), 76.35 (average), 86.80 (best)<br>​    Proportion weighting accuracy: 76.40 (last), 77.21 (average), 86.80 (best)</p><p>​    </p><pre><code>100%|██████████████████████████████████████████████████████████████████████████| 60000/60000 [4:53:53&lt;00:00,  3.54it/s]Progress: 1 / 1 (17633.7226 seconds)Training complete.</code></pre><p>​    </p><h4 id="result"><a href="#result" class="headerlink" title="result"></a>result</h4><p>All activity accuracy: 76.40 (last), 75.78 (average), 84.00 (best)<br>Proportion weighting accuracy: 75.60 (last), 76.45 (average), 85.20 (best)</p><p>100%|██████████████████████████████████████████████████████████████████████████| 60000/60000 [4:52:35&lt;00:00,  3.48it/s]<br>Progress: 1 / 1 (17555.5081 seconds)<br>Training complete.</p><pre><code>tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,        0., 0., 0., 0.])</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;STDP手写数字识别&quot;&gt;&lt;a href=&quot;#STDP手写数字识别&quot; class=&quot;headerlink&quot; title=&quot;STDP手写数字识别&quot;&gt;&lt;/a&gt;STDP手写数字识别&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;mnist.png&quot; alt=&quot;image.png&quot;&gt;&lt;
      
    
    </summary>
    
    
      <category term="snn" scheme="http://yoursite.com/categories/snn/"/>
    
    
  </entry>
  
  <entry>
    <title>动态规划老实人买卖股票</title>
    <link href="http://yoursite.com/2019/10/20/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E4%B9%8B%E4%B9%B0%E5%8D%96%E8%82%A1%E7%A5%A8/"/>
    <id>http://yoursite.com/2019/10/20/动态规划之买卖股票/</id>
    <published>2019-10-20T06:57:15.000Z</published>
    <updated>2020-01-03T00:29:17.341Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 121.买卖股票最佳时机I</span></span><br><span class="line"><span class="comment"> * 只能买卖一次</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxProfitI</span><span class="params">(<span class="keyword">int</span>[] prices)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (prices.length == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[prices.length][<span class="number">2</span>];</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">1</span>] = -prices[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; prices.length; i++) &#123;</span><br><span class="line">        dp[i][<span class="number">0</span>] = Math.max(dp[i - <span class="number">1</span>][<span class="number">0</span>], dp[i - <span class="number">1</span>][<span class="number">1</span>] + prices[i]);</span><br><span class="line">        dp[i][<span class="number">1</span>] = Math.max(dp[i - <span class="number">1</span>][<span class="number">1</span>], -prices[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dp[prices.length - <span class="number">1</span>][<span class="number">0</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 122.买卖股票最佳时机II</span></span><br><span class="line"><span class="comment"> * 如果是无限次的买卖机会，那么肯定就是能赚钱的都买卖</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> prices</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxProfitII</span><span class="params">(<span class="keyword">int</span>[] prices)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (prices.length == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[prices.length][<span class="number">2</span>];</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">1</span>] = -prices[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; prices.length; i++) &#123;</span><br><span class="line">        dp[i][<span class="number">0</span>] = Math.max(dp[i - <span class="number">1</span>][<span class="number">0</span>], dp[i - <span class="number">1</span>][<span class="number">1</span>] + prices[i]);</span><br><span class="line">        dp[i][<span class="number">1</span>] = Math.max(dp[i - <span class="number">1</span>][<span class="number">1</span>], dp[i - <span class="number">1</span>][<span class="number">0</span>] - prices[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dp[prices.length - <span class="number">1</span>][<span class="number">0</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 123.卖卖股票的最佳时机III</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> prices</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxProfitIII</span><span class="params">(<span class="keyword">int</span>[] prices)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (prices.length == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span>[][][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[prices.length][<span class="number">3</span>][<span class="number">2</span>];</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">1</span>][<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">1</span>][<span class="number">1</span>] = -prices[<span class="number">0</span>];</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">2</span>][<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">2</span>][<span class="number">1</span>] = -prices[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; prices.length; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">2</span>; j &gt;= <span class="number">1</span>; j--) &#123;</span><br><span class="line">            dp[i][j][<span class="number">0</span>] = Math.max(dp[i - <span class="number">1</span>][j][<span class="number">0</span>], dp[i - <span class="number">1</span>][j][<span class="number">1</span>] + prices[i]);</span><br><span class="line">            dp[i][j][<span class="number">1</span>] = Math.max(dp[i - <span class="number">1</span>][j][<span class="number">1</span>], dp[i - <span class="number">1</span>][j - <span class="number">1</span>][<span class="number">0</span>] - prices[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dp[prices.length - <span class="number">1</span>][<span class="number">2</span>][<span class="number">0</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 188.买卖股票最佳时机IV</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> prices</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxProfitIV</span><span class="params">(<span class="keyword">int</span>[] prices, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (prices.length == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (k &gt;= prices.length / <span class="number">2</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> maxProfitII(prices);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span>[][][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[prices.length][k + <span class="number">1</span>][<span class="number">2</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= k; i++) &#123;</span><br><span class="line">        dp[<span class="number">0</span>][i][<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">        dp[<span class="number">0</span>][i][<span class="number">1</span>] = -prices[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; prices.length; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = k; j &gt;= <span class="number">1</span>; j--) &#123;</span><br><span class="line">            dp[i][j][<span class="number">0</span>] = Math.max(dp[i - <span class="number">1</span>][j][<span class="number">0</span>], dp[i - <span class="number">1</span>][j][<span class="number">1</span>] + prices[i]);</span><br><span class="line">            dp[i][j][<span class="number">1</span>] = Math.max(dp[i - <span class="number">1</span>][j][<span class="number">1</span>], dp[i - <span class="number">1</span>][j - <span class="number">1</span>][<span class="number">0</span>] - prices[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dp[prices.length - <span class="number">1</span>][k][<span class="number">0</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 309.最佳股票买卖时机V</span></span><br><span class="line"><span class="comment"> * 含有冷冻期</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> prices</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxProfitV</span><span class="params">(<span class="keyword">int</span>[] prices)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (prices.length == <span class="number">0</span> || prices.length == <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[prices.length][<span class="number">2</span>];</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">1</span>] = -prices[<span class="number">0</span>];</span><br><span class="line">    dp[<span class="number">1</span>][<span class="number">0</span>] = Math.max(dp[<span class="number">0</span>][<span class="number">0</span>], dp[<span class="number">0</span>][<span class="number">1</span>] + prices[<span class="number">1</span>]);</span><br><span class="line">    dp[<span class="number">1</span>][<span class="number">1</span>] = Math.max(dp[<span class="number">0</span>][<span class="number">1</span>], -prices[<span class="number">1</span>]);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">2</span>; i &lt; prices.length; i++) &#123;</span><br><span class="line">        dp[i][<span class="number">0</span>] = Math.max(dp[i - <span class="number">1</span>][<span class="number">0</span>], dp[i - <span class="number">1</span>][<span class="number">1</span>] + prices[i]);</span><br><span class="line">        dp[i][<span class="number">1</span>] = Math.max(dp[i - <span class="number">1</span>][<span class="number">1</span>], dp[i - <span class="number">2</span>][<span class="number">0</span>] - prices[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dp[prices.length - <span class="number">1</span>][<span class="number">0</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 714. 买卖股票的最佳时机</span></span><br><span class="line"><span class="comment"> * 含手续费</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> prices</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> fee</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxProfitVI</span><span class="params">(<span class="keyword">int</span>[] prices, <span class="keyword">int</span> fee)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (prices.length == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[prices.length][<span class="number">2</span>];</span><br><span class="line"></span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">1</span>] = -prices[<span class="number">0</span>] - fee;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; prices.length; i++) &#123;</span><br><span class="line">        dp[i][<span class="number">0</span>] = Math.max(dp[i - <span class="number">1</span>][<span class="number">0</span>], dp[i - <span class="number">1</span>][<span class="number">1</span>] + prices[i]);</span><br><span class="line">        dp[i][<span class="number">1</span>] = Math.max(dp[i - <span class="number">1</span>][<span class="number">1</span>], dp[i - <span class="number">1</span>][<span class="number">0</span>] - prices[i] - fee);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dp[prices.length - <span class="number">1</span>][<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=
      
    
    </summary>
    
    
      <category term="算法题" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95%E9%A2%98/"/>
    
    
  </entry>
  
  <entry>
    <title>设计模式_单例</title>
    <link href="http://yoursite.com/2019/10/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    <id>http://yoursite.com/2019/10/09/设计模式/</id>
    <published>2019-10-09T13:51:30.000Z</published>
    <updated>2020-05-24T14:19:45.371Z</updated>
    
    <content type="html"><![CDATA[<h3 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h3><h4 id="类、接口和类图"><a href="#类、接口和类图" class="headerlink" title="类、接口和类图"></a>类、接口和类图</h4><ul><li><p>依赖关系<br> 类通过 局部变量， 方法参数， 或静态方法的调用来访问另外一个类。</p><pre><code>如   人： 打电话（传入--手机）</code></pre><p> 用带箭头的虚线来表示  </p></li><li><p>关联关系</p><p> 关联关系是对象之间的引用关系， 表示一类对象与另一类对象之间的关系。</p><p> 双向的关联可以用带两个箭头或者没有箭头的实线 </p></li><li><p>聚合关系</p><p> 强关联关系。 是has - a 的关系。  同样是以成员对象来实现的。成员是整体的一部分，并且成员可以单独存在。          如 ： 大学 和 老师的关系。 </p><p> 用带空心菱形的实线来表示 ， 菱形指整体</p></li><li><p>组合关系</p><p> 更强烈的聚合关系。是 contain -  a 的关系， 整体对象控制部分对象的生命周期。整体不存在，那么部分对象也将失效。    如 ： 头 和 嘴的关系<br> 用带实心菱形的实线 来表示，  菱形指整体</p></li><li><p>泛化关系<br>对象之间耦合度最大的一种关系，是 is - a 的关系。 父类与子类的关系，继承关系。</p><pre><code>如 ： 人 —&gt; 学生， 老师。</code></pre><p> 用带空心三角箭头的实线来表示 ， 三角形指父类。</p></li><li><p>实现关系</p><p> 接口与实现类之间的关系 ， 类中的操作实现了接口中所声明的所有的抽象操作 </p><p>如， 汽车 和 船实现的交通工具。</p><p> 空心三角箭头的虚线来表示 ，三角形指接口 。</p></li></ul><h4 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h4><ul><li><p>开闭原则</p><p>可以通过“抽象约束、封装变化”来实现开闭原则，即通过接口或者抽象类为软件实体定义一个相对稳定的抽象层，而将相同的可变因素封装在相同的具体实现类中。 </p></li><li><p>里氏替换原则（Liskov Substitution Principle，LSP） </p><p>里氏替换原则主要阐述了有关继承的一些原则，也就是什么时候应该使用继承，什么时候不应该使用继承 。</p><p>里氏替换原则通俗来讲就是：子类可以扩展父类的功能，但不能改变父类原有的功能。 </p></li><li><p>依赖倒置原则（Dependence Inversion Principle，DIP） </p><p>依赖倒置原则的目的是通过要面向接口的编程来降低类间的耦合性 </p><ol><li>每个类尽量提供接口或抽象类，或者两者都具备。</li><li>变量的声明类型尽量是接口或者是抽象类。</li><li>任何类都不应该从具体类派生。</li><li>使用继承时尽量遵循里氏替换原则。</li></ol></li><li><p>单一职责原则（Single Responsibility Principle，SRP）</p><p> 发现类的不同职责并将其分离，再封装到不同的类或模块中 </p></li><li><p>接口隔离原则（Interface Segregation Principle，ISP） </p><p>要求程序员尽量将臃肿庞大的接口拆分成更小的和更具体的接口，让接口中只包含客户感兴趣的方法。 </p><ol><li>接口尽量小，但是要有限度。一个接口只服务于一个子模块或业务逻辑。</li><li>为依赖接口的类定制服务。只提供调用者需要的方法，屏蔽不需要的方法。</li><li>了解环境，拒绝盲从。每个项目或产品都有选定的环境因素，环境不同，接口拆分的标准就不同深入了解业务逻辑。</li><li>.提高内聚，减少对外交互。使接口用最少的方法去完成最多的事情。</li></ol></li></ul><h4 id="创建型模式"><a href="#创建型模式" class="headerlink" title="创建型模式"></a>创建型模式</h4><h5 id="单例（Singleton）模式"><a href="#单例（Singleton）模式" class="headerlink" title="单例（Singleton）模式"></a>单例（Singleton）模式</h5><p>定义：指一个类只有一个实例，且该类能自行创建这个实例的一种模式。 </p><p>单例模式有 3 个特点：</p><ol><li>单例类只有一个实例对象；</li><li>该单例对象必须由单例类自行创建；</li><li>单例类对外提供一个访问该单例的全局访问点；</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Singleton1</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 类加载的时候就将对象实例化， 如果长时间不使用就会造成浪费</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton1 obj = <span class="keyword">new</span> Singleton1();</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton1</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> Singleton1 <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> obj;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Singleton2</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Singleton2 obj;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton2</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 多线程问题 new Singleton2 还没有构造完成， 新的请求obj == null 然后就产生了多个对象</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Singleton2 <span class="title">getInstace</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (obj == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> Singleton2();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> obj;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Singleton3</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Singleton3 obj;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton3</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 加锁解决3 的问题，但是如果对象比较大，还未创建结束就会出问题</span></span><br><span class="line">    <span class="function"><span class="keyword">synchronized</span> <span class="keyword">public</span> Singleton3 <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> == obj) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> Singleton3();</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">return</span> Singleton3.obj;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Singleton4</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Singleton4 obj;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton4</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"><span class="comment">// 使用双重锁的方式，解决三的问题</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Singleton4 <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> == obj) &#123;</span><br><span class="line">            <span class="keyword">synchronized</span> (Singleton4<span class="class">.<span class="keyword">class</span>) </span>&#123;</span><br><span class="line">                obj = <span class="keyword">new</span> Singleton4();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> Singleton4.obj;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 推荐</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Singleton6</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton6</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Java 本身来说 静态内部类 只有咋调用的时候 会加载， 而且只会加载一次</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">InstanceHolder</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> Singleton6 obj = <span class="keyword">new</span> Singleton6();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton6 <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> InstanceHolder.obj;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 推荐</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Singleton7</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton7</span><span class="params">()</span> 1    <span class="comment">//枚举只创建一次。</span></span></span><br><span class="line"><span class="function">    <span class="keyword">private</span> <span class="keyword">enum</span> Singleton </span>&#123;</span><br><span class="line">        INSTANCE;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> Singleton7 obj;</span><br><span class="line">        Singleton() &#123;</span><br><span class="line">            obj = <span class="keyword">new</span> Singleton7();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> Singleton7 <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> obj;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton7 <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Singleton.INSTANCE.getInstance();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;设计模式&quot;&gt;&lt;a href=&quot;#设计模式&quot; class=&quot;headerlink&quot; title=&quot;设计模式&quot;&gt;&lt;/a&gt;设计模式&lt;/h3&gt;&lt;h4 id=&quot;类、接口和类图&quot;&gt;&lt;a href=&quot;#类、接口和类图&quot; class=&quot;headerlink&quot; title=&quot;类、接
      
    
    </summary>
    
    
      <category term="设计模式" scheme="http://yoursite.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
  </entry>
  
  <entry>
    <title>回溯相关题目</title>
    <link href="http://yoursite.com/2019/10/09/%E5%9B%9E%E6%BA%AF/"/>
    <id>http://yoursite.com/2019/10/09/回溯/</id>
    <published>2019-10-09T13:51:30.000Z</published>
    <updated>2019-11-01T00:34:00.396Z</updated>
    
    <content type="html"><![CDATA[<h3 id="回溯相关算法题"><a href="#回溯相关算法题" class="headerlink" title="回溯相关算法题"></a>回溯相关算法题</h3><h4 id="Subsets"><a href="#Subsets" class="headerlink" title="Subsets"></a><a href="https://leetcode.com/problems/subsets/" target="_blank" rel="noopener">Subsets</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; subsets(<span class="keyword">int</span>[] nums) &#123;</span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; list = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        Arrays.sort(nums);</span><br><span class="line">        subsetsbacktrack(list, <span class="keyword">new</span> ArrayList&lt;&gt;(), nums, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> list;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">subsetsbacktrack</span><span class="params">(List&lt;List&lt;Integer&gt;&gt; list, List&lt;Integer&gt; tempList, <span class="keyword">int</span>[] nums, <span class="keyword">int</span> start)</span> </span>&#123;</span><br><span class="line">        list.add(<span class="keyword">new</span> ArrayList&lt;&gt;(tempList));</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = start; i &lt; nums.length; i++) &#123;</span><br><span class="line">            tempList.add(nums[i]);</span><br><span class="line">            subsetsbacktrack(list, tempList, nums, i + <span class="number">1</span>);</span><br><span class="line">            tempList.remove(tempList.size() - <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h4 id="Subsets-II"><a href="#Subsets-II" class="headerlink" title="Subsets II"></a><a href="https://leetcode.com/problems/subsets-ii/" target="_blank" rel="noopener">Subsets II</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; subsetsWithDup(<span class="keyword">int</span>[] nums) &#123;</span><br><span class="line">       List&lt;List&lt;Integer&gt;&gt; list = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">       Arrays.sort(nums);</span><br><span class="line">       subsetsWithDupbacktrack(list, <span class="keyword">new</span> ArrayList&lt;&gt;(), nums, <span class="number">0</span>);</span><br><span class="line">       <span class="keyword">return</span> list;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">subsetsWithDupbacktrack</span><span class="params">(List&lt;List&lt;Integer&gt;&gt; list, List&lt;Integer&gt; tempList, <span class="keyword">int</span>[] nums, <span class="keyword">int</span> start)</span> </span>&#123;</span><br><span class="line">       list.add(<span class="keyword">new</span> ArrayList&lt;&gt;(tempList));</span><br><span class="line">       <span class="keyword">for</span> (<span class="keyword">int</span> i = start; i &lt; nums.length; i++) &#123;</span><br><span class="line">           <span class="keyword">if</span> (i &gt; start &amp;&amp; nums[i] == nums[i - <span class="number">1</span>]) &#123;</span><br><span class="line">               <span class="keyword">continue</span>; <span class="comment">// skip duplicates</span></span><br><span class="line">           &#125;</span><br><span class="line">           tempList.add(nums[i]);</span><br><span class="line">           subsetsWithDupbacktrack(list, tempList, nums, i + <span class="number">1</span>);</span><br><span class="line">           tempList.remove(tempList.size() - <span class="number">1</span>);</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h4 id="Permutations"><a href="#Permutations" class="headerlink" title="Permutations"></a><a href="https://leetcode.com/problems/permutations/" target="_blank" rel="noopener">Permutations</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; permute(<span class="keyword">int</span>[] nums) &#123;</span><br><span class="line">       List&lt;List&lt;Integer&gt;&gt; list = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">       <span class="comment">// Arrays.sort(nums); // not necessary</span></span><br><span class="line">       permutebacktrack(list, <span class="keyword">new</span> ArrayList&lt;&gt;(), nums);</span><br><span class="line">       <span class="keyword">return</span> list;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">permutebacktrack</span><span class="params">(List&lt;List&lt;Integer&gt;&gt; list, List&lt;Integer&gt; tempList, <span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">if</span> (tempList.size() == nums.length) &#123;</span><br><span class="line">           list.add(<span class="keyword">new</span> ArrayList&lt;&gt;(tempList));</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++) &#123;</span><br><span class="line">               <span class="keyword">if</span> (tempList.contains(nums[i])) &#123;</span><br><span class="line">                   <span class="keyword">continue</span>; <span class="comment">// element already exists, skip</span></span><br><span class="line">               &#125;</span><br><span class="line">               tempList.add(nums[i]);</span><br><span class="line">               permutebacktrack(list, tempList, nums);</span><br><span class="line">               tempList.remove(tempList.size() - <span class="number">1</span>);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h4 id="Permutations-II"><a href="#Permutations-II" class="headerlink" title="Permutations II"></a><a href="https://leetcode.com/problems/permutations-ii/" target="_blank" rel="noopener">Permutations II</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; permuteUnique(<span class="keyword">int</span>[] nums) &#123;</span><br><span class="line">       List&lt;List&lt;Integer&gt;&gt; list = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">       Arrays.sort(nums);</span><br><span class="line">       permuteUniquebacktrack(list, <span class="keyword">new</span> ArrayList&lt;&gt;(), nums, <span class="keyword">new</span> <span class="keyword">boolean</span>[nums.length]);</span><br><span class="line">       <span class="keyword">return</span> list;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">permuteUniquebacktrack</span><span class="params">(List&lt;List&lt;Integer&gt;&gt; list, List&lt;Integer&gt; tempList, <span class="keyword">int</span>[] nums, <span class="keyword">boolean</span>[] used)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">if</span> (tempList.size() == nums.length) &#123;</span><br><span class="line">           list.add(<span class="keyword">new</span> ArrayList&lt;&gt;(tempList));</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++) &#123;</span><br><span class="line">               <span class="keyword">if</span> (used[i] || i &gt; <span class="number">0</span> &amp;&amp; nums[i] == nums[i - <span class="number">1</span>] &amp;&amp; !used[i - <span class="number">1</span>]) &#123;</span><br><span class="line">                   <span class="keyword">continue</span>;</span><br><span class="line">               &#125;</span><br><span class="line">               used[i] = <span class="keyword">true</span>;</span><br><span class="line">               tempList.add(nums[i]);</span><br><span class="line">               permuteUniquebacktrack(list, tempList, nums, used);</span><br><span class="line">               used[i] = <span class="keyword">false</span>;</span><br><span class="line">               tempList.remove(tempList.size() - <span class="number">1</span>);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h4 id="Combination"><a href="#Combination" class="headerlink" title="Combination"></a><a href="https://leetcode.com/problems/combination-sum/" target="_blank" rel="noopener">Combination</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; combinationSum(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; list = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        Arrays.sort(nums);</span><br><span class="line">        combinationSumbacktrack(list, <span class="keyword">new</span> ArrayList&lt;&gt;(), nums, target, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> list;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">combinationSumbacktrack</span><span class="params">(List&lt;List&lt;Integer&gt;&gt; list, List&lt;Integer&gt; tempList, <span class="keyword">int</span>[] nums, <span class="keyword">int</span> remain, <span class="keyword">int</span> start)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (remain &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (remain == <span class="number">0</span>) &#123;</span><br><span class="line">            list.add(<span class="keyword">new</span> ArrayList&lt;&gt;(tempList));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = start; i &lt; nums.length; i++) &#123;</span><br><span class="line">                tempList.add(nums[i]);</span><br><span class="line">                <span class="comment">// not i + 1 because we can reuse same elements</span></span><br><span class="line">                combinationSumbacktrack(list, tempList, nums, remain - nums[i], i);</span><br><span class="line">                tempList.remove(tempList.size() - <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h4 id="Combination-Sum-II"><a href="#Combination-Sum-II" class="headerlink" title="Combination Sum II"></a><a href="https://leetcode.com/problems/combination-sum-ii/" target="_blank" rel="noopener">Combination Sum II</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; combinationSum2(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">       List&lt;List&lt;Integer&gt;&gt; list = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">       Arrays.sort(nums);</span><br><span class="line">       backtrack(list, <span class="keyword">new</span> ArrayList&lt;&gt;(), nums, target, <span class="number">0</span>);</span><br><span class="line">       <span class="keyword">return</span> list;</span><br><span class="line"></span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">backtrack</span><span class="params">(List&lt;List&lt;Integer&gt;&gt; list, List&lt;Integer&gt; tempList, <span class="keyword">int</span>[] nums, <span class="keyword">int</span> remain, <span class="keyword">int</span> start)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">if</span> (remain &lt; <span class="number">0</span>) &#123;</span><br><span class="line">           <span class="keyword">return</span>;</span><br><span class="line">       &#125; <span class="keyword">else</span> <span class="keyword">if</span> (remain == <span class="number">0</span>) &#123;</span><br><span class="line">           list.add(<span class="keyword">new</span> ArrayList&lt;&gt;(tempList));</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           <span class="keyword">for</span> (<span class="keyword">int</span> i = start; i &lt; nums.length; i++) &#123;</span><br><span class="line">               <span class="keyword">if</span> (i &gt; start &amp;&amp; nums[i] == nums[i - <span class="number">1</span>]) &#123;</span><br><span class="line">                   <span class="keyword">continue</span>; <span class="comment">// skip duplicates</span></span><br><span class="line">               &#125;</span><br><span class="line">               tempList.add(nums[i]);</span><br><span class="line">               backtrack(list, tempList, nums, remain - nums[i], i + <span class="number">1</span>);</span><br><span class="line">               tempList.remove(tempList.size() - <span class="number">1</span>);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h4 id="Palindrome-Partitioning"><a href="#Palindrome-Partitioning" class="headerlink" title="Palindrome Partitioning"></a><a href="https://leetcode.com/problems/palindrome-partitioning/" target="_blank" rel="noopener">Palindrome Partitioning</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// todo</span></span><br><span class="line"><span class="keyword">public</span> List&lt;List&lt;String&gt;&gt; partition(String s) &#123;</span><br><span class="line">        List&lt;List&lt;String&gt;&gt; list = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        partitionbacktrack(list, <span class="keyword">new</span> ArrayList&lt;&gt;(), s, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> list;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">partitionbacktrack</span><span class="params">(List&lt;List&lt;String&gt;&gt; list, List&lt;String&gt; tempList, String s, <span class="keyword">int</span> start)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (start == s.length()) &#123;</span><br><span class="line">            list.add(<span class="keyword">new</span> ArrayList&lt;&gt;(tempList));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = start; i &lt; s.length(); i++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (isPalindrome(s, start, i)) &#123;</span><br><span class="line">                    tempList.add(s.substring(start, i + <span class="number">1</span>));</span><br><span class="line">                    partitionbacktrack(list, tempList, s, i + <span class="number">1</span>);</span><br><span class="line">                    tempList.remove(tempList.size() - <span class="number">1</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isPalindrome</span><span class="params">(String s, <span class="keyword">int</span> low, <span class="keyword">int</span> high)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (low &lt; high) &#123;</span><br><span class="line">            <span class="keyword">if</span> (s.charAt(low++) != s.charAt(high--)) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h4 id="combine"><a href="#combine" class="headerlink" title="combine"></a><a href>combine</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; combine(<span class="keyword">int</span> n, <span class="keyword">int</span> k) &#123;</span><br><span class="line">       List&lt;List&lt;Integer&gt;&gt; res = <span class="keyword">new</span> ArrayList&lt;List&lt;Integer&gt;&gt;();</span><br><span class="line">       helper(res, <span class="keyword">new</span> ArrayList&lt;Integer&gt;(),<span class="number">1</span> , n, k);</span><br><span class="line">       <span class="keyword">return</span> res;</span><br><span class="line"></span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">helper</span><span class="params">(List&lt;List&lt;Integer&gt;&gt; res, List&lt;Integer&gt; tmp, <span class="keyword">int</span> start, <span class="keyword">int</span> n, <span class="keyword">int</span> k)</span></span>&#123;</span><br><span class="line">       <span class="keyword">if</span> (tmp.size() == k)&#123;</span><br><span class="line">           res.add(<span class="keyword">new</span> ArrayList&lt;Integer&gt;(tmp));</span><br><span class="line">           <span class="keyword">return</span>;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">for</span> (<span class="keyword">int</span> i = start; i &lt;= n; i++)&#123;</span><br><span class="line">           tmp.add(i);</span><br><span class="line">           helper(res, tmp,i + <span class="number">1</span>, n, k - <span class="number">1</span>);</span><br><span class="line">           tmp.remove(tmp.size() - <span class="number">1</span>);</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;回溯相关算法题&quot;&gt;&lt;a href=&quot;#回溯相关算法题&quot; class=&quot;headerlink&quot; title=&quot;回溯相关算法题&quot;&gt;&lt;/a&gt;回溯相关算法题&lt;/h3&gt;&lt;h4 id=&quot;Subsets&quot;&gt;&lt;a href=&quot;#Subsets&quot; class=&quot;headerlink
      
    
    </summary>
    
    
      <category term="算法题" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95%E9%A2%98/"/>
    
    
  </entry>
  
  <entry>
    <title>TextRNN</title>
    <link href="http://yoursite.com/2019/10/01/TextRNN/"/>
    <id>http://yoursite.com/2019/10/01/TextRNN/</id>
    <published>2019-10-01T12:52:15.000Z</published>
    <updated>2019-10-04T12:31:21.874Z</updated>
    
    <content type="html"><![CDATA[<h3 id="TextRNN"><a href="#TextRNN" class="headerlink" title="TextRNN"></a>TextRNN</h3><p>使用双向LSTM。使用最后的hidden layer全连接进行分类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> pickle <span class="keyword">as</span> pkl</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> timedelta</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">train_file_path = <span class="string">"THUCNews/data/train.txt"</span></span><br><span class="line">test_file_path = <span class="string">"THUCNews/data/test.txt"</span></span><br><span class="line">dev_file_path = <span class="string">"THUCNews/data/dev.txt"</span></span><br><span class="line">class_file_path = <span class="string">"THUCNews/data/class.txt"</span></span><br><span class="line">embedding_file_path = <span class="string">"THUCNews/data/embedding_SougouNews.npz"</span></span><br><span class="line">vocab_file_path = <span class="string">"THUCNews/data/vocab.pkl"</span></span><br><span class="line">save_file_path = <span class="string">"THUCNews/saved_dict/TextRNN.ckpt"</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载与训练好的embedding 数组</span></span><br><span class="line">embedding_pretrained = torch.tensor(</span><br><span class="line">            np.load(embedding_file_path)[<span class="string">"embeddings"</span>].astype(<span class="string">'float32'</span>))\</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成一个 字 与 id 的map 相互一一映射(tokenizer 切割方式)</span></span><br><span class="line">UNK, PAD = <span class="string">'&lt;UNK&gt;'</span>, <span class="string">'&lt;PAD&gt;'</span> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_vocab</span><span class="params">(file_path, max_size = <span class="number">10000</span>, min_freq = <span class="number">1</span>)</span>:</span> </span><br><span class="line">    vocab_dic = &#123;&#125;</span><br><span class="line">    tokenizer = <span class="keyword">lambda</span> x:[y <span class="keyword">for</span>  y <span class="keyword">in</span> x] <span class="comment"># 切割</span></span><br><span class="line">    <span class="keyword">with</span> open(file_path, <span class="string">'r'</span>, encoding = <span class="string">'UTF-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> tqdm(f):</span><br><span class="line">            content = line.split(<span class="string">'\t'</span>)[<span class="number">0</span>] <span class="comment"># 将 文本与文本类型标志 分开</span></span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> tokenizer(content):</span><br><span class="line">                vocab_dic[word] = vocab_dic.get(word, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">        vocab_list = sorted([it <span class="keyword">for</span> it <span class="keyword">in</span> vocab_dic.items() <span class="keyword">if</span> it[<span class="number">1</span>] &gt; min_freq], key = <span class="keyword">lambda</span> x:x[<span class="number">1</span>], reverse = <span class="literal">True</span>)[:max_size] </span><br><span class="line">        vocab_dic = &#123;word_count[<span class="number">0</span>]: idx <span class="keyword">for</span> idx, word_count <span class="keyword">in</span> enumerate(vocab_list)&#125;</span><br><span class="line">        vocab_dic.update(&#123;UNK: len(vocab_dic), PAD: len(vocab_dic) + <span class="number">1</span>&#125;)</span><br><span class="line">    <span class="keyword">return</span> vocab_dic</span><br></pre></td></tr></table></figure><blockquote><p>{“如”：           213}  -&gt;  213    embedding   [1.24, 2.1, 3.5, 2.52,…… 12.3, 0.234]<br>{“<unk>“：4762}   -&gt; 4762   embedding   [3.04, 3.3, 1.5, 0.52,…… 2.13, 0.341] </unk></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成与源文本与之对应的 id 数值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dataset</span><span class="params">(file_path, pad_size=<span class="number">32</span>)</span>:</span></span><br><span class="line">    contents = []</span><br><span class="line">    tokenizer = <span class="keyword">lambda</span> x:[y <span class="keyword">for</span>  y <span class="keyword">in</span> x] <span class="comment"># 切割</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(vocab_file_path):</span><br><span class="line">        vocab = pkl.load(open(vocab_file_path, <span class="string">'rb'</span>))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        vocab = get_vocab(train_file_path, <span class="number">10000</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">with</span> open(file_path, <span class="string">'r'</span>, encoding = <span class="string">'UTF-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> tqdm(f):</span><br><span class="line">            content, label = line.split(<span class="string">'\t'</span>)</span><br><span class="line">            words_line = []</span><br><span class="line">            token = tokenizer(content)</span><br><span class="line">            seq_len = len(token)</span><br><span class="line">            <span class="keyword">if</span> pad_size:</span><br><span class="line">                <span class="keyword">if</span> len(token) &lt; pad_size:</span><br><span class="line">                    token.extend([vocab.get(PAD)] * (pad_size - len(token)))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    token = token[:pad_size]</span><br><span class="line">                    seq_len = pad_size</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> token:</span><br><span class="line">                words_line.append(vocab.get(word, vocab.get(UNK)))</span><br><span class="line">            contents.append((words_line, int(label), seq_len))</span><br><span class="line">    <span class="keyword">return</span> contents</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 产生train dev 和 test 数据集合（由id组成，并与文字一一对应）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_dataset</span><span class="params">()</span>:</span></span><br><span class="line">    train = load_dataset(train_file_path, <span class="number">32</span>)</span><br><span class="line">    dev = load_dataset(dev_file_path, <span class="number">32</span>)</span><br><span class="line">    test = load_dataset(test_file_path, <span class="number">32</span>)</span><br><span class="line">    <span class="keyword">return</span> train, dev, test</span><br></pre></td></tr></table></figure><blockquote><p>（[“我”, “爱”, “中”,  “国”，”,”…….. “美”， “好”，“<pad>”，“<pad>”]，  类型，总的长度）<br>（[132,   3,      32,    44,    24,……, 32,      213,      4403,          4403 ] ，       3，   30）</pad></pad></p></blockquote><p><img src="textrnn.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Model, self).__init__()</span><br><span class="line">        self.embedding = nn.Embedding.from_pretrained(embedding_pretrained, freeze=<span class="literal">False</span>)</span><br><span class="line">        self.lstm = nn.LSTM(<span class="number">300</span>, <span class="number">32</span>, bidirectional=<span class="literal">True</span>, batch_first=<span class="literal">True</span>, dropout=<span class="number">0.5</span>) <span class="comment">#hidden_size 32</span></span><br><span class="line">        self.fc = nn.Linear(<span class="number">32</span>* <span class="number">2</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># x[0] shape 128 * 32</span></span><br><span class="line">        out = self.embedding(x[<span class="number">0</span>])</span><br><span class="line">        <span class="comment"># embedding 之后 32个 每一个都转换为 300 维度的向量</span></span><br><span class="line">        out, h_n = self.lstm(out) </span><br><span class="line">        <span class="comment"># 得到一个shape 128 * 32 * 256 -&gt; 32个字 由于是双向 每一个字对应两个hidden 所以拼起来就是32 * 256</span></span><br><span class="line">        out = self.fc(out[:, <span class="number">-1</span>, :]) <span class="comment"># 取最后一共hidden层</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_iterator</span><span class="params">(dataset, batch_size)</span>:</span></span><br><span class="line">    iter = DatasetIterater(dataset, batch_size, <span class="string">'cpu'</span>)</span><br><span class="line">    <span class="keyword">return</span> iter</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 权重初始化， 使用xavier</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_network</span><span class="params">(model)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> name, w <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">         <span class="keyword">if</span> <span class="string">'embedding'</span> <span class="keyword">not</span> <span class="keyword">in</span> name: </span><br><span class="line">            <span class="keyword">if</span> <span class="string">'weight'</span> <span class="keyword">in</span> name:</span><br><span class="line">                    nn.init.xavier_normal_(w)</span><br><span class="line">            <span class="keyword">elif</span> <span class="string">'bias'</span> <span class="keyword">in</span> name:</span><br><span class="line">                nn.init.constant_(w, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(model, train_iter, dev_iter, test_iter)</span>:</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    model.train() <span class="comment"># 训练模式</span></span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), lr =  <span class="number">1e-3</span>)</span><br><span class="line">    batch_no = <span class="number">0</span> <span class="comment"># 记录到多少batch了</span></span><br><span class="line">    dev_best_loss = float(<span class="string">'inf'</span>)</span><br><span class="line">    last_improve = <span class="number">0</span> <span class="comment"># 上次验证集loss下降的batch数</span></span><br><span class="line">    flag = <span class="literal">False</span> <span class="comment"># 是否很久没有效果提升</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">        print(<span class="string">'Epoch [&#123;&#125;/&#123;&#125;]'</span>.format(epoch + <span class="number">1</span>, <span class="number">20</span>))</span><br><span class="line">        <span class="keyword">for</span> i, (trains, labels) <span class="keyword">in</span> enumerate(train_iter):</span><br><span class="line">            outputs = model(trains)</span><br><span class="line">            model.zero_grad()</span><br><span class="line">            loss = F.cross_entropy(outputs, labels) <span class="comment"># 交叉熵损失函数</span></span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> batch_no % <span class="number">100</span> == <span class="number">0</span>: <span class="comment"># 100输出 训练集，和验证集的效果</span></span><br><span class="line">                true = labels.data.cpu()</span><br><span class="line">                predic = torch.max(outputs.data, <span class="number">1</span>)[<span class="number">1</span>].cpu() <span class="comment"># 获取输出结果中最大的作为预测类别</span></span><br><span class="line">                train_acc = metrics.accuracy_score(true, predic) <span class="comment"># 获取训练集的准确度</span></span><br><span class="line">                dev_acc, dev_loss = evaluate(model, dev_iter) <span class="comment"># 评估验证集中的效果</span></span><br><span class="line">                <span class="keyword">if</span> dev_loss &lt; dev_best_loss:</span><br><span class="line">                    dev_best_loss = dev_loss</span><br><span class="line">                    torch.save(model.state_dict(), save_file_path) <span class="comment"># 将有提升的模型参数存下来</span></span><br><span class="line">                    improve = <span class="string">'*'</span></span><br><span class="line">                    last_improve = batch_no <span class="comment"># 最后提升的批次号</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    improve = <span class="string">''</span></span><br><span class="line">                time_dif = time.time() - start_time <span class="comment"># 记录花费的时间</span></span><br><span class="line">                msg = <span class="string">'Iter: &#123;0:&gt;6&#125;,  Train Loss: &#123;1:&gt;5.2&#125;,  Train Acc: &#123;2:&gt;6.2%&#125;,  '</span> \</span><br><span class="line">                      <span class="string">'Val Loss: &#123;3:&gt;5.2&#125;,  Val Acc: &#123;4:&gt;6.2%&#125;,  Time: &#123;5&#125; &#123;6&#125;'</span></span><br><span class="line">                print(msg.format(batch_no, loss.item(), train_acc, dev_loss, dev_acc, time_dif, improve)) <span class="comment"># </span></span><br><span class="line">                model.train()</span><br><span class="line">            batch_no += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> batch_no - last_improve &gt; <span class="number">1000</span>: <span class="comment"># 如果已经超过1000次没有提升了 就主动停止训练</span></span><br><span class="line">                print(<span class="string">"No improve, auto-stoppping"</span>)</span><br><span class="line">                flag = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> flag:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    test(model, test_iter)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(model, test_iter)</span>:</span></span><br><span class="line">    model.load_state_dict(torch.load(save_file_path)) <span class="comment"># 加载以及存储的dev 效果最好的相应模型</span></span><br><span class="line">    model.eval()</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    test_acc, test_loss, test_report, test_confusion = evaluate(model, test_iter, test=<span class="literal">True</span>)</span><br><span class="line">    msg = <span class="string">'Test Loss: &#123;0:&gt;5.2&#125;,  Test Acc: &#123;1:&gt;6.2%&#125;'</span></span><br><span class="line">    print(msg.format(test_loss, test_acc))</span><br><span class="line">    print(<span class="string">"Precision, Recall and F1-Score..."</span>)</span><br><span class="line">    print(test_report)</span><br><span class="line">    print(<span class="string">"Confusion Matrix..."</span>)</span><br><span class="line">    print(test_confusion)</span><br><span class="line">    time_dif = time.time() - start_time</span><br><span class="line">    print(<span class="string">"Time usage:"</span>, time_dif)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(model, data_iter, test = False)</span>:</span></span><br><span class="line">    model.eval() <span class="comment"># eval 模式</span></span><br><span class="line">    loss_total = <span class="number">0</span></span><br><span class="line">    predict_all = np.array([], dtype = int)</span><br><span class="line">    labels_all = np.array([], dtype = int)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> texts, labels <span class="keyword">in</span> data_iter:</span><br><span class="line">            outputs = model(texts)</span><br><span class="line">            loss = F.cross_entropy(outputs, labels)</span><br><span class="line">            loss_total += loss</span><br><span class="line">            labels = labels.data.cpu().numpy()</span><br><span class="line">            predic = torch.max(outputs.data, <span class="number">1</span>)[<span class="number">1</span>].cpu().numpy()</span><br><span class="line">            labels_all = np.append(labels_all, labels) <span class="comment"># 验证集上一个批次真实分类</span></span><br><span class="line">            predict_all = np.append(predict_all, predic) <span class="comment"># 验证集上一个批次的预测结果</span></span><br><span class="line">    acc = metrics.accuracy_score(labels_all, predict_all) <span class="comment"># 在整个验证集上的acc</span></span><br><span class="line">    <span class="keyword">if</span> test:</span><br><span class="line">        class_list = [x.strip() <span class="keyword">for</span> x <span class="keyword">in</span> open(</span><br><span class="line">             <span class="string">'THUCNews/data/class.txt'</span>).readlines()] </span><br><span class="line">        report = metrics.classification_report(labels_all, predict_all, target_names = class_list, digits=<span class="number">4</span>)</span><br><span class="line">        confusion = metrics.confusion_matrix(labels_all, predict_all)</span><br><span class="line">        <span class="keyword">return</span> acc, loss_total / len(data_iter), report, confusion</span><br><span class="line">    <span class="keyword">return</span> acc, loss_total / len(data_iter)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">()</span>:</span></span><br><span class="line">    torch.manual_seed(<span class="number">1</span>)</span><br><span class="line">    torch.cuda.manual_seed_all(<span class="number">1</span>)</span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span>  <span class="comment"># 保证每次结果一样</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    print(<span class="string">"Loading data..."</span>) <span class="comment">#vocab, </span></span><br><span class="line">    train_data, dev_data, test_data = build_dataset()</span><br><span class="line">    print(<span class="string">"+++++++++++++++++++++++++++++++++"</span>)</span><br><span class="line">    train_iter = build_iterator(train_data, <span class="number">128</span>) <span class="comment">#batch_size</span></span><br><span class="line">    print(train_iter)</span><br><span class="line">    dev_iter = build_iterator(dev_data, <span class="number">128</span>)</span><br><span class="line">    print(train_iter)</span><br><span class="line">    test_iter = build_iterator(test_data, <span class="number">128</span>)</span><br><span class="line">    print(train_iter)</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">"Loading data Complete, Using time"</span>, time.time() - start_time)</span><br><span class="line">    </span><br><span class="line">    model = Model()</span><br><span class="line">    init_network(model)</span><br><span class="line">    print(model.parameters)</span><br><span class="line">    </span><br><span class="line">    train(model, train_iter, dev_iter, test_iter)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run()</span><br></pre></td></tr></table></figure><pre><code>Loading data...180000it [00:02, 65875.25it/s]10000it [00:00, 70955.32it/s]10000it [00:00, 69962.09it/s]+++++++++++++++++++++++++++++++++&lt;__main__.DatasetIterater object at 0x000002854FC59D30&gt;&lt;__main__.DatasetIterater object at 0x000002854FC59D30&gt;&lt;__main__.DatasetIterater object at 0x000002854FC59D30&gt;Loading data Complete, Using time 3.046241283416748C:\ProgramData\Anaconda3\lib\site-packages\torch\nn\modules\rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1  &quot;num_layers={}&quot;.format(dropout, num_layers))&lt;bound method Module.parameters of Model(  (embedding): Embedding(4762, 300)  (lstm): LSTM(300, 32, batch_first=True, dropout=0.5, bidirectional=True)  (fc): Linear(in_features=64, out_features=10, bias=True))&gt;Epoch [1/20]Iter:      0,  Train Loss:   2.3,  Train Acc:  5.47%,  Val Loss:   2.3,  Val Acc:  9.99%,  Time: 3.8678135871887207 *Iter:    100,  Train Loss:   1.9,  Train Acc: 28.91%,  Val Loss:   1.9,  Val Acc: 31.62%,  Time: 22.469587802886963 *Iter:    200,  Train Loss:   1.4,  Train Acc: 51.56%,  Val Loss:   1.2,  Val Acc: 55.65%,  Time: 40.84703755378723 *Iter:    300,  Train Loss:  0.95,  Train Acc: 72.66%,  Val Loss:   1.1,  Val Acc: 65.07%,  Time: 60.29182720184326 *Iter:    400,  Train Loss:  0.78,  Train Acc: 75.78%,  Val Loss:  0.81,  Val Acc: 74.96%,  Time: 78.93504977226257 *Iter:    500,  Train Loss:  0.63,  Train Acc: 82.81%,  Val Loss:  0.72,  Val Acc: 77.39%,  Time: 98.05553436279297 *Iter:    600,  Train Loss:  0.69,  Train Acc: 79.69%,  Val Loss:  0.67,  Val Acc: 79.05%,  Time: 117.16351222991943 *Iter:    700,  Train Loss:  0.63,  Train Acc: 82.03%,  Val Loss:  0.61,  Val Acc: 81.13%,  Time: 135.9926619529724 *Iter:    800,  Train Loss:   0.5,  Train Acc: 83.59%,  Val Loss:  0.57,  Val Acc: 82.46%,  Time: 155.52704286575317 *Iter:    900,  Train Loss:  0.52,  Train Acc: 83.59%,  Val Loss:  0.55,  Val Acc: 82.95%,  Time: 174.2003309726715 *Iter:   1000,  Train Loss:  0.44,  Train Acc: 86.72%,  Val Loss:  0.54,  Val Acc: 83.21%,  Time: 192.82258319854736 *Iter:   1100,  Train Loss:   0.4,  Train Acc: 89.84%,  Val Loss:  0.49,  Val Acc: 84.65%,  Time: 211.5442943572998 *Iter:   1200,  Train Loss:  0.36,  Train Acc: 89.06%,  Val Loss:  0.48,  Val Acc: 85.20%,  Time: 230.28150415420532 *Iter:   1300,  Train Loss:  0.48,  Train Acc: 83.59%,  Val Loss:  0.48,  Val Acc: 85.06%,  Time: 249.9981701374054 *Iter:   1400,  Train Loss:  0.55,  Train Acc: 84.38%,  Val Loss:  0.46,  Val Acc: 85.76%,  Time: 268.71038818359375 *Epoch [2/20]Iter:   1500,  Train Loss:  0.48,  Train Acc: 85.16%,  Val Loss:  0.45,  Val Acc: 85.83%,  Time: 287.3316514492035 *Iter:   1600,  Train Loss:  0.45,  Train Acc: 85.16%,  Val Loss:  0.46,  Val Acc: 85.38%,  Time: 306.0338559150696 Iter:   1700,  Train Loss:  0.42,  Train Acc: 84.38%,  Val Loss:  0.43,  Val Acc: 86.62%,  Time: 324.7470557689667 *Iter:   1800,  Train Loss:  0.34,  Train Acc: 90.62%,  Val Loss:  0.44,  Val Acc: 86.25%,  Time: 343.53873229026794 Iter:   1900,  Train Loss:  0.36,  Train Acc: 88.28%,  Val Loss:  0.41,  Val Acc: 86.96%,  Time: 362.429979801178 *Iter:   2000,  Train Loss:  0.41,  Train Acc: 87.50%,  Val Loss:  0.41,  Val Acc: 86.97%,  Time: 381.4939856529236 *Iter:   2100,  Train Loss:  0.45,  Train Acc: 87.50%,  Val Loss:   0.4,  Val Acc: 87.39%,  Time: 400.5055284500122 *Iter:   2200,  Train Loss:  0.28,  Train Acc: 91.41%,  Val Loss:  0.41,  Val Acc: 87.08%,  Time: 419.2572121620178 Iter:   2300,  Train Loss:  0.32,  Train Acc: 90.62%,  Val Loss:   0.4,  Val Acc: 87.43%,  Time: 438.2492642402649 *Iter:   2400,  Train Loss:  0.31,  Train Acc: 91.41%,  Val Loss:   0.4,  Val Acc: 87.65%,  Time: 456.98245310783386 *Iter:   2500,  Train Loss:  0.28,  Train Acc: 90.62%,  Val Loss:   0.4,  Val Acc: 86.99%,  Time: 476.24933409690857 Iter:   2600,  Train Loss:  0.36,  Train Acc: 88.28%,  Val Loss:  0.39,  Val Acc: 87.81%,  Time: 495.0570206642151 *Iter:   2700,  Train Loss:  0.27,  Train Acc: 93.75%,  Val Loss:  0.39,  Val Acc: 87.61%,  Time: 513.9666152000427 *Iter:   2800,  Train Loss:  0.44,  Train Acc: 85.94%,  Val Loss:  0.38,  Val Acc: 87.87%,  Time: 532.8607122898102 *Epoch [3/20]Iter:   2900,  Train Loss:   0.4,  Train Acc: 89.06%,  Val Loss:  0.38,  Val Acc: 87.80%,  Time: 551.6988520622253 Iter:   3000,  Train Loss:  0.29,  Train Acc: 89.06%,  Val Loss:  0.38,  Val Acc: 88.30%,  Time: 570.5799615383148 *Iter:   3100,  Train Loss:  0.28,  Train Acc: 89.84%,  Val Loss:  0.39,  Val Acc: 87.66%,  Time: 589.4430770874023 Iter:   3200,  Train Loss:  0.35,  Train Acc: 90.62%,  Val Loss:  0.38,  Val Acc: 87.63%,  Time: 608.1702740192413 Iter:   3300,  Train Loss:  0.37,  Train Acc: 85.94%,  Val Loss:  0.38,  Val Acc: 87.97%,  Time: 627.0054371356964 Iter:   3400,  Train Loss:   0.3,  Train Acc: 89.84%,  Val Loss:  0.38,  Val Acc: 88.29%,  Time: 645.7606160640717 Iter:   3500,  Train Loss:  0.29,  Train Acc: 91.41%,  Val Loss:  0.37,  Val Acc: 88.25%,  Time: 665.3868064880371 *Iter:   3600,  Train Loss:   0.2,  Train Acc: 93.75%,  Val Loss:  0.37,  Val Acc: 88.15%,  Time: 684.3798725605011 Iter:   3700,  Train Loss:  0.37,  Train Acc: 84.38%,  Val Loss:  0.36,  Val Acc: 88.40%,  Time: 703.2969629764557 *Iter:   3800,  Train Loss:  0.32,  Train Acc: 89.06%,  Val Loss:  0.36,  Val Acc: 88.65%,  Time: 722.1076171398163 Iter:   3900,  Train Loss:  0.33,  Train Acc: 88.28%,  Val Loss:  0.36,  Val Acc: 88.56%,  Time: 741.0077271461487 Iter:   4000,  Train Loss:  0.24,  Train Acc: 91.41%,  Val Loss:  0.37,  Val Acc: 88.10%,  Time: 759.8083894252777 Iter:   4100,  Train Loss:  0.34,  Train Acc: 89.06%,  Val Loss:  0.37,  Val Acc: 88.56%,  Time: 778.7774691581726 Iter:   4200,  Train Loss:  0.34,  Train Acc: 92.19%,  Val Loss:  0.35,  Val Acc: 88.69%,  Time: 797.5661556720734 *Epoch [4/20]Iter:   4300,  Train Loss:  0.26,  Train Acc: 92.19%,  Val Loss:  0.36,  Val Acc: 88.57%,  Time: 816.4322924613953 Iter:   4400,  Train Loss:  0.15,  Train Acc: 93.75%,  Val Loss:  0.36,  Val Acc: 88.61%,  Time: 835.2734205722809 Iter:   4500,  Train Loss:  0.31,  Train Acc: 89.84%,  Val Loss:  0.35,  Val Acc: 88.54%,  Time: 854.1645164489746 *Iter:   4600,  Train Loss:  0.22,  Train Acc: 92.19%,  Val Loss:  0.36,  Val Acc: 88.29%,  Time: 873.123607635498 Iter:   4700,  Train Loss:  0.37,  Train Acc: 89.06%,  Val Loss:  0.36,  Val Acc: 88.73%,  Time: 892.0637054443359 Iter:   4800,  Train Loss:  0.18,  Train Acc: 92.19%,  Val Loss:  0.36,  Val Acc: 88.60%,  Time: 911.1337130069733 Iter:   4900,  Train Loss:  0.22,  Train Acc: 92.97%,  Val Loss:  0.36,  Val Acc: 88.87%,  Time: 930.1882197856903 Iter:   5000,  Train Loss:  0.34,  Train Acc: 87.50%,  Val Loss:  0.36,  Val Acc: 88.76%,  Time: 949.0653252601624 Iter:   5100,  Train Loss:  0.28,  Train Acc: 88.28%,  Val Loss:  0.35,  Val Acc: 88.85%,  Time: 968.1674032211304 *Iter:   5200,  Train Loss:  0.33,  Train Acc: 86.72%,  Val Loss:  0.35,  Val Acc: 88.98%,  Time: 987.1639504432678 Iter:   5300,  Train Loss:   0.2,  Train Acc: 91.41%,  Val Loss:  0.35,  Val Acc: 88.65%,  Time: 1005.9341161251068 Iter:   5400,  Train Loss:  0.34,  Train Acc: 89.84%,  Val Loss:  0.35,  Val Acc: 89.01%,  Time: 1024.9731514453888 Iter:   5500,  Train Loss:  0.22,  Train Acc: 92.19%,  Val Loss:  0.35,  Val Acc: 88.74%,  Time: 1045.3965137004852 Iter:   5600,  Train Loss:  0.16,  Train Acc: 96.88%,  Val Loss:  0.35,  Val Acc: 88.91%,  Time: 1065.713327884674 Epoch [5/20]Iter:   5700,  Train Loss:  0.29,  Train Acc: 90.62%,  Val Loss:  0.35,  Val Acc: 88.90%,  Time: 1085.443971157074 Iter:   5800,  Train Loss:  0.17,  Train Acc: 95.31%,  Val Loss:  0.35,  Val Acc: 88.97%,  Time: 1104.4659898281097 Iter:   5900,  Train Loss:  0.24,  Train Acc: 90.62%,  Val Loss:  0.36,  Val Acc: 88.75%,  Time: 1124.85223031044 Iter:   6000,  Train Loss:  0.28,  Train Acc: 90.62%,  Val Loss:  0.36,  Val Acc: 88.90%,  Time: 1146.5233688354492 Iter:   6100,  Train Loss:  0.31,  Train Acc: 89.06%,  Val Loss:  0.36,  Val Acc: 88.79%,  Time: 1166.4595756530762 No improve, auto-stopppingTest Loss:  0.35,  Test Acc: 89.18%Precision, Recall and F1-Score...               precision    recall  f1-score   support      finance     0.9049    0.8470    0.8750      1000       realty     0.8627    0.9360    0.8978      1000       stocks     0.8492    0.7770    0.8115      1000    education     0.9258    0.9360    0.9309      1000      science     0.8071    0.8620    0.8337      1000      society     0.9007    0.8890    0.8948      1000     politics     0.8752    0.8770    0.8761      1000       sports     0.9706    0.9560    0.9632      1000         game     0.9197    0.9160    0.9178      1000entertainment     0.9084    0.9220    0.9151      1000    micro avg     0.8918    0.8918    0.8918     10000    macro avg     0.8924    0.8918    0.8916     10000 weighted avg     0.8924    0.8918    0.8916     10000Confusion Matrix...[[847  36  67   5  21   8  12   1   2   1] [  9 936  12   2   8   9   6   3   4  11] [ 58  44 777   1  58   1  44   1  13   3] [  0   5   3 936  14  16  13   0   4   9] [  4  13  25   8 862  16  16   3  38  15] [  5  22   1  24  16 889  24   2   4  13] [  6  12  19  18  22  29 877   2   4  11] [  1   3   3   2   3   5   5 956   1  21] [  2   2   6   2  52   7   2   2 916   9] [  4  12   2  13  12   7   3  15  10 922]]Time usage: 3.51796293258667</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;TextRNN&quot;&gt;&lt;a href=&quot;#TextRNN&quot; class=&quot;headerlink&quot; title=&quot;TextRNN&quot;&gt;&lt;/a&gt;TextRNN&lt;/h3&gt;&lt;p&gt;使用双向LSTM。使用最后的hidden layer全连接进行分类。&lt;/p&gt;
&lt;figure cla
      
    
    </summary>
    
    
      <category term="nlp" scheme="http://yoursite.com/categories/nlp/"/>
    
    
  </entry>
  
  <entry>
    <title>TextCNN</title>
    <link href="http://yoursite.com/2019/09/25/TextCNN/"/>
    <id>http://yoursite.com/2019/09/25/TextCNN/</id>
    <published>2019-09-25T08:52:15.000Z</published>
    <updated>2019-10-04T12:30:43.928Z</updated>
    
    <content type="html"><![CDATA[<h3 id="TextCnn"><a href="#TextCnn" class="headerlink" title="TextCnn"></a>TextCnn</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> pickle <span class="keyword">as</span> pkl</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> timedelta</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br></pre></td></tr></table></figure><h4 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h4><p>数据集采用THUCNEWS，和预处理的embedding</p><ol><li>class.text, test.txt, train.txt 2. embedding_SougouNew.npz</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">train_file_path = <span class="string">"THUCNews/data/train.txt"</span></span><br><span class="line">test_file_path = <span class="string">"THUCNews/data/test.txt"</span></span><br><span class="line">dev_file_path = <span class="string">"THUCNews/data/dev.txt"</span></span><br><span class="line">class_file_path = <span class="string">"THUCNews/data/class.txt"</span></span><br><span class="line">embedding_file_path = <span class="string">"THUCNews/data/embedding_SougouNews.npz"</span></span><br><span class="line">vocab_file_path = <span class="string">"THUCNews/data/vocab.pkl"</span></span><br><span class="line">save_file_path = <span class="string">"THUCNews/saved_dict/TextCNN.ckpt"</span></span><br></pre></td></tr></table></figure><ul><li>现在开始处理数据，我们采用以字为单位的方式来进行处理<ul><li>以字为单位分割， 并且统计每一个字出现的个数。可以去除出现次数非常少的字（min_freq）,确定vocab的最大长度（max_size）</li><li>生成一个 字 与 id 的map 相互一一映射(tokenizer 切割方式)</li><li>生成与源文本与之对应的 id 数值 </li><li>保证没一段文本的长度固定，字数超过就切断，如果字数不够 则加 PAD</li><li>如果到字表中没有的字 则一律采用一个标志 UNK 来表示<br>（PAD 和 UNK 实际上都是对应着一个向量）</li><li>使用DataLoader在训练的时候进行批次加载</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成一个 字 与 id 的map 相互一一映射(tokenizer 切割方式)</span></span><br><span class="line">UNK, PAD = <span class="string">'&lt;UNK&gt;'</span>, <span class="string">'&lt;PAD&gt;'</span> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_vocab</span><span class="params">(file_path, max_size = <span class="number">10000</span>, min_freq = <span class="number">1</span>)</span>:</span> </span><br><span class="line">    vocab_dic = &#123;&#125;</span><br><span class="line">    tokenizer = <span class="keyword">lambda</span> x:[y <span class="keyword">for</span>  y <span class="keyword">in</span> x] <span class="comment"># 切割</span></span><br><span class="line">    <span class="keyword">with</span> open(file_path, <span class="string">'r'</span>, encoding = <span class="string">'UTF-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> tqdm(f):</span><br><span class="line">            content = line.split(<span class="string">'\t'</span>)[<span class="number">0</span>] <span class="comment"># 将 文本与文本类型标志 分开</span></span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> tokenizer(content):</span><br><span class="line">                vocab_dic[word] = vocab_dic.get(word, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">        vocab_list = sorted([it <span class="keyword">for</span> it <span class="keyword">in</span> vocab_dic.items() <span class="keyword">if</span> it[<span class="number">1</span>] &gt; min_freq], key = <span class="keyword">lambda</span> x:x[<span class="number">1</span>], reverse = <span class="literal">True</span>)[:max_size] </span><br><span class="line">        vocab_dic = &#123;word_count[<span class="number">0</span>]: idx <span class="keyword">for</span> idx, word_count <span class="keyword">in</span> enumerate(vocab_list)&#125;</span><br><span class="line">        vocab_dic.update(&#123;UNK: len(vocab_dic), PAD: len(vocab_dic) + <span class="number">1</span>&#125;)</span><br><span class="line">    <span class="keyword">return</span> vocab_dic</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get_vocab(train_file_path, 10000, 1)</span></span><br></pre></td></tr></table></figure><blockquote><p>{“如”：           213}  -&gt;  213    embedding   [1.24, 2.1, 3.5, 2.52,…… 12.3, 0.234]<br>{“<unk>“：4762}   -&gt; 4762   embedding   [3.04, 3.3, 1.5, 0.52,…… 2.13, 0.341] </unk></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成与源文本与之对应的 id 数值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dataset</span><span class="params">(file_path, pad_size=<span class="number">32</span>)</span>:</span></span><br><span class="line">    contents = []</span><br><span class="line">    tokenizer = <span class="keyword">lambda</span> x:[y <span class="keyword">for</span>  y <span class="keyword">in</span> x] <span class="comment"># 切割</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(vocab_file_path):</span><br><span class="line">        vocab = pkl.load(open(vocab_file_path, <span class="string">'rb'</span>))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        vocab = get_vocab(train_file_path, <span class="number">10000</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">with</span> open(file_path, <span class="string">'r'</span>, encoding = <span class="string">'UTF-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> tqdm(f):</span><br><span class="line">            content, label = line.split(<span class="string">'\t'</span>)</span><br><span class="line">            words_line = []</span><br><span class="line">            token = tokenizer(content)</span><br><span class="line">            seq_len = len(token)</span><br><span class="line">            <span class="keyword">if</span> pad_size:</span><br><span class="line">                <span class="keyword">if</span> len(token) &lt; pad_size:</span><br><span class="line">                    token.extend([vocab.get(PAD)] * (pad_size - len(token)))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    token = token[:pad_size]</span><br><span class="line">                    seq_len = pad_size</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> token:</span><br><span class="line">                words_line.append(vocab.get(word, vocab.get(UNK)))</span><br><span class="line">            contents.append((words_line, int(label), seq_len))</span><br><span class="line">    <span class="keyword">return</span> contents</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#load_dataset(train_file_path)</span></span><br></pre></td></tr></table></figure><blockquote><p>（[“我”, “爱”, “中”,  “国”，”,”…….. “美”， “好”，“<pad>”，“<pad>”]，  类型，总的长度）<br>（[132,   3,      32,    44,    24,……, 32,      213,      4403,          4403 ] ，       3，   30）</pad></pad></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 产生train dev 和 test 数据集合（由id组成，并与文字一一对应）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_dataset</span><span class="params">()</span>:</span></span><br><span class="line">    train = load_dataset(train_file_path, <span class="number">32</span>)</span><br><span class="line">    dev = load_dataset(dev_file_path, <span class="number">32</span>)</span><br><span class="line">    test = load_dataset(test_file_path, <span class="number">32</span>)</span><br><span class="line">    <span class="keyword">return</span> train, dev, test</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># build_dataset()</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 产生batch_data即就是将所有数据封装成对象， 再训练的时候一个批次一个批次的取</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DatasetIterater</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, batches, batch_size, device)</span>:</span></span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.batches = batches</span><br><span class="line">        self.n_batches = len(batches) // batch_size</span><br><span class="line">        self.residue = <span class="literal">False</span>  <span class="comment"># 记录batch数量是否为整数</span></span><br><span class="line">        <span class="keyword">if</span> len(batches) % self.n_batches != <span class="number">0</span>:</span><br><span class="line">            self.residue = <span class="literal">True</span></span><br><span class="line">        self.index = <span class="number">0</span></span><br><span class="line">        self.device = device</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_to_tensor</span><span class="params">(self, datas)</span>:</span></span><br><span class="line">        x = torch.LongTensor([_[<span class="number">0</span>] <span class="keyword">for</span> _ <span class="keyword">in</span> datas]).to(self.device)</span><br><span class="line">        y = torch.LongTensor([_[<span class="number">1</span>] <span class="keyword">for</span> _ <span class="keyword">in</span> datas]).to(self.device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># pad前的长度(超过pad_size的设为pad_size)</span></span><br><span class="line">        seq_len = torch.LongTensor([_[<span class="number">2</span>] <span class="keyword">for</span> _ <span class="keyword">in</span> datas]).to(self.device)</span><br><span class="line">        <span class="keyword">return</span> (x, seq_len), y</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__next__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.residue <span class="keyword">and</span> self.index == self.n_batches:</span><br><span class="line">            batches = self.batches[self.index * self.batch_size: len(self.batches)]</span><br><span class="line">            self.index += <span class="number">1</span></span><br><span class="line">            batches = self._to_tensor(batches)</span><br><span class="line">            <span class="keyword">return</span> batches</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> self.index &gt; self.n_batches:</span><br><span class="line">            self.index = <span class="number">0</span></span><br><span class="line">            <span class="keyword">raise</span> StopIteration</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            batches = self.batches[self.index * self.batch_size: (self.index + <span class="number">1</span>) * self.batch_size]</span><br><span class="line">            self.index += <span class="number">1</span></span><br><span class="line">            batches = self._to_tensor(batches)</span><br><span class="line">            <span class="keyword">return</span> batches</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.residue:</span><br><span class="line">            <span class="keyword">return</span> self.n_batches + <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.n_batches</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_iterator</span><span class="params">(dataset, batch_size)</span>:</span></span><br><span class="line">    iter = DatasetIterater(dataset, batch_size, <span class="string">'cpu'</span>)</span><br><span class="line">    <span class="keyword">return</span> iter</span><br></pre></td></tr></table></figure><h4 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h4><p><img src="textcnn.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">128</span> <span class="comment"># 批次大小</span></span><br><span class="line">num_epochs = <span class="number">20</span> <span class="comment"># 迭代次数</span></span><br><span class="line">drop_out = <span class="number">0.5</span> <span class="comment"># </span></span><br><span class="line">embedding = <span class="number">300</span> <span class="comment"># embedding 维度</span></span><br><span class="line">pad_size = <span class="number">32</span> <span class="comment"># 文本处理后统一的 长度</span></span><br><span class="line">filter_sizes = (<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>) <span class="comment"># </span></span><br><span class="line">num_filters = <span class="number">128</span> <span class="comment">#filter数量</span></span><br><span class="line">num_class = <span class="number">10</span> <span class="comment"># 文本类型数</span></span><br><span class="line">n_vocab = <span class="number">0</span> <span class="comment"># 词表的大小</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载与训练好的embedding 数组</span></span><br><span class="line">embedding_pretrained = torch.tensor(</span><br><span class="line">            np.load(embedding_file_path)[<span class="string">"embeddings"</span>].astype(<span class="string">'float32'</span>))</span><br></pre></td></tr></table></figure><p>为了方便查看网络结构所以我把所有参数定义在上面， 然后再网络结构中 直接写相关的数（不用变量，方便读者查看）</p><ul><li>首先是embedding的向量 对图中每一行</li><li>convs是3种不同尺寸的filter（每一种的个数可以是多个一般是2的指数）</li><li>将通过卷积运算的数据通过激活函数relu</li><li>max_pool1d的工作是取得当前的卷积运中的最大值，然后将相同尺寸的max_pool结果拼接起来。 然后再由将不同尺寸max_pool后的结果拼接起来</li><li>将拼接好的结果通过dropout 防止过拟合</li><li>通过fc网络得每一种分类的得分</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Model, self).__init__()</span><br><span class="line">        self.embedding = nn.Embedding.from_pretrained(embedding_pretrained, freeze=<span class="literal">False</span>)</span><br><span class="line">        self.convs = nn.ModuleList([nn.Conv2d(<span class="number">1</span>, <span class="number">2</span>, (k, <span class="number">300</span>)) <span class="keyword">for</span> k <span class="keyword">in</span> (<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)]) <span class="comment"># num_filters 2   kernel 2, 3, 4,  * 300</span></span><br><span class="line">        self.dropout = nn.Dropout(<span class="number">0.5</span>)</span><br><span class="line">        self.fc = nn.Linear(<span class="number">2</span> * <span class="number">3</span>, <span class="number">10</span>) <span class="comment">#  num_filters *  len(filter_sizes) num_class</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">conv_and_pool</span><span class="params">(self, x, conv)</span>:</span></span><br><span class="line">        <span class="comment"># 由forward的传过来 x 128 1 32 300</span></span><br><span class="line">        x = F.relu(conv(x)).squeeze(<span class="number">3</span>)</span><br><span class="line">        <span class="comment">#  x 128 256 31</span></span><br><span class="line">        x = F.max_pool1d(x, x.size(<span class="number">2</span>)).squeeze(<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># max_pool 取 31 个中的最大 ，得到128 256 1 然后 squeeze 得到 128 256</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># x[0] shape 128 * 32</span></span><br><span class="line">        out = self.embedding(x[<span class="number">0</span>])</span><br><span class="line">        <span class="comment"># embedding 之后 32个 每一个都转换为 300 维度的向量</span></span><br><span class="line">        <span class="comment"># out shape 128 32 300</span></span><br><span class="line">        out = out.unsqueeze(<span class="number">1</span>) <span class="comment"># 在 1 上增加一个维度 ？  why</span></span><br><span class="line">        <span class="comment"># 在 1 处增加一个维度 out shape 128 1 32 300</span></span><br><span class="line">        out = torch.cat([self.conv_and_pool(out, conv) <span class="keyword">for</span> conv <span class="keyword">in</span> self.convs], <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 横着拼在一起 128 768</span></span><br><span class="line">        out = self.dropout(out)</span><br><span class="line">        out = self.fc(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><h4 id="网络的训练"><a href="#网络的训练" class="headerlink" title="网络的训练"></a>网络的训练</h4><ul><li>权重的初始化</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 权重初始化， 使用xavier</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_network</span><span class="params">(model)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> name, w <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">         <span class="keyword">if</span> <span class="string">'embedding'</span> <span class="keyword">not</span> <span class="keyword">in</span> name: </span><br><span class="line">            <span class="keyword">if</span> <span class="string">'weight'</span> <span class="keyword">in</span> name:</span><br><span class="line">                    nn.init.xavier_normal_(w)</span><br><span class="line">            <span class="keyword">elif</span> <span class="string">'bias'</span> <span class="keyword">in</span> name:</span><br><span class="line">                nn.init.constant_(w, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><ul><li>训练<ul><li>训练的模型 在上文已经定义</li><li>训练的数据集 通过DatasetIterater批量加载数据</li><li>优化的方法 使用Adam</li><li>使用交叉熵损失函数</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(model, train_iter, dev_iter, test_iter)</span>:</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    model.train() <span class="comment"># 训练模式</span></span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), lr =  <span class="number">1e-3</span>)</span><br><span class="line">    batch_no = <span class="number">0</span> <span class="comment"># 记录到多少batch了</span></span><br><span class="line">    dev_best_loss = float(<span class="string">'inf'</span>)</span><br><span class="line">    last_improve = <span class="number">0</span> <span class="comment"># 上次验证集loss下降的batch数</span></span><br><span class="line">    flag = <span class="literal">False</span> <span class="comment"># 是否很久没有效果提升</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">        print(<span class="string">'Epoch [&#123;&#125;/&#123;&#125;]'</span>.format(epoch + <span class="number">1</span>, <span class="number">20</span>))</span><br><span class="line">        <span class="keyword">for</span> i, (trains, labels) <span class="keyword">in</span> enumerate(train_iter):</span><br><span class="line">            outputs = model(trains)</span><br><span class="line">            model.zero_grad()</span><br><span class="line">            loss = F.cross_entropy(outputs, labels) <span class="comment"># 交叉熵损失函数</span></span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> batch_no % <span class="number">100</span> == <span class="number">0</span>: <span class="comment"># 100输出 训练集，和验证集的效果</span></span><br><span class="line">                true = labels.data.cpu()</span><br><span class="line">                predic = torch.max(outputs.data, <span class="number">1</span>)[<span class="number">1</span>].cpu() <span class="comment"># 获取输出结果中最大的作为预测类别</span></span><br><span class="line">                train_acc = metrics.accuracy_score(true, predic) <span class="comment"># 获取训练集的准确度</span></span><br><span class="line">                dev_acc, dev_loss = evaluate(model, dev_iter) <span class="comment"># 评估验证集中的效果</span></span><br><span class="line">                <span class="keyword">if</span> dev_loss &lt; dev_best_loss:</span><br><span class="line">                    dev_best_loss = dev_loss</span><br><span class="line">                    torch.save(model.state_dict(), save_file_path) <span class="comment"># 将有提升的模型参数存下来</span></span><br><span class="line">                    improve = <span class="string">'*'</span></span><br><span class="line">                    last_improve = batch_no <span class="comment"># 最后提升的批次号</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    improve = <span class="string">''</span></span><br><span class="line">                time_dif = time.time() - start_time <span class="comment"># 记录花费的时间</span></span><br><span class="line">                msg = <span class="string">'Iter: &#123;0:&gt;6&#125;,  Train Loss: &#123;1:&gt;5.2&#125;,  Train Acc: &#123;2:&gt;6.2%&#125;,  '</span> \</span><br><span class="line">                      <span class="string">'Val Loss: &#123;3:&gt;5.2&#125;,  Val Acc: &#123;4:&gt;6.2%&#125;,  Time: &#123;5&#125; &#123;6&#125;'</span></span><br><span class="line">                print(msg.format(batch_no, loss.item(), train_acc, dev_loss, dev_acc, time_dif, improve)) <span class="comment"># </span></span><br><span class="line">                model.train()</span><br><span class="line">            batch_no += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> batch_no - last_improve &gt; <span class="number">1000</span>: <span class="comment"># 如果已经超过1000次没有提升了 就主动停止训练</span></span><br><span class="line">                print(<span class="string">"No improve, auto-stoppping"</span>)</span><br><span class="line">                flag = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> flag:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    test(model, test_iter)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(model, test_iter)</span>:</span></span><br><span class="line">    model.load_state_dict(torch.load(save_file_path)) <span class="comment"># 加载以及存储的dev 效果最好的相应模型</span></span><br><span class="line">    model.eval()</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    test_acc, test_loss, test_report, test_confusion = evaluate(model, test_iter, test=<span class="literal">True</span>)</span><br><span class="line">    msg = <span class="string">'Test Loss: &#123;0:&gt;5.2&#125;,  Test Acc: &#123;1:&gt;6.2%&#125;'</span></span><br><span class="line">    print(msg.format(test_loss, test_acc))</span><br><span class="line">    print(<span class="string">"Precision, Recall and F1-Score..."</span>)</span><br><span class="line">    print(test_report)</span><br><span class="line">    print(<span class="string">"Confusion Matrix..."</span>)</span><br><span class="line">    print(test_confusion)</span><br><span class="line">    time_dif = time.time() - start_time</span><br><span class="line">    print(<span class="string">"Time usage:"</span>, time_dif)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(model, data_iter, test = False)</span>:</span></span><br><span class="line">    model.eval() <span class="comment"># eval 模式</span></span><br><span class="line">    loss_total = <span class="number">0</span></span><br><span class="line">    predict_all = np.array([], dtype = int)</span><br><span class="line">    labels_all = np.array([], dtype = int)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> texts, labels <span class="keyword">in</span> data_iter:</span><br><span class="line">            outputs = model(texts)</span><br><span class="line">            loss = F.cross_entropy(outputs, labels)</span><br><span class="line">            loss_total += loss</span><br><span class="line">            labels = labels.data.cpu().numpy()</span><br><span class="line">            predic = torch.max(outputs.data, <span class="number">1</span>)[<span class="number">1</span>].cpu().numpy()</span><br><span class="line">            labels_all = np.append(labels_all, labels) <span class="comment"># 验证集上一个批次真实分类</span></span><br><span class="line">            predict_all = np.append(predict_all, predic) <span class="comment"># 验证集上一个批次的预测结果</span></span><br><span class="line">    acc = metrics.accuracy_score(labels_all, predict_all) <span class="comment"># 在整个验证集上的acc</span></span><br><span class="line">    <span class="keyword">if</span> test:</span><br><span class="line">        class_list = [x.strip() <span class="keyword">for</span> x <span class="keyword">in</span> open(</span><br><span class="line">             <span class="string">'THUCNews/data/class.txt'</span>).readlines()] </span><br><span class="line">        report = metrics.classification_report(labels_all, predict_all, target_names = class_list, digits=<span class="number">4</span>)</span><br><span class="line">        confusion = metrics.confusion_matrix(labels_all, predict_all)</span><br><span class="line">        <span class="keyword">return</span> acc, loss_total / len(data_iter), report, confusion</span><br><span class="line">    <span class="keyword">return</span> acc, loss_total / len(data_iter)</span><br></pre></td></tr></table></figure><h4 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">()</span>:</span></span><br><span class="line">    torch.manual_seed(<span class="number">1</span>)</span><br><span class="line">    torch.cuda.manual_seed_all(<span class="number">1</span>)</span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span>  <span class="comment"># 保证每次结果一样</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    print(<span class="string">"Loading data..."</span>) <span class="comment">#vocab, </span></span><br><span class="line">    train_data, dev_data, test_data = build_dataset()</span><br><span class="line">    print(<span class="string">"+++++++++++++++++++++++++++++++++"</span>)</span><br><span class="line">    train_iter = build_iterator(train_data, <span class="number">128</span>) <span class="comment">#batch_size</span></span><br><span class="line">    print(train_iter)</span><br><span class="line">    dev_iter = build_iterator(dev_data, <span class="number">128</span>)</span><br><span class="line">    print(train_iter)</span><br><span class="line">    test_iter = build_iterator(test_data, <span class="number">128</span>)</span><br><span class="line">    print(train_iter)</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">"Loading data Complete, Using time"</span>, time.time() - start_time)</span><br><span class="line">    </span><br><span class="line">    model = Model()</span><br><span class="line">    init_network(model)</span><br><span class="line">    print(model.parameters)</span><br><span class="line">    </span><br><span class="line">    train(model, train_iter, dev_iter, test_iter)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run()</span><br></pre></td></tr></table></figure><pre><code>Loading data...180000it [00:02, 70878.90it/s]10000it [00:00, 69477.66it/s]10000it [00:00, 72506.85it/s]+++++++++++++++++++++++++++++++++&lt;__main__.DatasetIterater object at 0x000001E8F73248D0&gt;&lt;__main__.DatasetIterater object at 0x000001E8F73248D0&gt;&lt;__main__.DatasetIterater object at 0x000001E8F73248D0&gt;Loading data Complete, Using time 2.84836745262146&lt;bound method Module.parameters of Model(  (embedding): Embedding(4762, 300)  (convs): ModuleList(    (0): Conv2d(1, 2, kernel_size=(2, 300), stride=(1, 1))    (1): Conv2d(1, 2, kernel_size=(3, 300), stride=(1, 1))    (2): Conv2d(1, 2, kernel_size=(4, 300), stride=(1, 1))  )  (dropout): Dropout(p=0.5)  (fc): Linear(in_features=6, out_features=10, bias=True))&gt;Epoch [1/20]Iter:      0,  Train Loss:   2.4,  Train Acc: 10.94%,  Val Loss:   2.3,  Val Acc: 11.67%,  Time: 4.347041845321655 *Iter:    100,  Train Loss:   2.0,  Train Acc: 21.88%,  Val Loss:   2.0,  Val Acc: 38.10%,  Time: 31.06502628326416 *Iter:    200,  Train Loss:   1.9,  Train Acc: 28.12%,  Val Loss:   1.8,  Val Acc: 48.73%,  Time: 56.15272235870361 *Iter:    300,  Train Loss:   1.7,  Train Acc: 35.16%,  Val Loss:   1.6,  Val Acc: 56.35%,  Time: 81.23346781730652 *Iter:    400,  Train Loss:   1.8,  Train Acc: 35.94%,  Val Loss:   1.6,  Val Acc: 60.44%,  Time: 106.87457942962646 *Iter:    500,  Train Loss:   1.7,  Train Acc: 35.16%,  Val Loss:   1.5,  Val ...........Epoch [6/20]Iter:   7100,  Train Loss:   1.6,  Train Acc: 46.09%,  Val Loss:   1.1,  Val Acc: 72.51%,  Time: 1965.9722084999084 Iter:   7200,  Train Loss:   1.5,  Train Acc: 46.09%,  Val Loss:   1.1,  Val Acc: 72.92%,  Time: 1993.864845275879 Iter:   7300,  Train Loss:   1.6,  Train Acc: 41.41%,  Val Loss:   1.1,  Val Acc: 72.55%,  Time: 2020.9455888271332 Iter:   7400,  Train Loss:   1.4,  Train Acc: 47.66%,  Val Loss:   1.1,  Val Acc: 72.65%,  Time: 2047.5681087970734 Iter:   7500,  Train Loss:   1.8,  Train Acc: 36.72%,  Val Loss:   1.1,  Val Acc: 72.65%,  Time: 2077.9685645103455 No improve, auto-stopppingTest Loss:   1.1,  Test Acc: 74.40%Precision, Recall and F1-Score...               precision    recall  f1-score   support      finance     0.8488    0.7750    0.8102      1000       realty     0.8516    0.7690    0.8082      1000       stocks     0.7146    0.6610    0.6868      1000    education     0.9013    0.8580    0.8791      1000      science     0.6545    0.6290    0.6415      1000      society     0.7890    0.6620    0.7200      1000     politics     0.4792    0.7620    0.5884      1000       sports     0.8064    0.8330    0.8195      1000         game     0.8377    0.7590    0.7964      1000entertainment     0.7485    0.7320    0.7401      1000    micro avg     0.7440    0.7440    0.7440     10000    macro avg     0.7632    0.7440    0.7490     10000 weighted avg     0.7632    0.7440    0.7490     10000Confusion Matrix...[[775   9  92  10  16   3  54  35   2   4] [ 11 769  15  12  48   5  86   7   1  46] [ 85  14 661   1  64   2 150  17   6   0] [  5  20   4 858   2  29  65   0   2  15] [ 14  22 106   7 629  12 112  17  54  27] [  4  16   5  39  11 662 211  15  10  27] [ 10  20  22  18  31  85 762  29   3  20] [  7   1   7   2  15  12  55 833   2  66] [  1   4  12   3 123   3  32  22 759  41] [  1  28   1   2  22  26  63  58  67 732]</code></pre><p>参考资料：<br><a href="https://aclweb.org/anthology/D14-1181/" target="_blank" rel="noopener">Convolutional Neural Networks for Sentence Classification</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;TextCnn&quot;&gt;&lt;a href=&quot;#TextCnn&quot; class=&quot;headerlink&quot; title=&quot;TextCnn&quot;&gt;&lt;/a&gt;TextCnn&lt;/h3&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class
      
    
    </summary>
    
    
      <category term="nlp" scheme="http://yoursite.com/categories/nlp/"/>
    
    
  </entry>
  
  <entry>
    <title>Neural Networks and Neural Language Models</title>
    <link href="http://yoursite.com/2019/09/06/Neural%20Networks%20and%20Neural%20Language%20Models/"/>
    <id>http://yoursite.com/2019/09/06/Neural Networks and Neural Language Models/</id>
    <published>2019-09-06T06:57:15.000Z</published>
    <updated>2019-09-06T02:14:58.652Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Neural-Networks-and-Neural-Language-Models"><a href="#Neural-Networks-and-Neural-Language-Models" class="headerlink" title="Neural Networks and Neural Language Models"></a>Neural Networks and Neural Language Models</h3><h4 id="Units"><a href="#Units" class="headerlink" title="Units"></a>Units</h4><p>即一个节点，输入 - &gt; 处理  -&gt;输出</p><ul><li><p><strong>bias</strong> </p><script type="math/tex; mode=display">z = b(这个就是bias) + \sum_iw_ix_i</script></li><li><p><strong>vector</strong> 将上面的 sum 看作向量的<strong>dot product</strong></p><script type="math/tex; mode=display">z = w\cdot x + b</script></li><li><p><strong>activation</strong> 把unit中的输出传入activation，事实上是当前网络的实际输出：</p><script type="math/tex; mode=display">y = a = {f(z)}</script></li></ul><ul><li><p>sigmoid:</p><script type="math/tex; mode=display">y  = \sigma(z) = \frac{1}{1 + e^{-z}}</script></li><li><p>tanh:</p><script type="math/tex; mode=display">y = \frac{e^z - e^{-z}}{e^z + e{-z}}</script></li><li><p>ReLU</p><script type="math/tex; mode=display">y = max(x, 0)</script></li></ul><h4 id="The-XOR-problem"><a href="#The-XOR-problem" class="headerlink" title="The XOR problem"></a>The XOR problem</h4><script type="math/tex; mode=display">y=\left\{\begin{array}{ll}{0,} & {\text { if } w \cdot x+b \leq 0} \\ {1,} & {\text { if } w \cdot x+b>0}\end{array}\right.</script><p>建立一个 <strong>与</strong> <strong>(a)</strong>， <strong>或</strong> <strong>(b)</strong> 网络非常简单, 但是不能建立一个网络 XOR </p><p><img src="01.png" alt="png"></p><ul><li><p><strong>decision boundary</strong>  $w1x1+w2x2+b = 0$</p><p>如果由决策边界 或者 决策面，说明是线性可分的，所以可以由单层网络直接模拟</p></li></ul><p><img src="02.png" alt="png"></p><p>由图可以明显看出 XOR 线性不可分。 所以 XOR不能被单层的感知机计算。可以叠加网络来解决这个问题。</p><p><img src="03.png" alt="png"></p><p>中间加了hidden layer 形成新的input 。新形成的input 使得其线性可分。</p><h4 id="Feed-Forward-Neural-Networks"><a href="#Feed-Forward-Neural-Networks" class="headerlink" title="Feed-Forward Neural Networks"></a>Feed-Forward Neural Networks</h4><script type="math/tex; mode=display">h = \sigma(Wx + b)\\z = Uh\\y = softmax(z)</script><p>e.g</p><script type="math/tex; mode=display">\begin{aligned} z^{[1]} &=W^{[1]} a^{[0]}+b^{[1]} \\ a^{[1]} &=g^{[1]}\left(z^{[1]}\right) \\ z^{[2]} &=W^{[2]} a^{[1]}+b^{[2]} \\ a^{[2]} &=g^{[2]}\left(z^{[2]}\right) \\ \hat{y} &=a^{[2]} \end{aligned}</script><h5 id="Training-Neural-Nets"><a href="#Training-Neural-Nets" class="headerlink" title="Training Neural Nets"></a>Training Neural Nets</h5><ul><li><p><strong>Loss funciton</strong></p><ul><li>cross-entropy loss:<script type="math/tex; mode=display">\text 二分类：： L_{CE}(\hat y, y)= -log\ p(p|x) = -[ylog\ \hat y + (1 - y)log(1-\hat y)]\\\text 多分类：：L_{CE}(\hat y,y) = - \sum_{i = 1}^{C}y_ilog\ \hat y_i</script></li></ul></li></ul><ul><li>由于上述等式处理 当前为真的其他的都将是零，所以可以简化为negative log likelihood loss:<script type="math/tex; mode=display">  L_{CE}(\hat y, y) = -log\ \hat y_i\\  \text 把softmax函数加上\  L_{CE}(\hat y,y) = -log\frac{e^{z_i}}{\sum_{i = j}^Ke^{z_j}}</script></li></ul><ul><li><p><strong>Computing thre Gradient</strong></p><ul><li>error back-propagation</li></ul></li></ul><ul><li><p><strong>Computation Graphs</strong> </p><p>如果我们计算$L(a,b,c) = c(a + 2b)$。我们可以把计算步骤分解如下：</p><script type="math/tex; mode=display">d = 2 * b\\e = a +d\\L = c * e</script><p>使用计算图来表示如下：</p><p><img src="04.png" alt="png"></p></li><li><p><strong>Backward differentiation on computation graphs</strong> </p><ul><li><p>chain rule $f(x) = u(v(x))$ 其中$f$对 $x$的导数如下：</p><script type="math/tex; mode=display">\frac{df}{dx} = \frac{du}{dv}\cdot \frac{dv}{dx}</script></li><li><p>我们继续计算上图我们需要的3个导数：</p><script type="math/tex; mode=display">\frac{\partial L}{\partial c} = e\\\frac{\partial L}{\partial a} = \frac{\partial L}{\partial e}\frac{\partial e}{\partial a}\\\frac{\partial L}{\partial b} =  \frac{\partial L}{\partial e} \frac{\partial e}{\partial d} \frac{\partial d}{\partial b}</script></li><li><p>在反向传播中我们从右边到左边计算，直到我们所需要的导数</p><p><img src="05.png" alt="png"></p></li></ul></li><li><p><strong>Backward differentiation for a neural network</strong></p><script type="math/tex; mode=display">\begin{aligned} z^{[1]} &=W^{[1]} \mathbf{x}+b^{[1]} \\ a^{[1]} &=\operatorname{RELu}\left(z^{[1]}\right) \\ z^{[2]} &=W^{[2]} a^{[1]}+b^{[2]} \\ a^{[2]} &=\sigma\left(z^{[2]}\right) \\ \hat{y} &=a^{[2]} \end{aligned}</script><p><img src="06.png" alt="png"></p><ul><li>the derivative of the sigmoid $\sigma$:<script type="math/tex; mode=display">\frac {d\sigma(z)}{dz} = \sigma(z)(1 - \sigma(z))</script></li><li><p>the derivative of tanh:</p><script type="math/tex; mode=display">\frac{dtanh(z)}{dz} = 1 - tanh^2(z)</script></li><li><p>the derivative of the ReLU</p><script type="math/tex; mode=display">\frac{d \operatorname{ReLU}(z)}{d z}=\left\{\begin{array}{ll}{0} & {\text { for } x<0} \\ {1} & {\text { for } x \geq 0}\end{array}\right.</script></li></ul></li></ul><h5 id="More-details-on-learning"><a href="#More-details-on-learning" class="headerlink" title="More details on learning"></a>More details on learning</h5><ul><li><p><strong>dropout</strong> : 防止过拟合</p></li><li><p><strong>hyperparameter</strong>：神经网络的参数是$权重\  W 和 bias\  b$ 通过梯度下降学习而来，而hyperparameters 是通过算法设计者自己选择。其包括 learning rate $\eta$,   mini-batch size， the model architecture ，如何 正则化，采用哪种梯度下降算法等等。</p></li></ul><h4 id="Neural-Language-Models"><a href="#Neural-Language-Models" class="headerlink" title="Neural Language Models"></a>Neural Language Models</h4><p>Neural Models</p><ul><li><p><strong>advance</strong>： 获取更长的的信息。概括上下文。更好的预测准确率。 是其他模型的的基础。</p></li><li><p><strong>disadvance</strong>： 训练速度慢</p></li></ul><p>n-gram 模型</p><script type="math/tex; mode=display">P(w_t| w_1^{t - 1})\approx P(w_t| w_{t - N + 1}^{t - 1})</script><h5 id="Embeddings"><a href="#Embeddings" class="headerlink" title="Embeddings"></a>Embeddings</h5><blockquote><p>e.g:I have to make sure when I get home to feed the cat. </p></blockquote><ul><li><p><strong>pretraining</strong>: 通过其他算法，如word2vec训练出embeding representations</p></li><li><p>当然也通常是在训练具体的任务中同时学习embedding </p></li></ul><p><img src="07.png" alt="png"></p><script type="math/tex; mode=display">1 * d -> 1 * 3d\\W^T.shape = 3d * d_h \\(1 * 3d) * (3d * d_h) = 1 * d_h \\U^T = d_h * |V| \\(1 * d_h) * U^T = 1 * |V|\\\text {softmax:  the probobilty of V_42 is the largest}</script><ul><li><strong>one-hot vector</strong> :</li></ul><script type="math/tex; mode=display">[\  0\ 0\  0\  0\  1\  0\  0\  ...\  0\  0\  0\  0\  ] \\  1\ 2\ 3\  4 \ 5 \ 6 \ 7 ... ...  \ |V|</script><p><img src="08.png" alt="png"></p><pre><code>  首先初始换一个 E 矩阵, 该矩阵 乘以 one-hot 之后 ,实际上就是 one-hot 所代表的那个单词的embedding.</code></pre><p>​    然后后面操作就和之前是一样的.</p><script type="math/tex; mode=display">\begin{aligned} e &=\left(E x_{1}, E x_{2}, \ldots, E x\right) \\ h &=\sigma(W e+b) \\ z &=U h \\ y &=\operatorname{softmax}(z) \end{aligned}</script><h5 id="Training-the-neural-language-model"><a href="#Training-the-neural-language-model" class="headerlink" title="Training the neural language model"></a>Training the neural language model</h5><ul><li><p>训练的参数 $ \theta = E,\ W,\ U,\ b$</p></li><li><p>使用梯度下降,反向传播.</p></li><li>由于在训练中不仅仅是训练参数,并且要预测下一个单词,所以训练出来的E 在预测下一个单词上更优秀.</li></ul><p>通常情况下,输入是一个长文本,包括所有的句子, 随机权重,然后迭代. cross-entropy(negative log likelihood) loss :</p><script type="math/tex; mode=display">L = - log\ p(w_t|w_{t-1},...,w_{t-n+1})</script><p>梯度:</p><script type="math/tex; mode=display">\theta_{t+1} = \theta_t - \eta \frac{\partial{- log\ p(w_t|w_{t-1},...,w_{t-n+1})}}{\partial \theta}</script><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>1.<a href="https://web.stanford.edu/~jurafsky/slp3/" target="_blank" rel="noopener">Neural Networks and Neural Language Models </a></p><p>2.[<a href="https://web.stanford.edu/~jurafsky/slp3/" target="_blank" rel="noopener">Vector Semantics and Embeddings</a>; </p><p>3.<a href>Word2vec Parameter Learning Explained</a>; Xin Rong ronxin@umich.edu.</p><p>4.<a href>Distributed Representations of Sentences and Documents.pdf</a>Quoc Le Tomas Mikolov Google Inc, 1600 Amphitheatre Parkway, Mountain View, CA 94043</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Neural-Networks-and-Neural-Language-Models&quot;&gt;&lt;a href=&quot;#Neural-Networks-and-Neural-Language-Models&quot; class=&quot;headerlink&quot; title=&quot;Neural N
      
    
    </summary>
    
    
      <category term="nlp" scheme="http://yoursite.com/categories/nlp/"/>
    
    
  </entry>
  
  <entry>
    <title>Transformer</title>
    <link href="http://yoursite.com/2019/08/28/Transformer/"/>
    <id>http://yoursite.com/2019/08/28/Transformer/</id>
    <published>2019-08-28T09:57:15.000Z</published>
    <updated>2019-09-01T12:11:05.955Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><h3 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h3><p><img src="trans.png" alt="png"></p><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><h4 id="先定义符号："><a href="#先定义符号：" class="headerlink" title="先定义符号："></a>先定义符号：</h4><p><strong>emb_dim</strong>：embedding的维度</p><p><strong>input_length</strong>: 输入序列的长度（不同长度的序列通过填充来使得其长度都相同）</p><p><strong>hidden_dim</strong>:forward_feedback中隐藏层的长度</p><p><strong>vocab_size</strong>:词汇表中单词的数量，总的数量</p><h4 id="数据流"><a href="#数据流" class="headerlink" title="数据流"></a>数据流</h4><ul><li><p>1.输入（<strong>input_length</strong>) <em> (<em>*emb_size</em></em>)</p></li><li><p>2.然后添加位置信息 得到（<strong>input_length</strong>) <em> (<em>*emb_size</em></em>)</p></li><li><p>3.通过N个Encoder编码块得到 （<strong>input_length</strong>) <em> (<em>*emb_size</em></em>)</p></li></ul><p>&emsp; <strong><em>note：</em></strong>N块Encoder的输入和输出尺寸维度是相同的，所以可以把上一个Encoder的输出，作为下一个Encoder的输入。</p><p>&emsp; <strong><em>note：</em></strong>每一个Encoder不会共享权重</p><h4 id="Input-Embedding"><a href="#Input-Embedding" class="headerlink" title="Input_Embedding"></a>Input_Embedding</h4><ul><li>Word_Embedding</li></ul><p>比如一句话：<em>“你好，你吃饭了吗？”</em></p><blockquote><p><strong>step1</strong> ：<em>”你好，你吃饭了吗“ -&gt; [“你好”，”,” , “你”，”吃饭”,  “了”，”吗”，”?”]</em></p><p><strong>step2</strong>:  <em>[“你好”，”,” , “你”，”吃饭”,  “了”，”吗”，”?”] -&gt;[2, 4, 5, 12, 35, 5, 34, 99]</em>     在语料中的index</p><p><strong>step3</strong>: <em>2 -&gt; E[2]  = [123.4, 0.32, ……, 32.1,32]</em></p></blockquote><p>&emsp; <strong><em>note：</em></strong>这些向量也是参数，使用反向传播进行优化/</p><blockquote><p><strong>step4</strong>：把每一个向量堆叠起来，就得到个维度为（<strong>input_length</strong>) <em> (<em>*emb_size</em></em>)的矩阵</p><p><strong>step5</strong>：每一句话的长度不一样，所以使用标记来填充长度，[<pad>, <pad>, “你”，”吃饭”， “了”，”吗”，”?”] </pad></pad></p><p>这里的<strong>input_length</strong>为7， <pad> -&gt; [999] = [213, 4.23, 413, ….]</pad></p></blockquote><ul><li>Positional_Encoding<br>作者是用预定的正弦函数来对位置信息进行编码<script type="math/tex; mode=display">p_{i, j}=\left\{\begin{array}{l}{\sin \left(\frac{i}{10000^{\frac{i}{d_{e m b_{-} d i m}}}}\right)\quad if\ j\  is\  even } \\ {\cos \left(\frac{i}{10000^{\frac{i}{d_{e m b}-d i m}}}\right)\quad if\ j\  is\  odd }\end{array}\right.</script>其中<strong>i</strong>作为序列号（第几个单词）<strong>j</strong>作为embedding的位置<script type="math/tex; mode=display">\sin \left(\frac{0}{10000^{\frac{0}{\operatorname{em} b_{d i m}}}}\right) \quad \cos \left(\frac{0}{10000^{\frac{0}{\operatorname{em} b_{d i m}}}}\right) \quad \sin \left(\frac{0}{10000^{\frac{2}{\operatorname{em} b_{d i m}}}}\right) \quad \cos \left(\frac{0}{10000^{\frac{2}{e m b_{d i m}}}}\right)\\\sin \left(\frac{1}{10000^{\frac{0}{\operatorname{em} b_{d i m}}}}\right) \quad \cos \left(\frac{1}{10000^{\frac{0}{\operatorname{em} b_{d i m}}}}\right) \quad \sin \left(\frac{1}{10000^{\frac{2}{\operatorname{em} b_{d i m}}}}\right) \quad \cos \left(\frac{1}{10000^{\frac{2}{e m b_{d i m}}}}\right)\\\\\.................</script></li></ul><p>最后的结果：<strong>X = Z + P</strong></p><p><strong>X</strong>作为第一个Encoder的输入 （<strong>input_length</strong>) <em> (<em>*emb_size</em></em>)</p><h4 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h4><p><img src="mult.png" alt="png"></p><p><strong>（input_length）x（h * d_v）</strong>。然后，将应用具有尺寸<strong>（h * d_v）x（emb_dim）</strong>的<em>权重矩阵W’的线性层，从而导致尺寸的最终结果 <em>*（input_length）x（emb_dim）</em></em></p><p>Multi-Head，就是只多做几次同样的事情，同时参数不共享，然后把结果拼接</p><p><img src="1567047917508.png" alt="png"></p><script type="math/tex; mode=display">\text { MultiHead }(Q, K, V)=\text { Concat }\left(\text { head }_{1}, \ldots, \text { head }_{\mathrm{h}}\right) W^{O}\\\text { head }_{\mathrm{i}}=\text { Attention }\left(Q W_{i}^{Q}, K W_{i}^{K}, V W_{i}^{V}\right)</script><p>其中 Q K V 就是三个输入的矩阵，每一个头部都是由给出的三个不同 K Q V投影表示</p><script type="math/tex; mode=display">\begin{array}{l}{W_{i}^{K} \text { with dimensons } d_{e m b_{-} d i m} \mathrm{x} d_{k}} \\ {W_{i}^{Q} \text { with dimensons } d_{e m b_{-} d i m} \mathrm{x} d_{k}} \\ {W_{i}^{V} \text { with dimensons } d_{e m b-d i m} \mathrm{x} d_{v}}\end{array}</script><p>输入矩阵<em>X</em>并分别将其与上述权重矩阵一起投影，得到我们的K Q V</p><script type="math/tex; mode=display">\begin{aligned} X W_{i}^{K} &=K_{i} \text { with dimensons input length } \mathrm{x} d_{k} \\ X W_{i}^{Q} &=Q_{i} \text { with dimensons input length } \mathrm{x} d_{k} \\ X W_{i}^{V} &=V_{i} \text { with dimensons input length } \mathrm{x} d_{v} \end{aligned}</script><p>&emsp; <strong><em>note：</em></strong>在论文中 <strong>d_k = d_v = emb_dim / h</strong>  </p><p>得到K Q V 之后我们就可以使用其来计算<em>Scaled Dot-Product Attention</em>：</p><script type="math/tex; mode=display">\text { Attention }(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^{T}}{\sqrt{d_{k}}}\right) V</script><p><img src="1567048488955.png" alt="png"></p><ul><li><p>我们来看看 Attention 到底做了些什么</p><p>首先我们看 </p><script type="math/tex; mode=display">Q_{i} K_{i}^{T}</script></li></ul><p>此矩阵相乘表示了什么东西？如果我们把其中的 <strong>v_i</strong> 和 <strong>u_j</strong> 单独拿出来看他们的点乘可以看作：</p><script type="math/tex; mode=display">v_{i} u_{j}=\cos \left(v_{i}, u_{j}\right)\left\|v_{i}\right\|_{2}\left\|u_{j}\right\|_{2}</script><p>因此，这是对<em>u_i</em>和<em>v_j</em>的方向有多相似以及它们的长度有多大的度量（方向最接近，长度越大，点积越大）。</p><p>在该乘法之后，为了缩放目的，矩阵被元素划分为 <strong>d_k</strong> 的平方根。论文里对于 <strong>d_k</strong> 的作用这么来解释：<strong>d_k</strong> 很大的时候，点积得到的结果维度很大，使得结果处于 <strong>softmax</strong> 函数梯度很小的区域。这时候除以一个缩放因子，可以一定程度上减缓这种情况。</p><p>最后得到结果 如下：</p><script type="math/tex; mode=display">\left(\begin{array}{cccccc}{72.40 * 10^{-06}} & {1.23 * 10^{-21}} & {6.51 * 10^{-40}} & {2.62 * 10^{-22}} & {9.99 * 10^{-01}} & {4.30 * 10^{-08}}  \\  {1.00 * 10^{+00}} & {7.51 * 10^{-30}} & {1.54 * 10^{-17}} & {9.91 * 10^{-13}} & {8.15 * 10^{-69}} & {1.09 * 10^{-30}} \\ {3.12 * 10^{-70}} & {2.51 * 10^{-51}} & {2.72 * 10^{-21}} & {8.03 * 10^{-09}} & {1.29 * 10^{-07}} & {9.99 * 10^{-01}} \\{2.47 * 10^{-72}} & {5.54 * 10^{-05}} & {9.80 * 10^{-01}} & {1.98 * 10^{-02}} & {2.77 * 10^{-82}} & {2.58 * 10^{-08}} \\{2.67 * 10^{-05}} & {1.21 * 10^{-09}} & {9.75 * 10^{-07}} & {3.17 * 10^{-76}} & {9.99 * 10^{-01}} & {3.64 * 10^{-28}} \\{8.59 * 10^{-47}} & {1.05 * 10^{-35}} & {9.99 * 10^{-01}} & {2.38 * 10^{-15}} & {4.21 * 10^{-27}} & {4.07 * 10^{-06}}\end{array}\right)</script><p>结果是数字在0和1之间的行总和为1。并且为 <strong>input_size * input_size</strong> 的大小。最后，结果乘以 <strong>V</strong>（<strong>input_size * d_v  </strong>）可以这样理解，得到的方形的矩阵，可以作为 <strong>V</strong> 的权重参数最终得到 <strong>input_size * d_v</strong>  的 <strong>head</strong> </p><p>此时就做到了单词和其他所有单词产生了特定的关系。 <strong>Multi-Head Attention</strong>就是做 h 次这样的处理，就会捕捉到 h 次不同的关系。然后把全部的 关系 串连到一起。</p><h4 id="Feed-Forward-Network"><a href="#Feed-Forward-Network" class="headerlink" title="Feed-Forward Network"></a>Feed-Forward Network</h4><p><img src="1567060993399.png" alt="png"></p><script type="math/tex; mode=display">\operatorname{FFN}(x)=\max \left(0, x W_{1}+b_{1}\right) W_{2}+b_{2}</script><p>其中 <strong>W_1 和 W_2</strong> 分别是 <strong>（emb_dim）x（d_F）</strong> 和 <strong>（d_F）x（emb_dim）</strong> 矩阵</p><p>最后输出为 <strong>（input_length）x（emb_dim）</strong>的矩阵</p><h4 id="Dropout-Add-amp-Norm"><a href="#Dropout-Add-amp-Norm" class="headerlink" title="Dropout, Add &amp; Norm"></a>Dropout, Add &amp; Norm</h4><script type="math/tex; mode=display">\text {Layer Norm }(x+\text { Dropout }(\text {Sublayer}(x)))</script><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>这里相较与 <strong>Encoder</strong> 多了：</p><p><strong>target input</strong>:目标输入</p><h4 id="数据流-1"><a href="#数据流-1" class="headerlink" title="数据流"></a>数据流</h4><ul><li><p><strong>Encoder</strong> 数据出来， <strong>input_size * emb_dim</strong></p></li><li><p>masked之后 <strong>target_length * emb_dim</strong></p></li><li><p>再输入把 Encoder 的数据传给和masked数据一起传入N个 Decoder ，<strong>target_length * emb_dim</strong></p></li><li><p>最后通过fully connected layer 和 row-wise softmax 输出 <strong>target * vocab_size</strong></p></li></ul><p>&emsp; <strong><em>note：</em></strong>每一个Block不会共享权重</p><p>输入与 <strong>Encoder</strong> 完全相同，与encoder主要的不同在于，target sequence 将左移一位，前面加上标志</p><p><ss>，例如：</ss></p><blockquote><p>[“Hola”, “, “, “como”, “estás”, “?”]→[“<ss>”, “Hola”, “, “, “como”, “estás”, “?”]</ss></p></blockquote><h4 id="Decode"><a href="#Decode" class="headerlink" title="Decode"></a>Decode</h4><ul><li>Test Time</li></ul><ol><li><p>计算embedding representation</p></li><li><p>使用开始token，比如<ss>作为序列的第一个target。然后模型的输出作为下一个token</ss></p></li><li><p>把最后一个预测的标记添加到序列之中，并使用他生成下一个新的预测</p></li><li><p>一直重复步骤3. 知道遇到表示结束的token 比如<eos></eos></p></li></ol><ul><li>Training Time</li></ul><p>按照我们之前的示例，我们将输入：</p><blockquote><p>[‘<ss>‘，’Hola’，’，’，’como’，’estas’，’？’]</ss></p></blockquote><p>  预期的预测是：</p><blockquote><p>[‘Hola’，’，’，’como’，’estas’，’？’，’<eos>‘]</eos></p></blockquote><p>由于在训练的时候，全部的信息都是已经知道的。我们应该防止通过已经看到的单词来预测单词。例如，它可能会在’como’的右侧看到’estas ‘并用它来预测’estas’。</p><p>让我们举一个例子来说明这一点。鉴于：<br>[‘<ss>‘，’Hola’，’，’，’como’，’estas’，’？’]<br>我们将如上所述将其转换为矩阵并添加位置编码。这会产生一个矩阵：</ss></p><p><img src="11.png" alt="png"></p><p><img src="12.png" alt="png"></p><p>如果要预测estas，我们能够信息能够交互的区域就如上图所示。</p><h4 id="Masked-Multi-Head-Attention"><a href="#Masked-Multi-Head-Attention" class="headerlink" title="Masked Multi-Head Attention"></a>Masked Multi-Head Attention</h4><p>与<strong>Multi-Head Attention</strong>机制完全相同，但为我们的输入添加maske。而且需要maske的唯一的block是解码器中的第一块，修改将在计算之后。</p><script type="math/tex; mode=display">\frac{Q_{i} K_{i}^{T}}{\sqrt{d_{k}}}</script><p>得到：</p><p><img src="13.png" alt="png"></p><p>maske步骤只是将矩阵的严格上三角形部分中的所有条目设置为负无穷大。</p><p><img src="14.png" alt="png"></p><p>其余部分与编码器<strong>Multi-Head Attention</strong>描述的相同。</p><p>设置为负无穷之后，通过softmax函数。其后面需要忽略的token的注意力将变为0，忽略了后面的单词。当将此矩阵与<em>V_i</em>相乘时，将用于预测下一个单词的唯一元素是其右侧的元素，即模型在测试时间内可以访问的元素。<img src="15.png" alt="png"></p><p>输出将是维度矩阵 <strong>target_length *emb_dim </strong>因为计算它的序列具有 <strong>target_length</strong> 的序列长度</p><h4 id="Multi-Head-Attention-—-Encoder-output-and-target"><a href="#Multi-Head-Attention-—-Encoder-output-and-target" class="headerlink" title="Multi-Head Attention — Encoder output and target"></a>Multi-Head Attention — Encoder output and target</h4><p><img src="16.png" alt="png"></p><p>与之前 <strong>Multi-Head Attention</strong> 层中那样从<em>X</em>中导出<em>Q_i</em>，<em>K_i</em>和<em>V_i</em>不同，而是使用编码器的最终输出<em>E</em>（所有编码器块的最终结果）和解码器的前一层输出<em>D</em>（经过<strong>Dropout，</strong> <strong>Add＆Norm </strong> <strong>图层后屏蔽</strong> <strong>的Multi-Head Attention</strong>）。</p><p>让我们首先澄清这些输入的形状及其代表的含义：</p><ol><li><em>E</em>，编码输入序列，是维度<em>（input_length）x（emb_dim）</em>的矩阵，其通过经过6个编码器块编码输入令牌之间的关系。</li><li><em>D</em>，经过<strong>Add＆Norm</strong>后屏蔽的<strong>Multi-Head Attention</strong>的输出是维度矩阵 <strong>target_length* emb_dim</strong></li></ol><p>现在让我们深入了解如何处理这些矩阵。我们将使用与以前相同尺寸的加权矩阵：</p><script type="math/tex; mode=display">\begin{array}{l}{W_{i}^{K} \text { with dimensons } d_{e m b_{-} d i m} \mathrm{x} d_{k}} \\ {W_{i}^{Q} \text { with dimensons } d_{e m b_{-} d i m} \mathrm{x} d_{k}} \\ {W_{i}^{V} \text { with dimensons } d_{e m b-d i m} \mathrm{x} d_{v}}\end{array}</script><p>但是这次投影生成 <strong>Q_i</strong> 将使用<strong>D</strong>（目标信息）完成，而生成K和V的投影将使用<strong>E</strong>（输入信息）创建。</p><script type="math/tex; mode=display">\begin{aligned} D W_{i}^{Q} &=Q_{i} \text { with dimensons target length } \mathrm{x} d_{k} \\ E W_{i}^{K} &=K_{i} \text { with dimensons input } \text {length} \mathrm{x} d_{k} \\ E W_{i}^{V} &=V_{i} \text { with dimensons input-length } \mathrm{x} d_{v} \end{aligned}</script><p>同样由多个head，串联之后使用的矩阵W_0将具有与编码器块中使用的尺寸<strong>（d_v * h）x（emb_dim）</strong>一样的尺寸。其他的与编码器中的 <strong>Multi-Head Attention</strong> 完全相同。</p><h4 id="Linear-and-Softmax"><a href="#Linear-and-Softmax" class="headerlink" title="Linear and Softmax"></a>Linear and Softmax</h4><p>来自最后一个解码器块的最后一个 <strong>Add＆Norm</strong> 层的输出是维度 <strong>（target_length）x（emb_dim）</strong>的矩阵X</p><script type="math/tex; mode=display">X W_{1}</script><p>并在每个结果行中应用Softmax</p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>1.<a href="[https://medium.com/dissecting-bert/dissecting-bert-appendix-the-decoder-3b86f66b0e5f     ](https://medium.com/dissecting-bert/dissecting-bert-appendix-the-decoder-3b86f66b0e5f">Dissecting BERT Appendix: The Decoder</a>)</p><p>2.<a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank" rel="noopener">Attention Is All You Need</a>; Vaswani et al., 2017.</p><p>3.<a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html#embeddings-and-softmax" target="_blank" rel="noopener">The Annotated Transformer</a>; Alexander Rush, Vincent Nguyen and Guillaume Klein.</p><p>4.<a href="https://medium.com/@mromerocalvo/dissecting-bert-part1-6dcf5360b07f" target="_blank" rel="noopener">Dissecting BERT Part 1: Understanding the Transformer</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Transformer&quot;&gt;&lt;a href=&quot;#Transformer&quot; class=&quot;headerlink&quot; title=&quot;Transformer&quot;&gt;&lt;/a&gt;Transformer&lt;/h2&gt;&lt;h3 id=&quot;Model-Architecture&quot;&gt;&lt;a href=&quot;
      
    
    </summary>
    
    
      <category term="ml" scheme="http://yoursite.com/categories/ml/"/>
    
    
  </entry>
  
  <entry>
    <title>Skip-Thought Vectors</title>
    <link href="http://yoursite.com/2019/08/25/Skip-Thought%20Vectors/"/>
    <id>http://yoursite.com/2019/08/25/Skip-Thought Vectors/</id>
    <published>2019-08-25T08:52:15.000Z</published>
    <updated>2020-07-12T06:52:33.493Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Skip-Thought-Vectors"><a href="#Skip-Thought-Vectors" class="headerlink" title="Skip-Thought Vectors"></a>Skip-Thought Vectors</h3><ul><li><p>目的：句子级别的无监督模型的表示 </p></li><li><p>为什么需要句子级别的表示：</p><p>两个句子的相似度，句子的所带有的情感。如果直接使用word2vec的单词进行组合，那么不同顺序的句子表示就会出现问题。比如 我爱你 和 你爱我。</p><p>需要一个更好的方法来表示句子中有单词的顺序的问题。</p><h4 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h4><p><img src="process.png" alt="png"></p></li></ul><p><strong>Skip-Thoughts 模型由三部分组成：</strong></p><ul><li><p>Encoder Network: 把位于第 i 个位置的句子  x(i)  用一个固定长度的向量 z(i) 表示. 作者使用的是GRU。</p></li><li><p>Previous Decoder NetWork： 把 embedding 的z(i)  去生成 x( i - 1) 同样使用 GRU</p></li><li><p>Next Decoder Network：和Previous Decoder NetWork 一样。</p></li></ul><p>如何训练：</p><ul><li>使得训练后的再embedding z（i）产生的上下句子 误差最小。</li></ul><p><strong>他要学习什么：</strong></p><ul><li>最后的产出应该是encoder ，decoder只是再训练时用，训练结束之后就丢弃了。</li><li>语义相似的句子得到的表示结果更接近。</li></ul><h4 id="进一步看看Decoder"><a href="#进一步看看Decoder" class="headerlink" title="进一步看看Decoder"></a>进一步看看Decoder</h4><p><strong>teacher forcing</strong></p><p>一般RNN运行的两种mode：(1). Free-running mode；(2). Teacher-Forcing mode[22]。前者就是正常的RNN运行方式：上一个state的输出就做为下一个state的输入，这样做时有风险的，因为在RNN训练的早期，靠前的state中如果出现了极差的结果，那么后面的全部state都会受牵连，以至于最终结果非常不好也很难溯源到发生错误的源头，而后者Teacher-Forcing mode的做法就是，每次不使用上一个state的输出作为下一个state的输入，而是直接使用ground truth的对应上一项作为下一个state的输入。</p><p>Encoder 是比较简单的，而Decoder相对比较棘手。</p><ol><li>Teacher forcing:-Decoder逐字地生成句子，同时从语料库中提供真实目标句子的单词，延迟一个时间步长（见下图）</li><li>给定相邻句子的上下文z（i）和当前位置之前出现的单词序列，预测是在该位置可能出现的单词的概率分布<br><img src="decoder.png" alt="png"></li></ol><p>训练中不仅由z（i）上下文引导，还由句子中的实际单词引导。</p><p><strong>为什么要使用 100 % teacher forcing。</strong></p><p>这由两个可能的原因：</p><p><strong>Naive Explanation</strong>：因为我们后面最终需要的不是Decoder而是Encoder所以我们不需要减少teacher forcing。</p><p><strong>Better Explanation</strong> ：teacher forcing 不是为了产生单词。仅仅是为了提供真实的单词来促进更好的单词的预测而存在。也就是说减少teacher forcing 会降低准确度。</p><ul><li>遇到的问题：测试数据中间有没有登录的词汇，解决办法：采用先word2vec 来map 相关的词。 </li></ul><p>  =====================================================================</p><p>  <strong> 思考 </strong><br>如果解码器 利用 teacher-forcing 那么用cnn的滑动窗口会不会更好</p><p>  <strong> 解码器实际学到了什么？</strong></p><p>  <strong>TL; DR</strong>：解码器学习从给定邻近句子的句子中填充缺失的单词。</p><p>  两个解码器主要学习两件事。首先是语法。例如，知道“接近”后面没有“到”。学习语法有助于解码器避免在语义上相似的句子中出现语法错误。第二，在位置<strong>p</strong>处的单词上的分布给出i）相邻句子的上下文<strong>z（i）</strong>和ii）在位置<strong>p</strong>（0-索引）<em>之前</em>出现的单词<strong>x（i）[0：p]</strong>。</p><p>  <strong>编码器学到了什么？</strong></p><p>  编码器学习在句子中提取和打包信息，帮助解码器更好地预测前/下句子的单词。</p><p>  这些信息确实捕获了句子的一些语义，如在语义相似性，情感分类等几个下游NLP任务中的令人钦佩的准确性</p><p>  参考资料：</p><p>  Paper：[Skip-Thought Vectors]</p><p>  blog:<a href="https://medium.com/@sanyamagarwal/my-thoughts-on-skip-thoughts-a3e773605efa" target="_blank" rel="noopener">My thoughts on Skip-Thoughts</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Skip-Thought-Vectors&quot;&gt;&lt;a href=&quot;#Skip-Thought-Vectors&quot; class=&quot;headerlink&quot; title=&quot;Skip-Thought Vectors&quot;&gt;&lt;/a&gt;Skip-Thought Vectors&lt;/h3&gt;&lt;
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/categories/paper/"/>
    
    
  </entry>
  
  <entry>
    <title>hands-on svm课后作业</title>
    <link href="http://yoursite.com/2019/08/13/SVM/"/>
    <id>http://yoursite.com/2019/08/13/SVM/</id>
    <published>2019-08-13T01:57:15.000Z</published>
    <updated>2019-08-18T07:47:59.705Z</updated>
    
    <content type="html"><![CDATA[<h3 id="hands-on-svm课后作业"><a href="#hands-on-svm课后作业" class="headerlink" title="hands-on svm课后作业"></a>hands-on svm课后作业</h3><h4 id="train-a-LinearSVC-on-a-linearly-separable-dataset-Then-train-an-SVC-and-a-SGDClassifier-on-the-same-dataset-See-if-you-can-get-them-to-produce-roughly-the-same-mode"><a href="#train-a-LinearSVC-on-a-linearly-separable-dataset-Then-train-an-SVC-and-a-SGDClassifier-on-the-same-dataset-See-if-you-can-get-them-to-produce-roughly-the-same-mode" class="headerlink" title="train a LinearSVC on a linearly separable dataset. Then train an SVC and a SGDClassifier on the same dataset. See if you can get them to produce roughly the same mode"></a>train a LinearSVC on a linearly separable dataset. Then train an SVC and a SGDClassifier on the same dataset. See if you can get them to produce roughly the same mode</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line">iris = datasets.load_iris()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X = iris[<span class="string">"data"</span>][:, (<span class="number">2</span>, <span class="number">3</span>)] <span class="comment">#X.shape (150, 2)</span></span><br><span class="line">y = iris[<span class="string">"target"</span>] <span class="comment">#y.shape (150,)</span></span><br><span class="line">setosa_or_versicolor = (y == <span class="number">0</span>) | (y == <span class="number">1</span>)</span><br><span class="line">X = X[setosa_or_versicolor] <span class="comment">#100, 2)</span></span><br><span class="line">y = y[setosa_or_versicolor]</span><br></pre></td></tr></table></figure><ul><li>using SVC（kernel = “linear”) is much slower than LinearSVC</li><li>SGDClassifier(loss = “hinge”) this aplies regular SGD to train alinear SVM classifier<br>_tip: The Linear SVC class regularizes the bias term, so you should center the trainset fiest by subtracting its mean. In sklearn，This is automatic if you scale the data using the StandarScaler</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC, LinearSVC</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">C = <span class="number">5</span></span><br><span class="line">alpha = <span class="number">1</span> / (C * len(X))</span><br><span class="line"></span><br><span class="line">lin_clf = LinearSVC(loss=<span class="string">"hinge"</span>, C=C, random_state=<span class="number">42</span>)</span><br><span class="line">svm_clf = SVC(kernel=<span class="string">"linear"</span>, C=C)</span><br><span class="line">sgd_clf = SGDClassifier(loss=<span class="string">"hinge"</span>, learning_rate=<span class="string">"constant"</span>, eta0=<span class="number">0.001</span>, alpha=alpha,</span><br><span class="line">                        max_iter=<span class="number">100000</span>, tol=-np.infty, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_scaled = scaler.fit_transform(X)</span><br><span class="line"></span><br><span class="line">lin_clf.fit(X_scaled,y)</span><br><span class="line">svm_clf.fit(X_scaled,y)</span><br><span class="line">sgd_clf.fit(X_scaled,y)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"LinearSVC:                   "</span>, lin_clf.intercept_, lin_clf.coef_)</span><br><span class="line">print(<span class="string">"SVC:                         "</span>, svm_clf.intercept_, svm_clf.coef_)</span><br><span class="line">print(<span class="string">"SGDClassifier(alpha=&#123;:.5f&#125;):"</span>.format(sgd_clf.alpha), sgd_clf.intercept_, sgd_clf.coef_)</span><br></pre></td></tr></table></figure><pre><code>LinearSVC:                    [0.28474027] [[1.0536456  1.09903032]]SVC:                          [0.31896852] [[1.1203284  1.02625193]]SGDClassifier(alpha=0.00200): [0.319] [[1.12072936 1.02666842]]</code></pre><ul><li>得到参数了 画出图来看看（线性模型中 intercept θ0 coef  θ1，  θ2）<br>又两个参数 ， 同时除以 θ2 得到一个一维 ： y = wx + b 的形式</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># Compute the slope and bias of each decision boundary</span></span><br><span class="line">w1 = -lin_clf.coef_[<span class="number">0</span>, <span class="number">0</span>]/lin_clf.coef_[<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">b1 = -lin_clf.intercept_[<span class="number">0</span>]/lin_clf.coef_[<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">w2 = -svm_clf.coef_[<span class="number">0</span>, <span class="number">0</span>]/svm_clf.coef_[<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">b2 = -svm_clf.intercept_[<span class="number">0</span>]/svm_clf.coef_[<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">w3 = -sgd_clf.coef_[<span class="number">0</span>, <span class="number">0</span>]/sgd_clf.coef_[<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">b3 = -sgd_clf.intercept_[<span class="number">0</span>]/sgd_clf.coef_[<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Transform the decision boundary lines back to the original scale</span></span><br><span class="line">line1 = scaler.inverse_transform([[<span class="number">-10</span>, <span class="number">-10</span> * w1 + b1], [<span class="number">10</span>, <span class="number">10</span> * w1 + b1]])</span><br><span class="line">line2 = scaler.inverse_transform([[<span class="number">-10</span>, <span class="number">-10</span> * w2 + b2], [<span class="number">10</span>, <span class="number">10</span> * w2 + b2]])</span><br><span class="line">line3 = scaler.inverse_transform([[<span class="number">-10</span>, <span class="number">-10</span> * w3 + b3], [<span class="number">10</span>, <span class="number">10</span> * w3 + b3]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot all three decision boundaries</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">4</span>))</span><br><span class="line">plt.plot(line1[:, <span class="number">0</span>], line1[:, <span class="number">1</span>], <span class="string">"g:"</span>, label=<span class="string">"LinearSVC"</span>)</span><br><span class="line">plt.plot(line2[:, <span class="number">0</span>], line2[:, <span class="number">1</span>], <span class="string">"b--"</span>, linewidth=<span class="number">2</span>, label=<span class="string">"SVC"</span>)</span><br><span class="line">plt.plot(line3[:, <span class="number">0</span>], line3[:, <span class="number">1</span>], <span class="string">"r-"</span>, label=<span class="string">"SGDClassifier"</span>)</span><br><span class="line">plt.plot(X[:, <span class="number">0</span>][y==<span class="number">1</span>], X[:, <span class="number">1</span>][y==<span class="number">1</span>], <span class="string">"bs"</span>) <span class="comment"># label="Iris-Versicolor"</span></span><br><span class="line">plt.plot(X[:, <span class="number">0</span>][y==<span class="number">0</span>], X[:, <span class="number">1</span>][y==<span class="number">0</span>], <span class="string">"yo"</span>) <span class="comment"># label="Iris-Setosa"</span></span><br><span class="line">plt.xlabel(<span class="string">"Petal length"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Petal width"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.legend(loc=<span class="string">"upper center"</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.axis([<span class="number">0</span>, <span class="number">5.5</span>, <span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_7_0.png" alt="png"></p><h4 id="Train-an-SVM-classifier-on-the-MNIST-dataset-Since-SVM-classifiers-are-binaryclassifiers-you-will-need-to-use-one-versus-all-to-classify-all-10-digits-You-may-want-to-tune-the-hyperparameters-using-small-validation-sets-to-speed-up-the-pro‐cess-What-accuracy-can-you-reach"><a href="#Train-an-SVM-classifier-on-the-MNIST-dataset-Since-SVM-classifiers-are-binaryclassifiers-you-will-need-to-use-one-versus-all-to-classify-all-10-digits-You-may-want-to-tune-the-hyperparameters-using-small-validation-sets-to-speed-up-the-pro‐cess-What-accuracy-can-you-reach" class="headerlink" title="Train  an  SVM  classifier  on  the  MNIST  dataset.  Since  SVM  classifiers  are  binaryclassifiers,  you  will  need  to  use  one-versus-all  to  classify  all  10  digits.  You  may  want to tune the hyperparameters using small validation sets to speed up the pro‐cess. What accuracy can you reach"></a>Train  an  SVM  classifier  on  the  MNIST  dataset.  Since  SVM  classifiers  are  binaryclassifiers,  you  will  need  to  use  one-versus-all  to  classify  all  10  digits.  You  may  want to tune the hyperparameters using small validation sets to speed up the pro‐cess. What accuracy can you reach</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>) <span class="comment">## warning</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_mldata</span><br><span class="line">mnist = fetch_mldata(<span class="string">'MNIST original'</span>,data_home=<span class="string">'./datasets/'</span>)</span><br><span class="line">mnist</span><br></pre></td></tr></table></figure><pre><code>{&#39;DESCR&#39;: &#39;mldata.org dataset: mnist-original&#39;, &#39;COL_NAMES&#39;: [&#39;label&#39;, &#39;data&#39;], &#39;target&#39;: array([0., 0., 0., ..., 9., 9., 9.]), &#39;data&#39;: array([[0, 0, 0, ..., 0, 0, 0],        [0, 0, 0, ..., 0, 0, 0],        [0, 0, 0, ..., 0, 0, 0],        ...,        [0, 0, 0, ..., 0, 0, 0],        [0, 0, 0, ..., 0, 0, 0],        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)}</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X, y = mnist[<span class="string">"data"</span>], mnist[<span class="string">"target"</span>]</span><br><span class="line">X_train, X_test, y_train, y_test = X[:<span class="number">60000</span>], X[<span class="number">60000</span>:], y[:<span class="number">60000</span>], y[<span class="number">60000</span>:] <span class="comment">#最简单的方式</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">shuffle_index = np.random.permutation(<span class="number">60000</span>) <span class="comment">#随机取序列， 也就是洗牌</span></span><br><span class="line">X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lin_clf = LinearSVC(random_state=<span class="number">42</span>)</span><br><span class="line">lin_clf.fit(X_train, y_train)</span><br></pre></td></tr></table></figure><pre><code>LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,     intercept_scaling=1, loss=&#39;squared_hinge&#39;, max_iter=1000,     multi_class=&#39;ovr&#39;, penalty=&#39;l2&#39;, random_state=42, tol=0.0001,     verbose=0)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">y_pred = lin_clf.predict(X_train)</span><br><span class="line">accuracy_score(y_train, y_pred)</span><br></pre></td></tr></table></figure><pre><code>0.8747</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train_scaled = scaler.fit_transform(X_train.astype(np.float32))</span><br><span class="line">X_test_scaled = scaler.transform(X_test.astype(np.float32))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lin_clf = LinearSVC(random_state=<span class="number">42</span>)</span><br><span class="line">lin_clf.fit(X_train_scaled, y_train)</span><br></pre></td></tr></table></figure><pre><code>LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,     intercept_scaling=1, loss=&#39;squared_hinge&#39;, max_iter=1000,     multi_class=&#39;ovr&#39;, penalty=&#39;l2&#39;, random_state=42, tol=0.0001,     verbose=0)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred = lin_clf.predict(X_train_scaled)</span><br><span class="line">accuracy_score(y_train, y_pred)</span><br></pre></td></tr></table></figure><pre><code>0.9199</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">svm_clf = SVC(decision_function_shape=<span class="string">"ovr"</span>, gamma=<span class="string">"auto"</span>)</span><br><span class="line">svm_clf.fit(X_train_scaled[:<span class="number">6000</span>], y_train[:<span class="number">6000</span>])</span><br></pre></td></tr></table></figure><pre><code>SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,  decision_function_shape=&#39;ovr&#39;, degree=3, gamma=&#39;auto&#39;, kernel=&#39;rbf&#39;,  max_iter=-1, probability=False, random_state=None, shrinking=True,  tol=0.001, verbose=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred = svm_clf.predict(X_train_scaled[:<span class="number">6000</span>])</span><br><span class="line">accuracy_score( y_train[:<span class="number">6000</span>], y_pred)</span><br></pre></td></tr></table></figure><pre><code>0.9775</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> RandomizedSearchCV</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> reciprocal, uniform</span><br><span class="line">param_distributions = &#123;<span class="string">"gamma"</span>: reciprocal(<span class="number">0.001</span>, <span class="number">0.1</span>), <span class="string">"C"</span>: uniform(<span class="number">1</span>,<span class="number">10</span>)&#125;</span><br><span class="line">rnd_search_cv = RandomizedSearchCV(svm_clf, param_distributions, n_iter=<span class="number">5</span>, verbose=<span class="number">2</span>, cv=<span class="number">3</span>)</span><br><span class="line">rnd_search_cv.fit(X_train_scaled[:<span class="number">500</span>], y_train[:<span class="number">500</span>])</span><br></pre></td></tr></table></figure><pre><code>Fitting 3 folds for each of 5 candidates, totalling 15 fits[CV] C=6.249402615871811, gamma=0.07077378550552337 ..................[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.[CV] ... C=6.249402615871811, gamma=0.07077378550552337, total=   0.1s[CV] C=6.249402615871811, gamma=0.07077378550552337 ..................[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s[CV] ... C=6.249402615871811, gamma=0.07077378550552337, total=   0.1s[CV] C=6.249402615871811, gamma=0.07077378550552337 ..................[CV] ... C=6.249402615871811, gamma=0.07077378550552337, total=   0.1s[CV] C=1.8908728532899979, gamma=0.05548178308647815 .................[CV] .. C=1.8908728532899979, gamma=0.05548178308647815, total=   0.1s[CV] C=1.8908728532899979, gamma=0.05548178308647815 .................[CV] .. C=1.8908728532899979, gamma=0.05548178308647815, total=   0.1s[CV] C=1.8908728532899979, gamma=0.05548178308647815 .................[CV] .. C=1.8908728532899979, gamma=0.05548178308647815, total=   0.1s[CV] C=6.575575197236928, gamma=0.010917851017824925 .................[CV] .. C=6.575575197236928, gamma=0.010917851017824925, total=   0.1s[CV] C=6.575575197236928, gamma=0.010917851017824925 .................[CV] .. C=6.575575197236928, gamma=0.010917851017824925, total=   0.1s[CV] C=6.575575197236928, gamma=0.010917851017824925 .................[CV] .. C=6.575575197236928, gamma=0.010917851017824925, total=   0.1s[CV] C=8.103984118328173, gamma=0.0010976969181254448 ................[CV] . C=8.103984118328173, gamma=0.0010976969181254448, total=   0.1s[CV] C=8.103984118328173, gamma=0.0010976969181254448 ................[CV] . C=8.103984118328173, gamma=0.0010976969181254448, total=   0.1s[CV] C=8.103984118328173, gamma=0.0010976969181254448 ................[CV] . C=8.103984118328173, gamma=0.0010976969181254448, total=   0.1s[CV] C=3.8772829451317716, gamma=0.002522772748672047 ................[CV] . C=3.8772829451317716, gamma=0.002522772748672047, total=   0.1s[CV] C=3.8772829451317716, gamma=0.002522772748672047 ................[CV] . C=3.8772829451317716, gamma=0.002522772748672047, total=   0.1s[CV] C=3.8772829451317716, gamma=0.002522772748672047 ................[CV] . C=3.8772829451317716, gamma=0.002522772748672047, total=   0.1s[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    4.2s finishedRandomizedSearchCV(cv=3, error_score=&#39;raise-deprecating&#39;,          estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,  decision_function_shape=&#39;ovr&#39;, degree=3, gamma=&#39;auto&#39;, kernel=&#39;rbf&#39;,  max_iter=-1, probability=False, random_state=None, shrinking=True,  tol=0.001, verbose=False),          fit_params=None, iid=&#39;warn&#39;, n_iter=5, n_jobs=None,          param_distributions={&#39;gamma&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000002A3E9698CC0&gt;, &#39;C&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000002A3EAA16390&gt;},          pre_dispatch=&#39;2*n_jobs&#39;, random_state=None, refit=True,          return_train_score=&#39;warn&#39;, scoring=None, verbose=2)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rnd_search_cv.best_params_</span><br></pre></td></tr></table></figure><pre><code>{&#39;C&#39;: 8.103984118328173, &#39;gamma&#39;: 0.0010976969181254448}</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rnd_search_cv.best_score_</span><br></pre></td></tr></table></figure><pre><code>0.802</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rnd_search_cv.best_estimator_.fit(X_train_scaled[:<span class="number">6000</span>], y_train[:<span class="number">6000</span>])</span><br></pre></td></tr></table></figure><pre><code>SVC(C=8.103984118328173, cache_size=200, class_weight=None, coef0=0.0,  decision_function_shape=&#39;ovr&#39;, degree=3, gamma=0.0010976969181254448,  kernel=&#39;rbf&#39;, max_iter=-1, probability=False, random_state=None,  shrinking=True, tol=0.001, verbose=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred = rnd_search_cv.best_estimator_.predict(X_train_scaled[:<span class="number">6000</span>])</span><br><span class="line">accuracy_score(y_train[:<span class="number">6000</span>], y_pred)</span><br></pre></td></tr></table></figure><pre><code>0.9991666666666666</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred = rnd_search_cv.best_estimator_.predict(X_test_scaled)</span><br><span class="line">accuracy_score(y_test, y_pred)</span><br></pre></td></tr></table></figure><pre><code>0.9404</code></pre><h4 id="Train-an-SVM-regressor-on-the-California-housing-dataset"><a href="#Train-an-SVM-regressor-on-the-California-housing-dataset" class="headerlink" title="Train an SVM regressor on the California housing dataset"></a>Train an SVM regressor on the California housing dataset</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_california_housing</span><br><span class="line">housing = fetch_california_housing()</span><br><span class="line">X = housing[<span class="string">"data"</span>]</span><br><span class="line">y = housing[<span class="string">"target"</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test,y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">42</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing  <span class="keyword">import</span> StandardScaler</span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train_scaled = scaler.fit_transform(X_train)</span><br><span class="line">X_test_scaled = scaler.transform(X_test)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVR</span><br><span class="line">lin_svr = LinearSVR()</span><br><span class="line">lin_svr.fit(X_train_scaled, y_train)</span><br></pre></td></tr></table></figure><pre><code>LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,     intercept_scaling=1.0, loss=&#39;epsilon_insensitive&#39;, max_iter=1000,     random_state=None, tol=0.0001, verbose=0)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># from sklearn.metrics import accuracy_score </span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line">y_pred = lin_svr.predict(X_train_scaled)</span><br><span class="line">mse = mean_squared_error(y_train, y_pred)</span><br><span class="line">mse</span><br></pre></td></tr></table></figure><pre><code>0.9541764911842403</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVR</span><br><span class="line">param_distributions = &#123;<span class="string">"gamma"</span>: reciprocal(<span class="number">0.001</span>, <span class="number">0.1</span>), <span class="string">"C"</span>: uniform(<span class="number">1</span>, <span class="number">10</span>)&#125;</span><br><span class="line">rnd_search_cv = RandomizedSearchCV(SVR(), param_distributions, n_iter=<span class="number">10</span>, verbose=<span class="number">2</span>, cv=<span class="number">3</span>, random_state=<span class="number">42</span>)</span><br><span class="line">rnd_search_cv.fit(X_train_scaled, y_train)</span><br></pre></td></tr></table></figure><pre><code>Fitting 3 folds for each of 10 candidates, totalling 30 fits[CV] C=4.745401188473625, gamma=0.07969454818643928 ..................[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.[CV] ... C=4.745401188473625, gamma=0.07969454818643928, total=   5.9s[CV] C=4.745401188473625, gamma=0.07969454818643928 ..................[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.7s remaining:    0.0s[CV] ... C=4.745401188473625, gamma=0.07969454818643928, total=   5.6s[CV] C=4.745401188473625, gamma=0.07969454818643928 ..................[CV] ... C=4.745401188473625, gamma=0.07969454818643928, total=   5.8s[CV] C=8.31993941811405, gamma=0.015751320499779724 ..................[CV] ... C=8.31993941811405, gamma=0.015751320499779724, total=   5.5s[CV] C=8.31993941811405, gamma=0.015751320499779724 ..................[CV] ... C=8.31993941811405, gamma=0.015751320499779724, total=   5.4s[CV] C=8.31993941811405, gamma=0.015751320499779724 ..................[CV] ... C=8.31993941811405, gamma=0.015751320499779724, total=   6.1s[CV] C=2.560186404424365, gamma=0.002051110418843397 .................[CV] .. C=2.560186404424365, gamma=0.002051110418843397, total=   5.4s[CV] C=2.560186404424365, gamma=0.002051110418843397 .................[CV] .. C=2.560186404424365, gamma=0.002051110418843397, total=   5.1s[CV] C=2.560186404424365, gamma=0.002051110418843397 .................[CV] .. C=2.560186404424365, gamma=0.002051110418843397, total=   4.7s[CV] C=1.5808361216819946, gamma=0.05399484409787431 .................[CV] .. C=1.5808361216819946, gamma=0.05399484409787431, total=   4.7s[CV] C=1.5808361216819946, gamma=0.05399484409787431 .................[CV] .. C=1.5808361216819946, gamma=0.05399484409787431, total=   4.8s[CV] C=1.5808361216819946, gamma=0.05399484409787431 .................[CV] .. C=1.5808361216819946, gamma=0.05399484409787431, total=   4.7s[CV] C=7.011150117432088, gamma=0.026070247583707663 .................[CV] .. C=7.011150117432088, gamma=0.026070247583707663, total=   5.8s[CV] C=7.011150117432088, gamma=0.026070247583707663 .................[CV] .. C=7.011150117432088, gamma=0.026070247583707663, total=   5.6s[CV] C=7.011150117432088, gamma=0.026070247583707663 .................[CV] .. C=7.011150117432088, gamma=0.026070247583707663, total=   5.8s[CV] C=1.2058449429580245, gamma=0.0870602087830485 ..................[CV] ... C=1.2058449429580245, gamma=0.0870602087830485, total=   5.0s[CV] C=1.2058449429580245, gamma=0.0870602087830485 ..................[CV] ... C=1.2058449429580245, gamma=0.0870602087830485, total=   5.3s[CV] C=1.2058449429580245, gamma=0.0870602087830485 ..................[CV] ... C=1.2058449429580245, gamma=0.0870602087830485, total=   4.9s[CV] C=9.324426408004218, gamma=0.0026587543983272693 ................[CV] . C=9.324426408004218, gamma=0.0026587543983272693, total=   5.2s[CV] C=9.324426408004218, gamma=0.0026587543983272693 ................[CV] . C=9.324426408004218, gamma=0.0026587543983272693, total=   4.9s[CV] C=9.324426408004218, gamma=0.0026587543983272693 ................[CV] . C=9.324426408004218, gamma=0.0026587543983272693, total=   4.7s[CV] C=2.818249672071006, gamma=0.0023270677083837795 ................[CV] . C=2.818249672071006, gamma=0.0023270677083837795, total=   4.8s[CV] C=2.818249672071006, gamma=0.0023270677083837795 ................[CV] . C=2.818249672071006, gamma=0.0023270677083837795, total=   4.7s[CV] C=2.818249672071006, gamma=0.0023270677083837795 ................[CV] . C=2.818249672071006, gamma=0.0023270677083837795, total=   5.0s[CV] C=4.042422429595377, gamma=0.011207606211860567 .................[CV] .. C=4.042422429595377, gamma=0.011207606211860567, total=   5.1s[CV] C=4.042422429595377, gamma=0.011207606211860567 .................[CV] .. C=4.042422429595377, gamma=0.011207606211860567, total=   5.2s[CV] C=4.042422429595377, gamma=0.011207606211860567 .................[CV] .. C=4.042422429595377, gamma=0.011207606211860567, total=   5.5s[CV] C=5.319450186421157, gamma=0.003823475224675185 .................[CV] .. C=5.319450186421157, gamma=0.003823475224675185, total=   5.0s[CV] C=5.319450186421157, gamma=0.003823475224675185 .................[CV] .. C=5.319450186421157, gamma=0.003823475224675185, total=   4.7s[CV] C=5.319450186421157, gamma=0.003823475224675185 .................[CV] .. C=5.319450186421157, gamma=0.003823475224675185, total=   4.8s[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  3.7min finishedRandomizedSearchCV(cv=3, error_score=&#39;raise-deprecating&#39;,          estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,  gamma=&#39;auto_deprecated&#39;, kernel=&#39;rbf&#39;, max_iter=-1, shrinking=True,  tol=0.001, verbose=False),          fit_params=None, iid=&#39;warn&#39;, n_iter=10, n_jobs=None,          param_distributions={&#39;gamma&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000002A3EAB4C630&gt;, &#39;C&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000002A3EAB26E80&gt;},          pre_dispatch=&#39;2*n_jobs&#39;, random_state=42, refit=True,          return_train_score=&#39;warn&#39;, scoring=None, verbose=2)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rnd_search_cv.best_estimator_</span><br></pre></td></tr></table></figure><pre><code>SVR(C=4.745401188473625, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,  gamma=0.07969454818643928, kernel=&#39;rbf&#39;, max_iter=-1, shrinking=True,  tol=0.001, verbose=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y_pred = rnd_search_cv.best_estimator_.predict(X_train_scaled)</span><br><span class="line">mse = mean_squared_error(y_train, y_pred)</span><br><span class="line">mse</span><br></pre></td></tr></table></figure><pre><code>0.3280453999995986</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;hands-on-svm课后作业&quot;&gt;&lt;a href=&quot;#hands-on-svm课后作业&quot; class=&quot;headerlink&quot; title=&quot;hands-on svm课后作业&quot;&gt;&lt;/a&gt;hands-on svm课后作业&lt;/h3&gt;&lt;h4 id=&quot;train-a-L
      
    
    </summary>
    
    
      <category term="ml" scheme="http://yoursite.com/categories/ml/"/>
    
    
  </entry>
  
  <entry>
    <title>MNIST 手写识别任务</title>
    <link href="http://yoursite.com/2019/08/09/MNIST/"/>
    <id>http://yoursite.com/2019/08/09/MNIST/</id>
    <published>2019-08-09T06:57:15.000Z</published>
    <updated>2019-11-13T01:44:44.884Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hand-on-3"><a href="#Hand-on-3" class="headerlink" title="Hand - on 3"></a>Hand - on 3</h1><h2 id="分类任务"><a href="#分类任务" class="headerlink" title="分类任务"></a>分类任务</h2><h3 id="预处理数据"><a href="#预处理数据" class="headerlink" title="预处理数据"></a>预处理数据</h3><h4 id="获取数据集"><a href="#获取数据集" class="headerlink" title="获取数据集"></a>获取数据集</h4><p>使用 sklearn提供的MNIST数据集，进行分类练习。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>) <span class="comment">## 个人不想看到warning</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_mldata</span><br><span class="line">mnist = fetch_mldata(<span class="string">'MNIST original'</span>,data_home=<span class="string">'./datasets/'</span>)</span><br><span class="line">mnist</span><br></pre></td></tr></table></figure><pre><code>{&#39;DESCR&#39;: &#39;mldata.org dataset: mnist-original&#39;, &#39;COL_NAMES&#39;: [&#39;label&#39;, &#39;data&#39;], &#39;target&#39;: array([0., 0., 0., ..., 9., 9., 9.]), &#39;data&#39;: array([[0, 0, 0, ..., 0, 0, 0],        [0, 0, 0, ..., 0, 0, 0],        [0, 0, 0, ..., 0, 0, 0],        ...,        [0, 0, 0, ..., 0, 0, 0],        [0, 0, 0, ..., 0, 0, 0],        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)}</code></pre><p>可以清晰的看到数据的结构，我们看看数据的详细情况</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X, y = mnist[<span class="string">"data"</span>], mnist[<span class="string">"target"</span>]</span><br><span class="line">X.shape <span class="comment">#(70000, 784)</span></span><br><span class="line">y.shape <span class="comment">#(70000,)</span></span><br></pre></td></tr></table></figure><pre><code>(70000,)</code></pre><p>将数据画出来画图代码如下（各个参数在代码中有解释详细可以见api）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">some_digit = X[<span class="number">36000</span>] <span class="comment">#随便查看一个数据</span></span><br><span class="line">some_digit_image = some_digit.reshape(<span class="number">28</span>,<span class="number">28</span>) <span class="comment"># </span></span><br><span class="line">plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation = <span class="string">'nearest'</span>) </span><br><span class="line"><span class="comment"># X : array-like or PIL image</span></span><br><span class="line"><span class="comment"># interpolation 构成图的效果不同 默认也是nearest</span></span><br><span class="line">plt.axis(<span class="string">"off"</span>) <span class="comment"># 画图不要坐标轴</span></span><br><span class="line">plt.show() </span><br><span class="line">y[<span class="number">36000</span>] <span class="comment"># 5.0</span></span><br></pre></td></tr></table></figure><p><img src="output_8_0.png" alt="png"></p><pre><code>5.0</code></pre><h4 id="处理数据集，-将其分成测试集与训练集"><a href="#处理数据集，-将其分成测试集与训练集" class="headerlink" title="处理数据集， 将其分成测试集与训练集"></a>处理数据集， 将其分成测试集与训练集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = X[:<span class="number">60000</span>], X[<span class="number">60000</span>:], y[:<span class="number">60000</span>], y[<span class="number">60000</span>:] <span class="comment">#最简单的方式</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">shuffle_index = np.random.permutation(<span class="number">60000</span>) <span class="comment">#随机取序列， 也就是洗牌</span></span><br><span class="line">X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]</span><br></pre></td></tr></table></figure><p>多分类算法可以建立在二分类算法之上，后文可以看到。首先我们试试二分类算法以 5作为例子，所有数中就是（ == 5 或者 != 5 两种情况。所以我们把训练集测试集的标签修改为 0， 1两种情况</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y_train_5 = (y_train == <span class="number">5</span>)  <span class="comment"># True for all 5s, False for all other digits.</span></span><br><span class="line">y_test_5 = (y_test == <span class="number">5</span>)</span><br><span class="line">y_train_5 <span class="comment">#array([False, False, False, ..., False, False, False])</span></span><br></pre></td></tr></table></figure><pre><code>array([False, False, False, ..., False, False, False])</code></pre><h4 id="先简化训练一个二分类，使用SGDClassifier分类器"><a href="#先简化训练一个二分类，使用SGDClassifier分类器" class="headerlink" title="先简化训练一个二分类，使用SGDClassifier分类器"></a>先简化训练一个二分类，使用SGDClassifier分类器</h4><p>某个名人说过，管他三七二十一 线性模型直接先拿出来看看。sklearn中已经帮我们实现好了各种模型，现在我们不要关系模型的底层如何工作。先把他用起来。熟悉流程，具体的分类分类器可以见sklearn的api（）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier </span><br><span class="line">sgd_clf = SGDClassifier(random_state = <span class="number">42</span>) <span class="comment">#这里保证每次的数据都是统一的</span></span><br><span class="line">sgd_clf.fit(X_train, y_train_5)</span><br><span class="line">sgd_clf.predict([some_digit])</span><br></pre></td></tr></table></figure><pre><code>array([ True])</code></pre><h3 id="评估一个分类器的好坏"><a href="#评估一个分类器的好坏" class="headerlink" title="评估一个分类器的好坏"></a>评估一个分类器的好坏</h3><p>我们先用传统的交叉验证，可以看到精确度已经很不错了。但是着这往往是不够的。在这个二分类问题上，否的占了绝大多数那么精确的自然就很高。<br>所以我们需要其他的的评估方式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line">cross_val_score(sgd_clf, X_train, y_train_5, cv = <span class="number">3</span>, scoring = <span class="string">'accuracy'</span>)</span><br><span class="line"><span class="comment">#cv 多少折</span></span><br><span class="line"><span class="comment"># 采用精确度的衡量 array([0.9587 , 0.95975, 0.95095])</span></span><br></pre></td></tr></table></figure><pre><code>array([0.965  , 0.95905, 0.9616 ])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Never5Classifier</span><span class="params">(BaseEstimator)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y = None)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> np.zeros((len(X), <span class="number">1</span>), dtype = bool)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> clone</span><br><span class="line">skfolds = StratifiedKFold(n_splits = <span class="number">3</span>, random_state = <span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> skfolds.split(X_train, y_train_5):</span><br><span class="line">    clone_clf = clone(sgd_clf)</span><br><span class="line">    X_train_folds = X_train[train_index]</span><br><span class="line">    y_train_folds = y_train_5[train_index]</span><br><span class="line">    X_test_fold = X_train[test_index]</span><br><span class="line">    y_test_fold = y_train_5[test_index]</span><br><span class="line">    </span><br><span class="line">    clone_clf.fit(X_train_folds,y_train_folds)</span><br><span class="line">    y_pred = clone_clf.predict(X_test_fold)</span><br><span class="line">    n_correct = sum(y_pred == y_test_fold)</span><br><span class="line">    </span><br><span class="line">    print(n_correct / len(y_pred))</span><br></pre></td></tr></table></figure><pre><code>0.9650.959050.9616</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">never_5_clf = Never5Classifier()</span><br><span class="line">cross_val_score(never_5_clf, X_train, y_train_5, cv = <span class="number">3</span>, scoring = <span class="string">'accuracy'</span>)</span><br><span class="line"><span class="comment">#array([0.91155, 0.9091 , 0.9083 ])</span></span><br></pre></td></tr></table></figure><pre><code>array([0.909  , 0.90955, 0.9104 ])</code></pre><h4 id="使用其他评判方法-—-采用混淆矩阵来查看具体的预测情况"><a href="#使用其他评判方法-—-采用混淆矩阵来查看具体的预测情况" class="headerlink" title="使用其他评判方法 — 采用混淆矩阵来查看具体的预测情况"></a>使用其他评判方法 — 采用混淆矩阵来查看具体的预测情况</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_predict  <span class="comment"># not corss_val_scores</span></span><br><span class="line">y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv = <span class="number">3</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix </span><br><span class="line">confusion_matrix(y_train_5, y_train_pred)</span><br></pre></td></tr></table></figure><pre><code>array([[53735,   844],       [ 1372,  4049]], dtype=int64)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">confusion_matrix(y_train_5, y_train_5)</span><br></pre></td></tr></table></figure><pre><code>array([[54579,     0],       [    0,  5421]], dtype=int64)</code></pre><p>我们给出其他的评估方式</p><script type="math/tex; mode=display">正项预测正确的比上所有正确的：：\text { precision }=\frac{T P}{T P+F P}</script><script type="math/tex; mode=display">正项预测正确的的比上预测正确的：：\text { recall }=\frac{T P}{T P+F N}</script><p>sklearn同样帮我们实现了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score, recall_score</span><br><span class="line"></span><br><span class="line">precision_score(y_train_5, y_train_pred) <span class="comment">#0.7913295996681187</span></span><br><span class="line"></span><br><span class="line">recall_score(y_train_5, y_train_pred)<span class="comment">#0.7037446965504519</span></span><br></pre></td></tr></table></figure><pre><code>0.6935989669802619</code></pre><p>新的问题又出现了 precision 和 recall 之间有如何权衡呢我们可以用f1值</p><script type="math/tex; mode=display">F_{1}=\frac{2}{\frac{1}{\text { precision }}+\frac{1}{\text { recall }}}=2 \times \frac{\text { precision } \times \text { recall }}{\text { precision }+\text { recall }}=\frac{T P}{T P+\frac{F N+F P}{2}}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line">f1_score(y_train_5, y_train_pred) <span class="comment">#0.7449716852177309</span></span><br></pre></td></tr></table></figure><pre><code>0.7606716568885292</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_scores = sgd_clf.decision_function([some_digit])</span><br><span class="line">y_scores <span class="comment">#array([45727.05659041])</span></span><br></pre></td></tr></table></figure><pre><code>array([181985.89677917])</code></pre><p>在不同的情况下我们需求的precision 和 recall 大小不一，我们可以修改阈值来获取更准确的判断</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">threshold = <span class="number">20000</span> <span class="comment">#300000</span></span><br><span class="line">y_some_digit_pred = (y_scores &gt; threshold)</span><br><span class="line">y_some_digit_pred <span class="comment">#array([ True]) array([False])</span></span><br></pre></td></tr></table></figure><pre><code>array([ True])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv = <span class="number">3</span>, method = <span class="string">"decision_function"</span>)</span><br></pre></td></tr></table></figure><h4 id="画出-precision-与-recall-的曲线来进行决策"><a href="#画出-precision-与-recall-的曲线来进行决策" class="headerlink" title="画出 precision 与 recall 的曲线来进行决策"></a>画出 precision 与 recall 的曲线来进行决策</h4><p>由图中我们可以看到 precision 和 recall 是成负相关的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_curve</span><br><span class="line"></span><br><span class="line">precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_precision_recall_vs_threshold</span><span class="params">(precisions, recalls, thresholds)</span>:</span></span><br><span class="line">    plt.plot(thresholds, precisions[: <span class="number">-1</span>], <span class="string">"b--"</span>, label = <span class="string">"Precision"</span>, linewidth=<span class="number">2</span>) <span class="comment"># x, y,  "blue- -"</span></span><br><span class="line">    plt.plot(thresholds, recalls[: <span class="number">-1</span>], <span class="string">'g-'</span>, label = <span class="string">"Recall"</span>, linewidth=<span class="number">2</span>) </span><br><span class="line">    plt.xlabel(<span class="string">"Threshold"</span>)</span><br><span class="line">    plt.legend(loc = <span class="string">"upper left"</span>)</span><br><span class="line">    plt.ylim([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">    plt.xlim([<span class="number">-700000</span>, <span class="number">700000</span>])</span><br><span class="line">plot_precision_recall_vs_threshold(precisions, recalls, thresholds)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_34_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(recalls, precisions)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_35_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_train_pred_90 = (y_scores &gt; <span class="number">70000</span>)</span><br><span class="line">precision_score(y_train_5, y_train_pred_90)<span class="comment">#0.9194610778443114</span></span><br></pre></td></tr></table></figure><pre><code>0.9118254202300207</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">recall_score(y_train_5, y_train_pred_90) <span class="comment">#0.5665006456373363</span></span><br></pre></td></tr></table></figure><pre><code>0.5703744696550452</code></pre><h4 id="ROC-receiver-operating-characteristic-曲线图"><a href="#ROC-receiver-operating-characteristic-曲线图" class="headerlink" title="ROC  receiver  operating  characteristic  曲线图"></a>ROC  receiver  operating  characteristic  曲线图</h4><p>PR曲线会面临一个问题，当需要获得更高recall时，model需要输出更多的样本，precision可能会伴随出现下降/不变/升高，得到的曲线会出现浮动差异（出现锯齿），无法像ROC一样保证单调性。所以，对于正负样本分布大致均匀的问题，ROC曲线作为性能指标更好。<br> PR图和ROC图使用， 如果poitivecalss 少 或者 相较false negatives 更在意 false positives的时候 使用RP 反之就可以使用ROC图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line">fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_roc_curve</span><span class="params">(fpr, tpr, label = None)</span>:</span></span><br><span class="line">    plt.plot(fpr, tpr, linewidth = <span class="number">2</span>, label = label)</span><br><span class="line">    plt.plot([<span class="number">0</span>,<span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], <span class="string">'k--'</span>)</span><br><span class="line">    plt.axis([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">    plt.xlabel(<span class="string">'False Positive Rate'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'True Positive Rate'</span>)</span><br><span class="line">plot_roc_curve(fpr, tpr)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_39_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line">roc_auc_score(y_train_5, y_scores) <span class="comment">#0.9633748472261346 计算出面积</span></span><br></pre></td></tr></table></figure><pre><code>0.9594366171439257</code></pre><p>换个分类算法看看ROC的面积</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line">forest_clf = RandomForestClassifier(random_state = <span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv = <span class="number">3</span>,method = <span class="string">"predict_proba"</span>)</span><br><span class="line">y_scores_forest = y_probas_forest[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5,y_scores_forest)</span><br><span class="line"></span><br><span class="line">plt.plot(fpr, tpr, <span class="string">"b:"</span>, label = <span class="string">"SGD"</span>)</span><br><span class="line">plot_roc_curve(fpr_forest, tpr_forest, <span class="string">"Random Forest"</span>)</span><br><span class="line">plt.legend(loc = <span class="string">"bottom right"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_42_0.png" alt="png"></p><h3 id="多分类"><a href="#多分类" class="headerlink" title="多分类"></a>多分类</h3><p>如果是用二分类器 分类多分类问题 sklearn 自动转成 OvA </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sgd_clf.fit(X_train, y_train)</span><br><span class="line">sgd_clf.predict([some_digit]) <span class="comment">#array([5.]) some_digit = X[36000]</span></span><br></pre></td></tr></table></figure><pre><code>array([5.])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">some_digit_scores = sgd_clf.decision_function([some_digit])</span><br><span class="line">some_digit_scores</span><br></pre></td></tr></table></figure><pre><code>array([[-155608.02760533, -555690.96286451, -356978.92322184,        -175413.31640276, -447476.21501408,  181985.89677917,        -635600.35487992, -405225.45597096, -721820.14291054,        -747332.14490551]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">np.argmax(some_digit_scores) <span class="comment"># 5</span></span><br><span class="line">sgd_clf.classes_ <span class="comment">#array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])</span></span><br></pre></td></tr></table></figure><pre><code>array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])</code></pre><p>如果使用OVO形式</p><script type="math/tex; mode=display">classifiers的数量N \times(N-1) / 2</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.multiclass <span class="keyword">import</span> OneVsOneClassifier</span><br><span class="line">ovo_clf = OneVsOneClassifier(SGDClassifier(random_state = <span class="number">42</span>))</span><br><span class="line">ovo_clf.fit(X_train, y_train)</span><br><span class="line">ovo_clf.predict([some_digit])<span class="comment">#array([5.])</span></span><br><span class="line">len(ovo_clf.estimators_) <span class="comment"># 45</span></span><br></pre></td></tr></table></figure><pre><code>45</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">forest_clf.fit(X_train, y_train)</span><br><span class="line">forest_clf.predict([some_digit]) </span><br><span class="line">forest_clf.predict_proba([some_digit]) <span class="comment">#array([[0. , 0. , 0.1, 0.2, 0. , 0.6, 0. , 0.1, 0. , 0. ]])</span></span><br></pre></td></tr></table></figure><pre><code>array([[0.1, 0. , 0.1, 0. , 0. , 0.8, 0. , 0. , 0. , 0. ]])</code></pre><h4 id="交叉验证，-标准化"><a href="#交叉验证，-标准化" class="headerlink" title="交叉验证， 标准化"></a>交叉验证， 标准化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cross_val_score(sgd_clf, X_train, y_train, cv=<span class="number">3</span>, scoring=<span class="string">"accuracy"</span>) <span class="comment">#array([0.86842631, 0.87664383, 0.86888033])</span></span><br></pre></td></tr></table></figure><pre><code>array([0.86612677, 0.87064353, 0.85777867])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))</span><br><span class="line">cross_val_score(sgd_clf, X_train_scaled, y_train, cv = <span class="number">3</span>, scoring = <span class="string">"accuracy"</span>) <span class="comment"># array([0.91226755, 0.90839542, 0.90818623])</span></span><br><span class="line"><span class="comment"># 有所提升</span></span><br></pre></td></tr></table></figure><pre><code>array([0.90831834, 0.91114556, 0.9086863 ])</code></pre><h4 id="误差分析-进一步提高模型质量"><a href="#误差分析-进一步提高模型质量" class="headerlink" title="误差分析 进一步提高模型质量"></a>误差分析 进一步提高模型质量</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv = <span class="number">3</span>)</span><br><span class="line">conf_mx = confusion_matrix(y_train, y_train_pred)</span><br><span class="line">conf_mx</span><br></pre></td></tr></table></figure><pre><code>array([[5720,    3,   24,    8,   12,   56,   46,    8,   41,    5],       [   2, 6473,   48,   29,    6,   42,    8,   12,  112,   10],       [  54,   38, 5331,   97,   88,   25,  102,   52,  158,   13],       [  48,   38,  135, 5370,    3,  217,   39,   58,  131,   92],       [  26,   28,   36,    7, 5340,    8,   52,   29,   86,  230],       [  72,   38,   36,  196,   76, 4596,  105,   29,  176,   97],       [  38,   26,   39,    1,   40,   96, 5625,    6,   46,    1],       [  20,   27,   68,   30,   54,   10,    7, 5811,   17,  221],       [  49,  158,   80,  161,   15,  162,   57,   24, 5002,  143],       [  44,   36,   25,   96,  137,   29,    3,  207,   77, 5295]],      dtype=int64)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.matshow(conf_mx, cmap=plt.cm.gray)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_56_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">row_sums = conf_mx.sum(axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">norm_conf_mx = conf_mx / row_sums</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># print(row_sums)</span></span><br><span class="line"><span class="comment"># print(norm_conf_mx)</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.fill_diagonal(norm_conf_mx, <span class="number">0</span>)</span><br><span class="line">plt.matshow(norm_conf_mx, cmap=plt.cm.gray)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_59_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">y_train_large = (y_train &gt;= <span class="number">7</span>)</span><br><span class="line">y_train_odd = (y_train % <span class="number">2</span> == <span class="number">1</span>)</span><br><span class="line">y_multilabel = np.c_[y_train_large, y_train_odd]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">knn_clf = KNeighborsClassifier()</span><br><span class="line">knn_clf.fit(X_train, y_multilabel)</span><br></pre></td></tr></table></figure><pre><code>KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,           metric_params=None, n_jobs=None, n_neighbors=5, p=2,           weights=&#39;uniform&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">knn_clf.predict([some_digit])</span><br></pre></td></tr></table></figure><pre><code>array([[False,  True]])</code></pre><p>宏平均和微平均的对比</p><p>如果每个class的样本数量差不多,那么宏平均和微平均没有太大差异 <br><br>如果每个class的样本数量差异很大,而且你想:<br><br>更注重样本量多的class:使用微平均<br><br>更注重样本量少的class:使用宏平均<br><br>如果微平均大大低于宏平均,检查样本量多的class</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_train, cv = <span class="number">3</span>)</span><br><span class="line">f1_score(y_train, y_train_knn_pred, average=<span class="string">"macro"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">noise = np.random.randint(<span class="number">0</span>, <span class="number">100</span>, (len(X_train), <span class="number">784</span>))</span><br><span class="line">X_train_mod = X_train + noise</span><br><span class="line">noise = np.random.randint(<span class="number">0</span>, <span class="number">100</span>, (len(X_test), <span class="number">784</span>))</span><br><span class="line">X_test_mod = X_test + noise</span><br><span class="line">y_train_mod = X_train</span><br><span class="line">y_test_mod = X_test</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">some_index = <span class="number">5500</span></span><br><span class="line">plt.subplot(<span class="number">121</span>); plot_digit(X_test_mod[some_index])</span><br><span class="line">plt.subplot(<span class="number">122</span>); plot_digit(y_test_mod[some_index])</span><br><span class="line">save_fig(<span class="string">"noisy_digit_example_plot"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">knn_clf.fit(X_train_mod, y_train_mod)</span><br><span class="line">clean_digit = knn_clf.predict([X_test_mode[some_index]])</span><br><span class="line">plot_digit(clean_digit)</span><br><span class="line">save_fig(<span class="string">"cleaned_digit_example_plot"</span>)</span><br></pre></td></tr></table></figure><h2 id="课后练习"><a href="#课后练习" class="headerlink" title="课后练习"></a>课后练习</h2><h3 id="将KNeighborsClassifer-的-accuracy-提高的到-97-上"><a href="#将KNeighborsClassifer-的-accuracy-提高的到-97-上" class="headerlink" title="将KNeighborsClassifer 的  accuracy 提高的到  97%  上"></a>将KNeighborsClassifer 的  accuracy 提高的到  97%  上</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line">param_grid = [&#123;<span class="string">'weights'</span>: [<span class="string">"distance"</span>], <span class="string">'n_neighbors'</span>: [<span class="number">4</span>]&#125;]</span><br><span class="line"></span><br><span class="line">knn_clf = KNeighborsClassifier()</span><br><span class="line">grid_search = GridSearchCV(knn_clf, param_grid, cv = <span class="number">2</span>, verbose = <span class="number">3</span>, n_jobs = <span class="number">1</span>) <span class="comment">#verbose 提示信息 # n_jobs:用来设定CPU运行情况</span></span><br><span class="line"></span><br><span class="line">grid_search.fit(X_train, y_train)</span><br></pre></td></tr></table></figure><pre><code>Fitting 2 folds for each of 1 candidates, totalling 2 fits[CV] n_neighbors=4, weights=distance .................................[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grid_search.best_params_</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">y_pred = grid_search.predict(X_test)</span><br><span class="line">accuracy_score(y_test, y_pred)</span><br></pre></td></tr></table></figure><h3 id="训练集中加入图片上下左右移动后的图片，再看效果如何"><a href="#训练集中加入图片上下左右移动后的图片，再看效果如何" class="headerlink" title="训练集中加入图片上下左右移动后的图片，再看效果如何"></a>训练集中加入图片上下左右移动后的图片，再看效果如何</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.ndimage.interpolation <span class="keyword">import</span> shift</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shift_image</span><span class="params">(image, dx, dy)</span>:</span></span><br><span class="line">    image = image.reshape((<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">    shifted_image = shift(image,[dy, dx], cval = <span class="number">0</span>, mode = <span class="string">"constant"</span>)</span><br><span class="line">    <span class="keyword">return</span> shifted_image.reshape([<span class="number">-1</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">image = X_train[<span class="number">1000</span>]</span><br><span class="line">shifted_image_down =shift_image(image, <span class="number">0</span> , <span class="number">5</span>)</span><br><span class="line">plt.figure(figsize = (<span class="number">12</span>, <span class="number">3</span>))</span><br><span class="line">plt.subplot(<span class="number">131</span>)</span><br><span class="line">plt.title(<span class="string">"Original"</span>, fontsize = <span class="number">14</span>)</span><br><span class="line">plt.imshow(image.reshape(<span class="number">28</span>, <span class="number">28</span>), interpolation = <span class="string">"nearest"</span>, cmap = <span class="string">"Greys"</span>)</span><br><span class="line">plt.subplot(<span class="number">132</span>)</span><br><span class="line">plt.title(<span class="string">"Shifted down"</span>, fontsize = <span class="number">14</span>)</span><br><span class="line">plt.imshow(shifted_image_down.reshape(<span class="number">28</span>, <span class="number">28</span>), cmap = <span class="string">"Greys"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_77_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">X_train_augmented = [image <span class="keyword">for</span> image <span class="keyword">in</span> X_train]</span><br><span class="line">y_train_augmented = [label <span class="keyword">for</span> label <span class="keyword">in</span> y_train]</span><br><span class="line"><span class="comment">#上下左右移动一个点</span></span><br><span class="line"><span class="keyword">for</span> dx, dy <span class="keyword">in</span> ((<span class="number">1</span>, <span class="number">0</span>), (<span class="number">-1</span>, <span class="number">0</span>), (<span class="number">0</span>, <span class="number">1</span>), (<span class="number">0</span>, <span class="number">-1</span>)):</span><br><span class="line">    <span class="keyword">for</span> image, label <span class="keyword">in</span> zip(X_train, y_train):</span><br><span class="line">        X_train_augmented.append(shift_image(image, dx, dy))</span><br><span class="line">        y_train_augmented.append(label)</span><br><span class="line"></span><br><span class="line">X_train_augmented = np.array(X_train_augmented)</span><br><span class="line">y_train_augmented = np.array(y_train_augmented)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">shuffle_idx = np.random.permutation(len(X_train_augmented))</span><br><span class="line">X_train_augmented = X_train_augmented[shuffle_idx]</span><br><span class="line">y_train_augmented = y_train_augmented[shuffle_idx]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">knn_clf = KNeighborsClassifier(n_neighbors = <span class="number">4</span>,weights = <span class="string">'distance'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">knn_clf.fit(X_train_augmented, y_train_augmented)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred = knn_clf.predict(X_test)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">accuracy_score(y_test, y_pred)</span><br></pre></td></tr></table></figure><h3 id="kaggle-泰坦尼克"><a href="#kaggle-泰坦尼克" class="headerlink" title="kaggle 泰坦尼克"></a>kaggle 泰坦尼克</h3><h4 id="数据的读取，整理"><a href="#数据的读取，整理" class="headerlink" title="数据的读取，整理"></a>数据的读取，整理</h4><ul><li>同样首先需要获取数据源（），然后查看数据的分布情况</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">TITANIC_PATH = os.path.join(<span class="string">"datasets"</span>,<span class="string">"titanic"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_titanic_data</span><span class="params">(filename, titanic_path = TITANIC_PATH)</span>:</span></span><br><span class="line">    csv_path = os.path.join(titanic_path, filename)</span><br><span class="line">    <span class="keyword">return</span> pd.read_csv(csv_path)</span><br><span class="line"></span><br><span class="line">train_data = load_titanic_data(<span class="string">"train.csv"</span>)</span><br><span class="line">test_data = load_titanic_data(<span class="string">"test.csv"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_data = load_titanic_data(<span class="string">"train.csv"</span>)</span><br><span class="line">test_data = load_titanic_data(<span class="string">"test.csv"</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>PassengerId</th>      <th>Survived</th>      <th>Pclass</th>      <th>Name</th>      <th>Sex</th>      <th>Age</th>      <th>SibSp</th>      <th>Parch</th>      <th>Ticket</th>      <th>Fare</th>      <th>Cabin</th>      <th>Embarked</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>0</td>      <td>3</td>      <td>Braund, Mr. Owen Harris</td>      <td>male</td>      <td>22.0</td>      <td>1</td>      <td>0</td>      <td>A/5 21171</td>      <td>7.2500</td>      <td>NaN</td>      <td>S</td>    </tr>    <tr>      <th>1</th>      <td>2</td>      <td>1</td>      <td>1</td>      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>      <td>female</td>      <td>38.0</td>      <td>1</td>      <td>0</td>      <td>PC 17599</td>      <td>71.2833</td>      <td>C85</td>      <td>C</td>    </tr>    <tr>      <th>2</th>      <td>3</td>      <td>1</td>      <td>3</td>      <td>Heikkinen, Miss. Laina</td>      <td>female</td>      <td>26.0</td>      <td>0</td>      <td>0</td>      <td>STON/O2. 3101282</td>      <td>7.9250</td>      <td>NaN</td>      <td>S</td>    </tr>    <tr>      <th>3</th>      <td>4</td>      <td>1</td>      <td>1</td>      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>      <td>female</td>      <td>35.0</td>      <td>1</td>      <td>0</td>      <td>113803</td>      <td>53.1000</td>      <td>C123</td>      <td>S</td>    </tr>    <tr>      <th>4</th>      <td>5</td>      <td>0</td>      <td>3</td>      <td>Allen, Mr. William Henry</td>      <td>male</td>      <td>35.0</td>      <td>0</td>      <td>0</td>      <td>373450</td>      <td>8.0500</td>      <td>NaN</td>      <td>S</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 891 entries, 0 to 890Data columns (total 12 columns):PassengerId    891 non-null int64Survived       891 non-null int64Pclass         891 non-null int64Name           891 non-null objectSex            891 non-null objectAge            714 non-null float64SibSp          891 non-null int64Parch          891 non-null int64Ticket         891 non-null objectFare           891 non-null float64Cabin          204 non-null objectEmbarked       889 non-null objectdtypes: float64(2), int64(5), object(5)memory usage: 83.6+ KB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data.describe()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>PassengerId</th>      <th>Survived</th>      <th>Pclass</th>      <th>Age</th>      <th>SibSp</th>      <th>Parch</th>      <th>Fare</th>    </tr>  </thead>  <tbody>    <tr>      <th>count</th>      <td>891.000000</td>      <td>891.000000</td>      <td>891.000000</td>      <td>714.000000</td>      <td>891.000000</td>      <td>891.000000</td>      <td>891.000000</td>    </tr>    <tr>      <th>mean</th>      <td>446.000000</td>      <td>0.383838</td>      <td>2.308642</td>      <td>29.699118</td>      <td>0.523008</td>      <td>0.381594</td>      <td>32.204208</td>    </tr>    <tr>      <th>std</th>      <td>257.353842</td>      <td>0.486592</td>      <td>0.836071</td>      <td>14.526497</td>      <td>1.102743</td>      <td>0.806057</td>      <td>49.693429</td>    </tr>    <tr>      <th>min</th>      <td>1.000000</td>      <td>0.000000</td>      <td>1.000000</td>      <td>0.420000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>0.000000</td>    </tr>    <tr>      <th>25%</th>      <td>223.500000</td>      <td>0.000000</td>      <td>2.000000</td>      <td>20.125000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>7.910400</td>    </tr>    <tr>      <th>50%</th>      <td>446.000000</td>      <td>0.000000</td>      <td>3.000000</td>      <td>28.000000</td>      <td>0.000000</td>      <td>0.000000</td>      <td>14.454200</td>    </tr>    <tr>      <th>75%</th>      <td>668.500000</td>      <td>1.000000</td>      <td>3.000000</td>      <td>38.000000</td>      <td>1.000000</td>      <td>0.000000</td>      <td>31.000000</td>    </tr>    <tr>      <th>max</th>      <td>891.000000</td>      <td>1.000000</td>      <td>3.000000</td>      <td>80.000000</td>      <td>8.000000</td>      <td>6.000000</td>      <td>512.329200</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">train_data.hist(bins = <span class="number">100</span>, figsize = (<span class="number">20</span>, <span class="number">15</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="output_93_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">corr_matrix = train_data.corr()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">corr_matrix[<span class="string">"Survived"</span>].sort_values(ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><pre><code>Survived       1.000000Fare           0.257307Parch          0.081629PassengerId   -0.005007SibSp         -0.035322Age           -0.077221Pclass        -0.338481Name: Survived, dtype: float64</code></pre><p> 我们看到数据中有非数字等等，所以我们分开处理。使用pipeline 一次性完成数据的处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataFrameSelector</span><span class="params">(BaseEstimator, TransformerMixin)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, attribute_names)</span>:</span></span><br><span class="line">        self.attribute_names = attribute_names</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y = None)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X, y = None)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> X[self.attribute_names]</span><br><span class="line">    </span><br><span class="line"><span class="comment"># Inspired from stackoverflow.com/questions/25239958</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MostFrequentImputer</span><span class="params">(BaseEstimator, TransformerMixin)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        self.most_frequent_ = pd.Series([X[c].value_counts().index[<span class="number">0</span>] <span class="keyword">for</span> c <span class="keyword">in</span> X],</span><br><span class="line">                                        index=X.columns)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> X.fillna(self.most_frequent_)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler </span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder, OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> FeatureUnion</span><br><span class="line"></span><br><span class="line"><span class="comment"># train_num = train_data.drop(["PassengerId","Name","Sex","Ticket","Cabin", "Embarked"],  axis = 1)</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handle</span><span class="params">(num_atttribs, cat_tribs)</span>:</span></span><br><span class="line">    num_pipeline = Pipeline([</span><br><span class="line">         (<span class="string">'selector'</span>, DataFrameSelector(num_attribs)),</span><br><span class="line">         (<span class="string">'imputer'</span>, MostFrequentImputer()),</span><br><span class="line"><span class="comment">#     ('std_scaler', StandardScaler()),</span></span><br><span class="line">    ])</span><br><span class="line">    cat_pipeline = Pipeline([</span><br><span class="line">         (<span class="string">'seletor'</span>, DataFrameSelector(cat_tribs)),</span><br><span class="line">         (<span class="string">"imputer"</span>, MostFrequentImputer()),</span><br><span class="line">         (<span class="string">"cat_encoder"</span>, OneHotEncoder(sparse=<span class="literal">False</span>)),</span><br><span class="line">    ])</span><br><span class="line">    full_pipeline = FeatureUnion(transformer_list = [</span><br><span class="line">         (<span class="string">"num_pipeline"</span>, num_pipeline),</span><br><span class="line">         (<span class="string">"cat_pipeline"</span>, cat_pipeline),</span><br><span class="line">    ])</span><br><span class="line">    <span class="keyword">return</span> full_pipeline</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">num_attribs = [<span class="string">"Age"</span>, <span class="string">"SibSp"</span>, <span class="string">"Parch"</span>, <span class="string">"Fare"</span>]</span><br><span class="line">cat_attribs = [<span class="string">"Pclass"</span>,<span class="string">"Sex"</span>,<span class="string">"Embarked"</span>]</span><br><span class="line">full_pipeline = handle(num_attribs, cat_attribs)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_prepared = full_pipeline.fit_transform(train_data)</span><br><span class="line"></span><br><span class="line">X_test = full_pipeline.fit_transform(test_data) <span class="comment"># 测试集 也是需要处理的</span></span><br><span class="line">train_prepared</span><br></pre></td></tr></table></figure><pre><code>array([[22.,  1.,  0., ...,  0.,  0.,  1.],       [38.,  1.,  0., ...,  1.,  0.,  0.],       [26.,  0.,  0., ...,  0.,  0.,  1.],       ...,       [24.,  1.,  2., ...,  0.,  0.,  1.],       [26.,  0.,  0., ...,  1.,  0.,  0.],       [32.,  0.,  0., ...,  0.,  1.,  0.]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_train = train_data[<span class="string">"Survived"</span>]</span><br></pre></td></tr></table></figure><h4 id="小鹿乱撞"><a href="#小鹿乱撞" class="headerlink" title="小鹿乱撞"></a>小鹿乱撞</h4><h5 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line">lin_clf = SGDClassifier()</span><br><span class="line">lin_clf.fit(train_prepared, y_train)</span><br><span class="line">linear_scores = cross_val_score(lin_clf, train_prepared, y_train, cv=<span class="number">10</span>)</span><br><span class="line">print(<span class="string">"linear_model:"</span>, linear_scores.mean()) <span class="comment">#linear_model: 0.6868817387356714</span></span><br></pre></td></tr></table></figure><pre><code>linear_model: 0.6962870275791625</code></pre><h5 id="svm"><a href="#svm" class="headerlink" title="svm"></a>svm</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line">svm_clf = SVC(gamma = <span class="string">"auto"</span>)</span><br><span class="line">svm_clf.fit(train_prepared, y_train)</span><br><span class="line">svm_scores = cross_val_score(svm_clf, train_prepared, y_train, cv=<span class="number">10</span>)</span><br><span class="line">print(<span class="string">"svm:"</span>, svm_scores.mean()) <span class="comment">#svm: 0.7365250822835092</span></span><br></pre></td></tr></table></figure><pre><code>svm: 0.7386715469299737</code></pre><h5 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a><font color="red">随机森林</font></h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line">forest_clf = RandomForestClassifier(n_estimators = <span class="number">100</span>, random_state=<span class="number">42</span>)</span><br><span class="line">forest_scores = cross_val_score(forest_clf, train_prepared, y_train, cv=<span class="number">10</span>)</span><br><span class="line">forest_scores.mean()</span><br><span class="line">print(<span class="string">"ensemble:"</span>, forest_scores.mean()) <span class="comment">#ensemble: 0.8149526160481217</span></span><br></pre></td></tr></table></figure><pre><code>ensemble: 0.809334354783793</code></pre><h5 id="最近邻试试"><a href="#最近邻试试" class="headerlink" title="最近邻试试"></a>最近邻试试</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">knn_clf = KNeighborsClassifier(n_neighbors = <span class="number">4</span>,weights = <span class="string">'distance'</span>)</span><br><span class="line">knn_scores = cross_val_score(knn_clf, train_prepared, y_train, cv=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"neighbors:"</span>, knn_scores.mean()) <span class="comment">#neighbors: 0.7240517534899558</span></span><br></pre></td></tr></table></figure><pre><code>neighbors: 0.7229029054590852</code></pre><h4 id="继续优化-1-调参-2-年龄分层-3…"><a href="#继续优化-1-调参-2-年龄分层-3…" class="headerlink" title="继续优化 1.调参 2.年龄分层 3…."></a>继续优化 1.调参 2.年龄分层 3….</h4><h5 id="调参"><a href="#调参" class="headerlink" title="调参"></a>调参</h5><p>（0.8149526160481217 —— 0.8317563273181252)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="comment">#参数调好了我就只留下了 最优的参数</span></span><br><span class="line">param_grid = &#123; </span><br><span class="line">    <span class="string">'n_estimators'</span>: [<span class="number">100</span>],</span><br><span class="line">    <span class="string">'max_features'</span>: [<span class="string">'auto'</span>],</span><br><span class="line">    <span class="string">'min_samples_leaf'</span> :[<span class="number">2</span>],</span><br><span class="line">    <span class="string">'min_samples_split'</span>:[<span class="number">2</span>],</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">grid_search = GridSearchCV(forest_clf, param_grid, cv = <span class="number">5</span>, scoring = <span class="string">'neg_mean_squared_error'</span>)</span><br><span class="line">grid_search.fit(train_prepared, y_train)</span><br><span class="line">grid_search.best_params_ <span class="comment">#&#123;'max_features': 'auto', 'n_estimators': 50&#125;</span></span><br></pre></td></tr></table></figure><pre><code>{&#39;max_features&#39;: &#39;auto&#39;, &#39;min_samples_leaf&#39;: 2, &#39;min_samples_split&#39;: 2, &#39;n_estimators&#39;: 100}</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">forest_clf = RandomForestClassifier(n_estimators = <span class="number">100</span>,max_features = <span class="string">'auto'</span>, min_samples_leaf = <span class="number">2</span>, max_depth = <span class="number">20</span>,random_state=<span class="number">42</span>)</span><br><span class="line">forest_scores = cross_val_score(forest_clf, train_prepared, y_train, cv=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"ensemble:"</span>, forest_scores.mean()) <span class="comment">#ensemble: 0.8317563273181252</span></span><br><span class="line"></span><br><span class="line">forest_clf.fit(train_prepared, y_train)</span><br><span class="line">predictions = forest_clf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># test = pd.DataFrame(X_test)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># my_submission = pd.DataFrame(&#123;'PassengerId': test_data['PassengerId'],'Survived': predictions&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># my_submission.to_csv('./submission.csv', index=False)</span></span><br></pre></td></tr></table></figure><pre><code>ensemble: 0.8294716831233686</code></pre><h5 id="年龄分层"><a href="#年龄分层" class="headerlink" title="年龄分层"></a>年龄分层</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_data[<span class="string">"AgeBucket"</span>] = train_data[<span class="string">"Age"</span>] // <span class="number">15</span> * <span class="number">15</span></span><br><span class="line">train_data[[<span class="string">"AgeBucket"</span>, <span class="string">"Survived"</span>]].groupby([<span class="string">'AgeBucket'</span>]).mean()</span><br><span class="line">train = train_data.drop(<span class="string">'Age'</span>, axis = <span class="number">1</span>)</span><br><span class="line">train.info()</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;RangeIndex: 891 entries, 0 to 890Data columns (total 12 columns):PassengerId    891 non-null int64Survived       891 non-null int64Pclass         891 non-null int64Name           891 non-null objectSex            891 non-null objectSibSp          891 non-null int64Parch          891 non-null int64Ticket         891 non-null objectFare           891 non-null float64Cabin          204 non-null objectEmbarked       889 non-null objectAgeBucket      714 non-null float64dtypes: float64(2), int64(5), object(5)memory usage: 83.6+ KB</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">num_attribs = [<span class="string">"AgeBucket"</span>, <span class="string">"SibSp"</span>, <span class="string">"Parch"</span>, <span class="string">"Fare"</span>]</span><br><span class="line">cat_attribs = [<span class="string">"Pclass"</span>,<span class="string">"Sex"</span>,<span class="string">"Embarked"</span>]</span><br><span class="line">full_pipeline = handle(num_attribs, cat_attribs)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_prepared = full_pipeline.fit_transform(train)</span><br><span class="line">train_prepared</span><br></pre></td></tr></table></figure><pre><code>array([[15.,  1.,  0., ...,  0.,  0.,  1.],       [30.,  1.,  0., ...,  1.,  0.,  0.],       [15.,  0.,  0., ...,  0.,  0.,  1.],       ...,       [15.,  1.,  2., ...,  0.,  0.,  1.],       [15.,  0.,  0., ...,  1.,  0.,  0.],       [30.,  0.,  0., ...,  0.,  1.,  0.]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">forest_clf = RandomForestClassifier(n_estimators = <span class="number">100</span>,max_features = <span class="string">'auto'</span>, min_samples_leaf = <span class="number">2</span>, max_depth = <span class="number">20</span>,random_state=<span class="number">42</span>)</span><br><span class="line">forest_scores = cross_val_score(forest_clf, train_prepared, y_train, cv=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"ensemble:"</span>, forest_scores.mean()) <span class="comment">#  ensemble: 0.8294211780728634 反而还降低了</span></span><br></pre></td></tr></table></figure><pre><code>ensemble: 0.8272242083758938</code></pre><h5 id="属性融合"><a href="#属性融合" class="headerlink" title="属性融合"></a>属性融合</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">"RelativesOnboard"</span>] = train[<span class="string">"SibSp"</span>] + train[<span class="string">"Parch"</span>]</span><br><span class="line">train[[<span class="string">"RelativesOnboard"</span>, <span class="string">"Survived"</span>]].groupby([<span class="string">'RelativesOnboard'</span>]).mean()</span><br><span class="line"></span><br><span class="line">train_cb = train.drop([<span class="string">"SibSp"</span>,<span class="string">"Parch"</span>], axis = <span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">num_attribs = [<span class="string">"AgeBucket"</span>, <span class="string">"Fare"</span>] <span class="comment">#, "SibSp", "Parch",</span></span><br><span class="line">cat_attribs = [<span class="string">"Pclass"</span>,<span class="string">"Sex"</span>,<span class="string">"Embarked"</span>]</span><br><span class="line">full_pipeline = handle(num_attribs, cat_attribs)</span><br><span class="line"></span><br><span class="line">train_prepared = full_pipeline.fit_transform(train_cb)</span><br><span class="line">train_prepared</span><br></pre></td></tr></table></figure><pre><code>array([[15.    ,  7.25  ,  0.    , ...,  0.    ,  0.    ,  1.    ],       [30.    , 71.2833,  1.    , ...,  1.    ,  0.    ,  0.    ],       [15.    ,  7.925 ,  0.    , ...,  0.    ,  0.    ,  1.    ],       ...,       [15.    , 23.45  ,  0.    , ...,  0.    ,  0.    ,  1.    ],       [15.    , 30.    ,  1.    , ...,  1.    ,  0.    ,  0.    ],       [30.    ,  7.75  ,  0.    , ...,  0.    ,  1.    ,  0.    ]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">forest_clf = RandomForestClassifier(n_estimators = <span class="number">100</span>,max_features = <span class="string">'auto'</span>, min_samples_leaf = <span class="number">2</span>, max_depth = <span class="number">20</span>,random_state=<span class="number">42</span>)</span><br><span class="line">forest_scores = cross_val_score(forest_clf, train_prepared, y_train, cv=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"ensemble:"</span>, forest_scores.mean()) <span class="comment">#</span></span><br></pre></td></tr></table></figure><pre><code>ensemble: 0.8294211780728634</code></pre><ul><li>这机个方式不仅没有提升，反而还下降了。目前最高的得分就是以最优参数的随机森林分类算法</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Hand-on-3&quot;&gt;&lt;a href=&quot;#Hand-on-3&quot; class=&quot;headerlink&quot; title=&quot;Hand - on 3&quot;&gt;&lt;/a&gt;Hand - on 3&lt;/h1&gt;&lt;h2 id=&quot;分类任务&quot;&gt;&lt;a href=&quot;#分类任务&quot; class=&quot;head
      
    
    </summary>
    
    
      <category term="ml" scheme="http://yoursite.com/categories/ml/"/>
    
    
  </entry>
  
  <entry>
    <title>树的相关算法</title>
    <link href="http://yoursite.com/2019/08/09/%E6%A0%91%E7%9A%84%E7%9B%B8%E5%85%B3%20%EF%BC%88%E9%9A%BE%E5%BA%A6easy%EF%BC%89/"/>
    <id>http://yoursite.com/2019/08/09/树的相关 （难度easy）/</id>
    <published>2019-08-09T06:57:15.000Z</published>
    <updated>2019-08-23T13:41:44.651Z</updated>
    
    <content type="html"><![CDATA[<h3 id="树的相关-（难度easy）"><a href="#树的相关-（难度easy）" class="headerlink" title="树的相关 （难度easy）"></a>树的相关 （难度easy）</h3><h4 id="100-sameTree"><a href="#100-sameTree" class="headerlink" title="100. sameTree."></a><a href="https:// .com/problems/same-tree/" target="_blank" rel="noopener">100. sameTree</a>.</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">- Definition for a binary tree node.</span></span><br><span class="line"><span class="comment">- public class TreeNode &#123;</span></span><br><span class="line"><span class="comment">- int val;</span></span><br><span class="line"><span class="comment">- TreeNode left;</span></span><br><span class="line"><span class="comment">- TreeNode right;</span></span><br><span class="line"><span class="comment">- TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment">- &#125;</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isSameTree</span><span class="params">(TreeNode p, TreeNode q)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">if</span>(p == <span class="keyword">null</span> &amp;&amp; q == <span class="keyword">null</span>)</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">      <span class="keyword">if</span>(p == <span class="keyword">null</span> || q == <span class="keyword">null</span>)</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">      <span class="keyword">if</span>(p.val != q.val)</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">      <span class="keyword">boolean</span> t1 = isSameTree(p.left, q.left);</span><br><span class="line">      <span class="keyword">boolean</span> t2 = isSameTree(p.right, q.right);</span><br><span class="line">      <span class="keyword">if</span>(t1 == <span class="keyword">false</span> || t2 == <span class="keyword">false</span>)</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h4 id="101-Symmetric-Tree"><a href="#101-Symmetric-Tree" class="headerlink" title="101. Symmetric Tree"></a><a href="https:// .com/problems/symmetric-tree/" target="_blank" rel="noopener">101. Symmetric Tree</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isSymmetric</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">return</span> helper(root.left,root.right);</span><br><span class="line">     </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">helper</span><span class="params">(TreeNode root1, TreeNode root2)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root1==<span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> root2==<span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span>(root2==<span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> root1==<span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">return</span>        root1.val==root2.val&amp;&amp;helper(root1.left,root2.right)&amp;&amp;helper(root1.right,root2.left);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="104-Maximum-Depth-of-Binary-Tree"><a href="#104-Maximum-Depth-of-Binary-Tree" class="headerlink" title="104. Maximum Depth of Binary Tree"></a><a href="https:// .com/problems/maximum-depth-of-binary-tree/" target="_blank" rel="noopener">104. Maximum Depth of Binary Tree</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxDepth</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) &#123;<span class="keyword">return</span> <span class="number">0</span>;&#125;</span><br><span class="line">        <span class="keyword">return</span> Math.max(maxDepth(root.left), maxDepth(root.right)) + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="107-Binary-Tree-Level-Order-Traversal-II"><a href="#107-Binary-Tree-Level-Order-Traversal-II" class="headerlink" title="107. Binary Tree Level Order Traversal II"></a><a href="https:// .com/problems/binary-tree-level-order-traversal-ii/" target="_blank" rel="noopener">107. Binary Tree Level Order Traversal II</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    List&lt;List&lt;Integer&gt;&gt; res = <span class="keyword">new</span> ArrayList();</span><br><span class="line">    <span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; levelOrderBottom(TreeNode root) &#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span> res;</span><br><span class="line">        Queue&lt;TreeNode&gt; que = <span class="keyword">new</span> LinkedList();   </span><br><span class="line">        que.add(root);</span><br><span class="line">        <span class="keyword">while</span>(!que.isEmpty())&#123;</span><br><span class="line">            <span class="keyword">int</span> count = que.size();</span><br><span class="line">            List&lt;Integer&gt; list = <span class="keyword">new</span> ArrayList();</span><br><span class="line">            <span class="keyword">while</span>(count &gt; <span class="number">0</span>)&#123;</span><br><span class="line">                TreeNode node = que.peek();</span><br><span class="line">                que.poll();</span><br><span class="line">                list.add(node.val);</span><br><span class="line">                <span class="keyword">if</span>(node.left != <span class="keyword">null</span>) que.add(node.left);</span><br><span class="line">                <span class="keyword">if</span>(node.right != <span class="keyword">null</span>) que.add(node.right);</span><br><span class="line">                count--;</span><br><span class="line">            &#125;</span><br><span class="line">            res.add(list);</span><br><span class="line">        &#125; </span><br><span class="line">        Collections.reverse(res);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="108-Convert-Sorted-Array-to-Binary-Search-Tree"><a href="#108-Convert-Sorted-Array-to-Binary-Search-Tree" class="headerlink" title="108. Convert Sorted Array to Binary Search Tree"></a><a href="https:// .com/problems/convert-sorted-array-to-binary-search-tree/" target="_blank" rel="noopener">108. Convert Sorted Array to Binary Search Tree</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> TreeNode <span class="title">sortedArrayToBST</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> helper(nums,<span class="number">0</span>,nums.length-<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> TreeNode <span class="title">helper</span><span class="params">(<span class="keyword">int</span>[] arr,<span class="keyword">int</span> lo,<span class="keyword">int</span> hi)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span>(lo&gt;hi) &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">int</span> mid=(lo+hi)/<span class="number">2</span>;</span><br><span class="line">TreeNode node=<span class="keyword">new</span> TreeNode(arr[mid]);</span><br><span class="line"></span><br><span class="line">node.left=helper(arr, lo, mid-<span class="number">1</span>);</span><br><span class="line">node.right=helper(arr, mid+<span class="number">1</span>, hi);</span><br><span class="line">    <span class="keyword">return</span> node;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="110-Balanced-Binary-Tree"><a href="#110-Balanced-Binary-Tree" class="headerlink" title="110. Balanced Binary Tree"></a><a href="https:// .com/problems/balanced-binary-tree/" target="_blank" rel="noopener">110. Balanced Binary Tree</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isBalanced</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">     </span><br><span class="line">        <span class="keyword">int</span> lhigh = helper(root.left);</span><br><span class="line">        <span class="keyword">int</span> rhigh = helper(root.right);</span><br><span class="line">   </span><br><span class="line">        <span class="keyword">return</span> Math.abs(lhigh - rhigh) &lt;= <span class="number">1</span> &amp;&amp; isBalanced(root.left) &amp;&amp; isBalanced(root.right);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">helper</span><span class="params">(TreeNode node)</span></span>&#123;    </span><br><span class="line">        <span class="keyword">if</span>(node == <span class="keyword">null</span>)<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> Math.max(helper(node.left), helper(node.right)) + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="111-Minimum-Depth-of-Binary-Tree"><a href="#111-Minimum-Depth-of-Binary-Tree" class="headerlink" title="111. Minimum Depth of Binary Tree"></a><a href="https:// .com/problems/minimum-depth-of-binary-tree/" target="_blank" rel="noopener">111. Minimum Depth of Binary Tree</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">minDepth</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> left = minDepth(root.left);</span><br><span class="line">        <span class="keyword">int</span> right = minDepth(root.right);</span><br><span class="line">        <span class="keyword">return</span> (left == <span class="number">0</span> || right == <span class="number">0</span>) ? left + right + <span class="number">1</span>: Math.min(left,right) + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="112-Path-Sum"><a href="#112-Path-Sum" class="headerlink" title="112. Path Sum"></a><a href="https:// .com/problems/path-sum/" target="_blank" rel="noopener">112. Path Sum</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasPathSum</span><span class="params">(TreeNode root, <span class="keyword">int</span> sum)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">       <span class="keyword">if</span>(root.left == <span class="keyword">null</span> &amp;&amp; root.right == <span class="keyword">null</span> &amp;&amp; sum - root.val == <span class="number">0</span>) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">       <span class="keyword">return</span> hasPathSum(root.left, sum - root.val) || hasPathSum(root.right, sum - root.val);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="226-Invert-Binary-Tree"><a href="#226-Invert-Binary-Tree" class="headerlink" title="226. Invert Binary Tree"></a><a href="https:// .com/problems/invert-binary-tree/" target="_blank" rel="noopener">226. Invert Binary Tree</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> TreeNode <span class="title">invertTree</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        TreeNode left = invertTree(root.left);</span><br><span class="line">        TreeNode right = invertTree(root.right);</span><br><span class="line">        TreeNode temp = left;</span><br><span class="line">        root.left = right;</span><br><span class="line">        root.right = temp;</span><br><span class="line">        <span class="keyword">return</span> root;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="235-Lowest-Common-Ancestor-of-a-Binary-Search-Tree"><a href="#235-Lowest-Common-Ancestor-of-a-Binary-Search-Tree" class="headerlink" title="235. Lowest Common Ancestor of a Binary Search Tree"></a><a href="https:// .com/problems/lowest-common-ancestor-of-a-binary-search-tree/" target="_blank" rel="noopener">235. Lowest Common Ancestor of a Binary Search Tree</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> TreeNode <span class="title">lowestCommonAncestor</span><span class="params">(TreeNode root, TreeNode p, TreeNode q)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span>(root == p || root == q) <span class="keyword">return</span> root;</span><br><span class="line">        TreeNode left = lowestCommonAncestor(root.left, p, q);</span><br><span class="line">        TreeNode right = lowestCommonAncestor(root.right, p, q);</span><br><span class="line">        <span class="keyword">if</span>(left != <span class="keyword">null</span> &amp;&amp; right != <span class="keyword">null</span>) <span class="keyword">return</span> root;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(left != <span class="keyword">null</span>) <span class="keyword">return</span> left;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(right != <span class="keyword">null</span>) <span class="keyword">return</span> right;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="257-Binary-Tree-Paths"><a href="#257-Binary-Tree-Paths" class="headerlink" title="257. Binary Tree Paths"></a><a href="https:// .com/problems/binary-tree-paths/" target="_blank" rel="noopener">257. Binary Tree Paths</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;String&gt; <span class="title">binaryTreePaths</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        List&lt;String&gt; res = <span class="keyword">new</span> ArrayList();</span><br><span class="line">        <span class="keyword">if</span>(root != <span class="keyword">null</span>) helper(root, <span class="string">""</span> , res);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">helper</span><span class="params">(TreeNode root,String path, List&lt;String&gt; res)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root.left == <span class="keyword">null</span> &amp;&amp; root.right == <span class="keyword">null</span>) res.add(path + root.val);</span><br><span class="line">        <span class="keyword">if</span>(root.left != <span class="keyword">null</span>) helper(root.left, path + root. val + <span class="string">"-&gt;"</span> , res);</span><br><span class="line">        <span class="keyword">if</span>(root.right != <span class="keyword">null</span>) helper(root.right, path + root. val  +<span class="string">"-&gt;"</span>, res);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="404-Sum-of-Left-Leaves"><a href="#404-Sum-of-Left-Leaves" class="headerlink" title="404. Sum of Left Leaves"></a><a href="https:// .com/problems/sum-of-left-leaves/" target="_blank" rel="noopener">404. Sum of Left Leaves</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">// class Solution &#123;</span></span><br><span class="line"><span class="comment">//     public int sumOfLeftLeaves(TreeNode root) &#123;</span></span><br><span class="line"><span class="comment">//         int[] sum = new int[1];//定义</span></span><br><span class="line"><span class="comment">//         sum[0] = 0;</span></span><br><span class="line"><span class="comment">//         if(root == null) return 0;</span></span><br><span class="line"><span class="comment">//         if(root.left == null &amp;&amp; root.right == null) return 0;</span></span><br><span class="line"><span class="comment">//         if(root != null)&#123; </span></span><br><span class="line"><span class="comment">//              helper(3, root, sum);</span></span><br><span class="line"><span class="comment">//         &#125;</span></span><br><span class="line"><span class="comment">//         return sum[0];</span></span><br><span class="line"><span class="comment">//     &#125;</span></span><br><span class="line"><span class="comment">//     private void helper(int from, TreeNode node, int[] sum)&#123;</span></span><br><span class="line"><span class="comment">//         if(node.left == null &amp;&amp; node.right == null &amp;&amp; from == 1) &#123;</span></span><br><span class="line"><span class="comment">//             sum[0] = sum[0] + node.val;</span></span><br><span class="line"><span class="comment">//         &#125;</span></span><br><span class="line"><span class="comment">//         if(node.left != null)  helper(1, node.left, sum);</span></span><br><span class="line"><span class="comment">//         if(node.right != null)   helper(0, node.right, sum);</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//     &#125;</span></span><br><span class="line"><span class="comment">// &#125;</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sumOfLeftLeaves</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span> (root.left != <span class="keyword">null</span> &amp;&amp; root.left.left == <span class="keyword">null</span> &amp;&amp; root.left.right == <span class="keyword">null</span>) &#123;</span><br><span class="line">            sum += root.left.val;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            sum += sumOfLeftLeaves(root.left);</span><br><span class="line">        &#125;</span><br><span class="line">        sum += sumOfLeftLeaves(root.right);</span><br><span class="line">        <span class="keyword">return</span> sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="437-Path-Sum-III"><a href="#437-Path-Sum-III" class="headerlink" title="437. Path Sum III"></a><a href="https:// .com/problems/path-sum-iii/" target="_blank" rel="noopener">437. Path Sum III</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">pathSum</span><span class="params">(TreeNode root, <span class="keyword">int</span> sum)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>)<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        Queue&lt;TreeNode&gt; que = <span class="keyword">new</span> LinkedList();</span><br><span class="line">        <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">        que.offer(root);</span><br><span class="line">        <span class="keyword">while</span>(! que.isEmpty())&#123;</span><br><span class="line">            TreeNode node = que.poll();</span><br><span class="line">            <span class="keyword">int</span> tnum = helper(node, sum);</span><br><span class="line">            res += tnum;</span><br><span class="line">            <span class="keyword">if</span>(node.left != <span class="keyword">null</span>) que.offer(node.left);</span><br><span class="line">            <span class="keyword">if</span>(node.right != <span class="keyword">null</span>) que.offer(node.right);</span><br><span class="line">    </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">helper</span><span class="params">(TreeNode node, <span class="keyword">int</span> sum)</span></span>&#123;</span><br><span class="line">       <span class="keyword">if</span>(node == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">       <span class="keyword">if</span>(sum - node.val == <span class="number">0</span>) <span class="keyword">return</span> helper(node.left, sum - node.val) + helper(node.right, sum - node.val) + <span class="number">1</span>; </span><br><span class="line">       <span class="keyword">else</span> <span class="keyword">return</span> helper(node.left, sum - node.val) + helper(node.right, sum - node.val);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">=============</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">pathSum</span><span class="params">(TreeNode root, <span class="keyword">int</span> sum)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> pathSumFrom(root, sum) + pathSum(root.left, sum) + pathSum(root.right, sum);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">pathSumFrom</span><span class="params">(TreeNode node, <span class="keyword">int</span> sum)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (node == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> (node.val == sum ? <span class="number">1</span> : <span class="number">0</span>) </span><br><span class="line">            + pathSumFrom(node.left, sum - node.val) + pathSumFrom(node.right, sum - node.val);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="501-Find-Mode-in-Binary-Search-Tree"><a href="#501-Find-Mode-in-Binary-Search-Tree" class="headerlink" title="501. Find Mode in Binary Search Tree"></a><a href="https:// .com/problems/find-mode-in-binary-search-tree/" target="_blank" rel="noopener">501. Find Mode in Binary Search Tree</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">#复杂度有点高 todo</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    Map&lt;Integer,Integer&gt; map = <span class="keyword">new</span> HashMap();</span><br><span class="line">    <span class="keyword">int</span> max;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] findMode(TreeNode root) &#123;</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">0</span>]; </span><br><span class="line">        helper(root);</span><br><span class="line">        List&lt;Integer&gt; list = <span class="keyword">new</span> ArrayList();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> key: map.keySet())&#123;</span><br><span class="line">            <span class="keyword">if</span>(map.get(key) == max) list.add(key);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span>[] res = list.stream().mapToInt(Integer::valueOf).toArray();</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">     </span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">helper</span><span class="params">(TreeNode node)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(node.left != <span class="keyword">null</span>) helper(node.left);</span><br><span class="line">        map.put(node.val, map.getOrDefault(node.val, <span class="number">0</span>)+<span class="number">1</span>);</span><br><span class="line">        max = Math.max(max, map.get(node.val));</span><br><span class="line">        <span class="keyword">if</span>(node.right != <span class="keyword">null</span>) helper(node.right);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="98-Validate-Binary-Search-Tree"><a href="#98-Validate-Binary-Search-Tree" class="headerlink" title="98. Validate Binary Search Tree"></a><a href="https://leetcode.com/problems/validate-binary-search-tree/" target="_blank" rel="noopener">98. Validate Binary Search Tree</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">#todo</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isValidBST</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> helper(root, Integer.MIN_VALUE, Integer.MAX_VALUE);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">helper</span><span class="params">(TreeNode root, <span class="keyword">int</span> minVal, <span class="keyword">int</span> maxVal)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">if</span> (root.val &gt;= maxVal || root.val &lt;= minVal) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">return</span> helper(root.left, minVal, root.val) &amp; helper(root.right, root.val, maxVal);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="530-Minimum-Absolute-Difference-in-BST-todo"><a href="#530-Minimum-Absolute-Difference-in-BST-todo" class="headerlink" title="530. Minimum Absolute Difference in BST todo"></a><a href="https://leetcode.com/problems/minimum-absolute-difference-in-bst/" target="_blank" rel="noopener">530. Minimum Absolute Difference in BST todo</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> min = Integer.MAX_VALUE;</span><br><span class="line">    Integer prev = <span class="keyword">null</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getMinimumDifference</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (root == <span class="keyword">null</span>) <span class="keyword">return</span> min;</span><br><span class="line">        </span><br><span class="line">        getMinimumDifference(root.left);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (prev != <span class="keyword">null</span>) &#123;</span><br><span class="line">            min = Math.min(min, root.val - prev);</span><br><span class="line">        &#125;</span><br><span class="line">        prev = root.val;</span><br><span class="line">        </span><br><span class="line">        getMinimumDifference(root.right);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> min;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="538-Convert-BST-to-Greater-Tree"><a href="#538-Convert-BST-to-Greater-Tree" class="headerlink" title="538. Convert BST to Greater Tree"></a><a href="https://leetcode.com/problems/convert-bst-to-greater-tree/" target="_blank" rel="noopener">538. Convert BST to Greater Tree</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> prev = <span class="number">0</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> TreeNode <span class="title">convertBST</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        convertBST(root.right);</span><br><span class="line">        root.val = root.val + prev;</span><br><span class="line">        prev = root.val;</span><br><span class="line">        convertBST(root.left);</span><br><span class="line">        <span class="keyword">return</span> root;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="543-Diameter-of-Binary-Tree"><a href="#543-Diameter-of-Binary-Tree" class="headerlink" title="543. Diameter of Binary Tree"></a><a href="https://leetcode.com/problems/diameter-of-binary-tree/" target="_blank" rel="noopener">543. Diameter of Binary Tree</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> maxDim = Integer.MIN_VALUE;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">diameterOfBinaryTree</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        helper(root);</span><br><span class="line">        <span class="keyword">return</span> maxDim;        </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">helper</span><span class="params">(TreeNode node)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(node == <span class="keyword">null</span>)<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> left = helper(node.left);</span><br><span class="line">        <span class="keyword">int</span> right = helper(node.right);</span><br><span class="line">        maxDim = Math.max(maxDim, left + right);</span><br><span class="line">        <span class="keyword">return</span> Math.max(left, right) + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="572-Subtree-of-Another-Tree"><a href="#572-Subtree-of-Another-Tree" class="headerlink" title="572. Subtree of Another Tree"></a><a href="https://leetcode.com/problems/subtree-of-another-tree/" target="_blank" rel="noopener">572. Subtree of Another Tree</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isSubtree</span><span class="params">(TreeNode s, TreeNode t)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (s == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">if</span> (helper(s, t)) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">return</span> isSubtree(s.left, t) || isSubtree(s.right, t);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">helper</span><span class="params">(TreeNode s, TreeNode t)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (s == <span class="keyword">null</span> &amp;&amp; t == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">if</span> (s == <span class="keyword">null</span> || t == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">return</span> s.val == t.val &amp; helper(s.left, t.left) &amp; helper(s.right, t.right);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="617-Merge-Two-Binary-Trees"><a href="#617-Merge-Two-Binary-Trees" class="headerlink" title="617. Merge Two Binary Trees"></a><a href="https://leetcode.com/problems/merge-two-binary-trees/" target="_blank" rel="noopener">617. Merge Two Binary Trees</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**todo</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    TreeNode tree;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> TreeNode <span class="title">mergeTrees</span><span class="params">(TreeNode t1, TreeNode t2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(t1 == <span class="keyword">null</span>)<span class="keyword">return</span> t2;</span><br><span class="line">        <span class="keyword">if</span>(t2 != <span class="keyword">null</span>)&#123;</span><br><span class="line">            t1.val += t2.val;</span><br><span class="line">            t1.left = mergeTrees(t1.left, t2.left);</span><br><span class="line">            t1.right = mergeTrees(t1.right, t2.right);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> t1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;树的相关-（难度easy）&quot;&gt;&lt;a href=&quot;#树的相关-（难度easy）&quot; class=&quot;headerlink&quot; title=&quot;树的相关 （难度easy）&quot;&gt;&lt;/a&gt;树的相关 （难度easy）&lt;/h3&gt;&lt;h4 id=&quot;100-sameTree&quot;&gt;&lt;a href
      
    
    </summary>
    
    
      <category term="算法题" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95%E9%A2%98/"/>
    
    
  </entry>
  
  <entry>
    <title>DP相关算法题</title>
    <link href="http://yoursite.com/2019/08/09/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%EF%BC%88%E9%9A%BE%E5%BA%A6easey%EF%BC%89/"/>
    <id>http://yoursite.com/2019/08/09/动态规划（难度easey）/</id>
    <published>2019-08-09T06:57:15.000Z</published>
    <updated>2019-09-12T01:08:28.575Z</updated>
    
    <content type="html"><![CDATA[<h3 id="DP相关算法题"><a href="#DP相关算法题" class="headerlink" title="DP相关算法题"></a>DP相关算法题</h3><h4 id="198-House-Robber"><a href="#198-House-Robber" class="headerlink" title="198. House Robber"></a><a href="https://leetcode.com/problems/house-robber/" target="_blank" rel="noopener">198. House Robber</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// dp[i] = max(dp[i - 2] + nums[i], dp[i - 1])</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">rob</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.length == <span class="number">0</span>)<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(nums.length == <span class="number">1</span>)<span class="keyword">return</span> nums[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">if</span>(nums.length == <span class="number">2</span>)<span class="keyword">return</span> Math.max(nums[<span class="number">0</span>],nums[<span class="number">1</span>]);</span><br><span class="line">        <span class="keyword">int</span>[] dp = <span class="keyword">new</span> <span class="keyword">int</span> [nums.length + <span class="number">1</span>];</span><br><span class="line">        dp[<span class="number">0</span>] = nums[<span class="number">0</span>];</span><br><span class="line">        dp[<span class="number">1</span>] = Math.max(nums[<span class="number">0</span>],nums[<span class="number">1</span>]);</span><br><span class="line">        <span class="keyword">int</span> res = dp[<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>; i &lt; nums.length; i++)&#123;</span><br><span class="line">            dp[i] = Math.max(dp[i - <span class="number">2</span>] + nums[i], dp[i - <span class="number">1</span>]);</span><br><span class="line">            res = Math.max(res, dp[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="213-House-Robber-II"><a href="#213-House-Robber-II" class="headerlink" title="213. House Robber II"></a><a href="https://leetcode.com/problems/house-robber-ii/" target="_blank" rel="noopener">213. House Robber II</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//todo</span></span><br><span class="line"><span class="keyword">package</span> leleyi.study.algorithms.dp;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HouseRObber2</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">rob</span><span class="params">(<span class="keyword">int</span>[] nums)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (nums.length == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span> (nums.length == <span class="number">1</span>) <span class="keyword">return</span> Math.max(nums[<span class="number">0</span>], nums[<span class="number">1</span>]);</span><br><span class="line">        <span class="keyword">int</span> temp0, temp1, cur0 = <span class="number">0</span>, cur1 = <span class="number">0</span>, pre0 = <span class="number">0</span>, pre1 = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length - <span class="number">1</span>; i++)&#123;</span><br><span class="line">            <span class="comment">//begin at 0</span></span><br><span class="line">            temp0 = pre0;</span><br><span class="line">            pre0 = cur0;</span><br><span class="line">            cur0 = Math.max(temp0 + nums[i], cur0);</span><br><span class="line"><span class="comment">//begin at 1</span></span><br><span class="line">            temp1 = pre1;</span><br><span class="line">            pre1 = cur1;</span><br><span class="line">            cur1 = Math.max(temp1 + nums[i + <span class="number">1</span>], cur1);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> Math.max(cur0, cur1);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="746-Min-Cost-Climbing-Stairs"><a href="#746-Min-Cost-Climbing-Stairs" class="headerlink" title="746. Min Cost Climbing Stairs"></a><a href="https://leetcode.com/problems/min-cost-climbing-stairs/" target="_blank" rel="noopener">746. Min Cost Climbing Stairs</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// dp[i] = cost[i] + min(dp[i - 1], d[i - 2])</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">minCostClimbingStairs</span><span class="params">(<span class="keyword">int</span>[] cost)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] dp = <span class="keyword">new</span> <span class="keyword">int</span>[cost.length + <span class="number">1</span>];</span><br><span class="line">        dp[<span class="number">0</span>] = cost[<span class="number">0</span>];</span><br><span class="line">        dp[<span class="number">1</span>] = cost[<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>; i &lt; cost.length ; i++)&#123;</span><br><span class="line">            dp[i] = cost[i] + Math.min(dp[i - <span class="number">1</span>], dp[i-<span class="number">2</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> Math.min(dp[cost.length - <span class="number">1</span>], dp[cost.length - <span class="number">2</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="62-Unique-Paths"><a href="#62-Unique-Paths" class="headerlink" title="62. Unique Paths"></a><a href="https://leetcode.com/problems/unique-paths/" target="_blank" rel="noopener">62. Unique Paths</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// dp[i][j] = dp[i - 1][j] + dp[i][j - 1];</span></span><br><span class="line"><span class="comment">// dp[j] = dp[j - 1] + dp[j];</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">uniquePaths</span><span class="params">(<span class="keyword">int</span> m, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line"><span class="comment">//         int dp[][] = new int[m + 1][n + 1];</span></span><br><span class="line"><span class="comment">//         for(int i = 0; i &lt; m; i++)&#123;</span></span><br><span class="line"><span class="comment">//             dp[i][0] = 1;</span></span><br><span class="line"><span class="comment">//         &#125;</span></span><br><span class="line"><span class="comment">//         for(int j = 0; j &lt; n; j++)&#123;</span></span><br><span class="line"><span class="comment">//             dp[0][j] = 1;</span></span><br><span class="line"><span class="comment">//         &#125;</span></span><br><span class="line"><span class="comment">//         for(int i = 1; i &lt;= m; i++)&#123;</span></span><br><span class="line">            </span><br><span class="line"><span class="comment">//             for(int j = 1; j &lt;= n; j++)&#123;</span></span><br><span class="line"><span class="comment">//                     dp[i][j] = dp[i - 1][j] + dp[i][j - 1];</span></span><br><span class="line"><span class="comment">//             &#125;</span></span><br><span class="line"><span class="comment">//         &#125;</span></span><br><span class="line"><span class="comment">//         return dp[m - 1][n - 1];</span></span><br><span class="line"><span class="comment">//     &#125;</span></span><br><span class="line">        <span class="keyword">int</span> dp[] = <span class="keyword">new</span> <span class="keyword">int</span>[n + <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++)&#123;</span><br><span class="line">            dp[i] = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; m; i++)&#123;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>; j &lt; n; j++)&#123;</span><br><span class="line">                dp[j] = dp[j - <span class="number">1</span>] + dp[j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[n - <span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="63-Unique-Paths-II"><a href="#63-Unique-Paths-II" class="headerlink" title="63. Unique Paths II"></a><a href="https://leetcode.com/problems/unique-paths-ii/" target="_blank" rel="noopener">63. Unique Paths II</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">uniquePathsWithObstacles</span><span class="params">(<span class="keyword">int</span>[][] obstacleGrid)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">int</span> m = obstacleGrid.length;</span><br><span class="line">       <span class="keyword">int</span> n = obstacleGrid[<span class="number">0</span>].length;</span><br><span class="line">       <span class="keyword">int</span> dp[] = <span class="keyword">new</span> <span class="keyword">int</span>[n + <span class="number">1</span>];</span><br><span class="line">       <span class="keyword">if</span>(obstacleGrid[m-<span class="number">1</span>][n-<span class="number">1</span>] == <span class="number">1</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">       <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++)&#123;</span><br><span class="line">           <span class="keyword">if</span>(obstacleGrid[<span class="number">0</span>][i] == <span class="number">1</span>)&#123;</span><br><span class="line">               dp[i] = <span class="number">0</span>;</span><br><span class="line">               <span class="keyword">break</span>;</span><br><span class="line">           &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">               dp[i] = <span class="number">1</span>;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; m; i++)&#123;</span><br><span class="line">           <span class="keyword">if</span>(obstacleGrid[i][<span class="number">0</span>] == <span class="number">1</span>)&#123;</span><br><span class="line">               dp[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>; j &lt; n; j++)&#123;</span><br><span class="line">               <span class="keyword">if</span>(obstacleGrid[i][j] == <span class="number">1</span>)&#123;</span><br><span class="line">                   dp[j] = <span class="number">0</span>;</span><br><span class="line">               &#125;</span><br><span class="line">               <span class="keyword">else</span>&#123;</span><br><span class="line">                   dp[j] = dp[j - <span class="number">1</span>] + dp[j];</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> dp[n - <span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="64-Minimum-Path-Sum"><a href="#64-Minimum-Path-Sum" class="headerlink" title="64. Minimum Path Sum"></a><a href="https://leetcode.com/problems/minimum-path-sum/" target="_blank" rel="noopener">64. Minimum Path Sum</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// d[i][j] = min(d[i - 1][j], d[i][j - 1]) + grid[i][j]</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">minPathSum</span><span class="params">(<span class="keyword">int</span>[][] grid)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span> [grid.length][grid[<span class="number">0</span>].length];</span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">0</span>] = grid[<span class="number">0</span>][<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; grid[<span class="number">0</span>].length; i++)&#123;</span><br><span class="line">            dp[<span class="number">0</span>][i] = dp[<span class="number">0</span>][i - <span class="number">1</span>] + grid[<span class="number">0</span>][i];</span><br><span class="line">        &#125;</span><br><span class="line">         <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; grid.length; i++)&#123;</span><br><span class="line">            dp[i][<span class="number">0</span>] = dp[i - <span class="number">1</span>][<span class="number">0</span>] + grid[i][<span class="number">0</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; grid.length; i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>; j &lt; grid[<span class="number">0</span>].length; j++)&#123;</span><br><span class="line">                dp[i][j] = Math.min(dp[i - <span class="number">1</span>][j], dp[i][j - <span class="number">1</span>]) + grid[i][j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[grid.length - <span class="number">1</span>][grid[<span class="number">0</span>].length - <span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">minPathSum</span><span class="params">(<span class="keyword">int</span>[][] grid)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> m = grid.length;</span><br><span class="line">        <span class="keyword">int</span> n = grid[<span class="number">0</span>].length;</span><br><span class="line">        <span class="keyword">int</span> dp[] = <span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line"></span><br><span class="line">        dp[<span class="number">0</span>] = grid[<span class="number">0</span>][<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>; j &lt; n; j++)&#123;</span><br><span class="line">            dp[j] = dp[j - <span class="number">1</span>] + grid[<span class="number">0</span>][j];</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; m; i++)&#123;</span><br><span class="line">            dp[<span class="number">0</span>] += grid[i][<span class="number">0</span>];</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>; j &lt; n; j++)&#123;</span><br><span class="line">                dp[j] = Math.min(dp[j - <span class="number">1</span>], dp[j]) + grid[i][j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[n - <span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="96-Unique-Binary-Search-Trees"><a href="#96-Unique-Binary-Search-Trees" class="headerlink" title="96. Unique Binary Search Trees"></a><a href="https://leetcode.com/problems/unique-binary-search-trees/" target="_blank" rel="noopener">96. Unique Binary Search Trees</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//卡特兰数　h(n)=h(n-1)*(4*n-2)/(n+1)  1, 1, 5, 14...... = C(2n, n) / n + 1;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">numTrees</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> dp[] = <span class="keyword">new</span> <span class="keyword">long</span>[n + <span class="number">1</span>];</span><br><span class="line">        dp[<span class="number">0</span>] = <span class="number">1</span>; dp[<span class="number">1</span>] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>; i &lt;= n; i++)&#123;</span><br><span class="line">            dp[i] = dp[i - <span class="number">1</span>] * (<span class="number">4</span> * i - <span class="number">2</span>) / (i + <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">int</span>)dp[n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="95-Unique-Binary-Search-Trees-II"><a href="#95-Unique-Binary-Search-Trees-II" class="headerlink" title="95. Unique Binary Search Trees II"></a><a href="https://leetcode.com/problems/unique-binary-search-trees-ii/" target="_blank" rel="noopener">95. Unique Binary Search Trees II</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TODO</span><br></pre></td></tr></table></figure><h4 id="120-Triangle"><a href="#120-Triangle" class="headerlink" title="120. Triangle"></a><a href="https://leetcode.com/problems/triangle/" target="_blank" rel="noopener">120. Triangle</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 从最后一排往上dp</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">minimumTotal</span><span class="params">(List&lt;List&lt;Integer&gt;&gt; triangle)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> m = triangle.size();</span><br><span class="line">        <span class="keyword">int</span> n = triangle.get(m - <span class="number">1</span>).size();</span><br><span class="line">        <span class="keyword">int</span> dp[] = <span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">            dp[i] = triangle.get(m - <span class="number">1</span>).get(i);</span><br><span class="line">            System.out.println(dp[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = m - <span class="number">2</span>; i &gt;= <span class="number">0</span>; i--) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt;= i; j++) &#123;</span><br><span class="line"></span><br><span class="line">                dp[j] = Math.min(dp[j+ <span class="number">1</span>], dp[j]) + triangle.get(i).get(j);</span><br><span class="line">                <span class="comment">// System.out.println(i+":"+ j +"" + "-&gt;" + dp[j]);</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="139-Word-Break"><a href="#139-Word-Break" class="headerlink" title="139. Word Break"></a><a href="https://leetcode.com/problems/word-break/" target="_blank" rel="noopener">139. Word Break</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">wordBreak</span><span class="params">(String s, List&lt;String&gt; wordDict)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">boolean</span>[] dp = <span class="keyword">new</span> <span class="keyword">boolean</span> [s.length() + <span class="number">1</span>];</span><br><span class="line">        dp[<span class="number">0</span>] = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span>  i = <span class="number">1</span>; i &lt;= s.length(); i ++)&#123;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span>  j = <span class="number">0</span>; j &lt; i; j++)&#123;</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span>(dp[j] &amp;&amp; wordDict.contains(s.substring(j,i)))&#123;</span><br><span class="line">                    dp[i] = <span class="keyword">true</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[s.length()];</span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="140-Word-Break-II"><a href="#140-Word-Break-II" class="headerlink" title="140. Word Break II"></a><a href>140. Word Break II</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">todo</span><br></pre></td></tr></table></figure><h4 id="152-Maximum-Product-Subarray"><a href="#152-Maximum-Product-Subarray" class="headerlink" title="152. Maximum Product Subarray"></a><a href>152. Maximum Product Subarray</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// todo again</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxProduct</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">int</span>[] f = <span class="keyword">new</span> <span class="keyword">int</span>[nums.length];</span><br><span class="line">    <span class="keyword">int</span>[] g = <span class="keyword">new</span> <span class="keyword">int</span>[nums.length];</span><br><span class="line">    f[<span class="number">0</span>] = nums[<span class="number">0</span>];</span><br><span class="line">    g[<span class="number">0</span>] = nums[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">int</span> res = nums[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; nums.length; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span>(nums[i] &lt; <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">int</span> temp = f[i - <span class="number">1</span>];</span><br><span class="line">            f[i - <span class="number">1</span>] = g[i - <span class="number">1</span>];</span><br><span class="line">            g[i - <span class="number">1</span>] = temp;</span><br><span class="line">        &#125;</span><br><span class="line">        f[i] = Math.max(f[i - <span class="number">1</span>] * nums[i], nums[i]);</span><br><span class="line">        g[i] = Math.min(g[i - <span class="number">1</span>] * nums[i], nums[i]);</span><br><span class="line">        res = Math.max(res, f[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="221-Maximal-Square"><a href="#221-Maximal-Square" class="headerlink" title="221. Maximal Square"></a><a href="https://leetcode.com/problems/maximal-square/" target="_blank" rel="noopener">221. Maximal Square</a></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maximalSquare</span><span class="params">(<span class="keyword">char</span>[][] a)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(a.length == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> m = a.length, n = a[<span class="number">0</span>].length, result = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[m+<span class="number">1</span>][n+<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span> ; i &lt;= m; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>; j &lt;= n; j++) &#123;</span><br><span class="line">                <span class="keyword">if</span>(a[i-<span class="number">1</span>][j-<span class="number">1</span>] == <span class="string">'1'</span>) &#123;</span><br><span class="line">                    dp[i][j] = Math.min(Math.min(dp[i - <span class="number">1</span>][j], dp[i][j - <span class="number">1</span>]),dp[i - <span class="number">1</span>][j - <span class="number">1</span>]) + <span class="number">1</span>;</span><br><span class="line">                    result = Math.max(dp[i][j], result); <span class="comment">// update result</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">return</span> result*result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;DP相关算法题&quot;&gt;&lt;a href=&quot;#DP相关算法题&quot; class=&quot;headerlink&quot; title=&quot;DP相关算法题&quot;&gt;&lt;/a&gt;DP相关算法题&lt;/h3&gt;&lt;h4 id=&quot;198-House-Robber&quot;&gt;&lt;a href=&quot;#198-House-Robber&quot;
      
    
    </summary>
    
    
      <category term="算法题" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95%E9%A2%98/"/>
    
    
  </entry>
  
</feed>
